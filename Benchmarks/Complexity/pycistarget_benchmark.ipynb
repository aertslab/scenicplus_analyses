{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13933080-9f72-4b42-a595-26988813db53",
   "metadata": {},
   "source": [
    "# DPCL_cisTopicObject_3K_fragments_80_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207afab3-d663-4797-992f-d64d90358f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import pandas as pd\n",
    "import dill\n",
    "import pyranges as pr\n",
    "from pycistarget.motif_enrichment_cistarget import *\n",
    "from pycistarget.motif_enrichment_dem import *\n",
    "from pycistarget.utils import *\n",
    "import pybiomart as pbm\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "def run_pycistarget(region_sets: Dict[str, pr.PyRanges],\n",
    "                 species: str,\n",
    "                 save_path: str,\n",
    "                 custom_annot: pd.DataFrame = None,\n",
    "                 save_partial: bool = False,\n",
    "                 ctx_db_path: str = None,\n",
    "                 dem_db_path: str = None,\n",
    "                 run_without_promoters: bool = False,\n",
    "                 biomart_host: str = 'http://www.ensembl.org',\n",
    "                 promoter_space: int = 500,\n",
    "                 ctx_auc_threshold: float = 0.005,\n",
    "                 ctx_nes_threshold: float = 3.0,\n",
    "                 ctx_rank_threshold: float = 0.05,\n",
    "                 dem_log2fc_thr: float = 0.5,\n",
    "                 dem_motif_hit_thr: float = 3.0,\n",
    "                 dem_max_bg_regions: int = 500,\n",
    "                 annotation : List[str] = ['Direct_annot', 'Orthology_annot'],\n",
    "                 motif_similarity_fdr: float = 0.000001,\n",
    "                 path_to_motif_annotations: str = None,\n",
    "                 annotation_version: str = 'v9',\n",
    "                 n_cpu : int = 1,\n",
    "                 _temp_dir: str = None,\n",
    "                 exclude_motifs: str = None,\n",
    "                 exclude_collection: List[str] = None,\n",
    "                 **kwargs):\n",
    "    # Create logger\n",
    "    level = logging.INFO\n",
    "    log_format = '%(asctime)s %(name)-12s %(levelname)-8s %(message)s'\n",
    "    handlers = [logging.StreamHandler(stream=sys.stdout)]\n",
    "    logging.basicConfig(level=level, format=log_format, handlers=handlers)\n",
    "    log = logging.getLogger('pycisTarget_wrapper')\n",
    "    \n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    check_folder = os.path.isdir(save_path)\n",
    "    if not check_folder:\n",
    "        os.makedirs(save_path)\n",
    "        log.info(\"Created folder : \" + save_path)\n",
    "    else:\n",
    "        log.info(save_path + \" folder already exists.\")\n",
    "        \n",
    "    def get_species_annotation(species: str):\n",
    "        dataset = pbm.Dataset(name=species,  host=biomart_host)\n",
    "        annot = dataset.query(attributes=['chromosome_name', 'transcription_start_site', 'strand', 'external_gene_name', 'transcript_biotype'])\n",
    "        annot.columns = ['Chromosome', 'Start', 'Strand', 'Gene', 'Transcript_type']\n",
    "        annot['Chromosome'] = annot['Chromosome'].astype('str')\n",
    "        filterf = annot['Chromosome'].str.contains('CHR|GL|JH|MT|KI')\n",
    "        annot = annot[~filterf]\n",
    "        annot['Chromosome'] = annot['Chromosome'].replace(r'(\\b\\S)', r'chr\\1')\n",
    "        annot = annot[annot.Transcript_type == 'protein_coding']\n",
    "        annot = annot.dropna(subset = ['Chromosome', 'Start'])\n",
    "        # Check if chromosomes have chr\n",
    "        check = region_sets[list(region_sets.keys())[0]]\n",
    "        if not any(['chr' in c for c in check[list(check.keys())[0]].df['Chromosome']]):\n",
    "            annot.Chromosome = annot.Chromosome.str.replace('chr', '')\n",
    "        if not any(['chr' in x for x in annot.Chromosome]):\n",
    "            annot.Chromosome = [f'chr{x}' for x in annot.Chromosome]\n",
    "        annot_dem=annot.copy()\n",
    "        # Define promoter space\n",
    "        annot['End'] = annot['Start'].astype(int)+promoter_space\n",
    "        annot['Start'] = annot['Start'].astype(int)-promoter_space\n",
    "        annot = pr.PyRanges(annot[['Chromosome', 'Start', 'End']])\n",
    "        return annot, annot_dem\n",
    "        \n",
    "    # Prepare annotation\n",
    "    if species == 'homo_sapiens':\n",
    "        annot, annot_dem = get_species_annotation('hsapiens_gene_ensembl')\n",
    "    elif species == 'mus_musculus':\n",
    "        annot, annot_dem = get_species_annotation('mmusculus_gene_ensembl')\n",
    "    elif species == 'drosophila_melanogaster':\n",
    "        annot, annot_dem = get_species_annotation('dmelanogaster_gene_ensembl')\n",
    "    elif species == 'gallus_gallus':\n",
    "        annot, annot_dem = get_species_annotation('ggallus_gene_ensembl')\n",
    "    elif species == 'custom':\n",
    "        annot_dem = custom_annot\n",
    "        annot = annot_dem.copy()\n",
    "        # Define promoter space\n",
    "        annot['End'] = annot['Start'].astype(int)+promoter_space\n",
    "        annot['Start'] = annot['Start'].astype(int)-promoter_space\n",
    "        annot = pr.PyRanges(annot[['Chromosome', 'Start', 'End']])\n",
    "    else:\n",
    "        raise TypeError(\"Species not recognized\")\n",
    "\n",
    "    menr = {}\n",
    "    for key in region_sets.keys():\n",
    "        if ctx_db_path is not None:\n",
    "            log.info('Loading cisTarget database for ' + key)\n",
    "            ## CISTARGET\n",
    "            regions = region_sets[key]\n",
    "            ctx_db = cisTargetDatabase(ctx_db_path, regions)  \n",
    "            if exclude_motifs is not None:\n",
    "                out = pd.read_csv(exclude_motifs, header=None).iloc[:,0].tolist()\n",
    "                ctx_db.db_rankings = ctx_db.db_rankings.drop(out)\n",
    "            if exclude_collection is not None:\n",
    "                for col in exclude_collection:\n",
    "                    ctx_db.db_rankings = ctx_db.db_rankings[~ctx_db.db_rankings.index.str.contains(col)]\n",
    "            ## DEFAULT\n",
    "            import time\n",
    "            t1_start = time.time()\n",
    "            log.info('Running cisTarget for '+key)\n",
    "            menr['CTX_'+key+'_All'] = run_cistarget(ctx_db = ctx_db,\n",
    "                                   region_sets = regions,\n",
    "                                   specie = species,\n",
    "                                   auc_threshold = ctx_auc_threshold,\n",
    "                                   nes_threshold = ctx_nes_threshold,\n",
    "                                   rank_threshold = ctx_rank_threshold,\n",
    "                                   annotation = annotation,\n",
    "                                   motif_similarity_fdr = motif_similarity_fdr,\n",
    "                                   path_to_motif_annotations = path_to_motif_annotations,\n",
    "                                   n_cpu = n_cpu,\n",
    "                                   _temp_dir= _temp_dir,\n",
    "                                   annotation_version = annotation_version,\n",
    "                                   **kwargs)\n",
    "            m1=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "            t1_stop = time.time()\n",
    "            time_ctx_all = t1_stop-t1_start\n",
    "            out_folder = os.path.join(save_path,'CTX_'+key+'_All')\n",
    "            check_folder = os.path.isdir(out_folder)\n",
    "            if not check_folder:\n",
    "                os.makedirs(out_folder)\n",
    "                log.info(\"Created folder : \" + out_folder)\n",
    "            else:\n",
    "                log.info(out_folder + \" folder already exists.\")\n",
    "            for x in menr['CTX_'+key+'_All'].keys():\n",
    "                out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                menr['CTX_'+key+'_All'][str(x)].motif_enrichment.to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "            if(save_partial):\n",
    "                with open(os.path.join(save_path,'CTX_'+key+'_All' + '.pkl'), 'wb') as f:\n",
    "                    dill.dump(menr['CTX_'+key+'_All'], f, protocol=-1)\n",
    "\n",
    "            if run_without_promoters is True:\n",
    "                ## REMOVE PROMOTERS\n",
    "                log.info('Running cisTarget without promoters for '+key)\n",
    "                regions_overlaps = {key: regions[key].count_overlaps(annot) for key in regions.keys()}\n",
    "                regions_np = {key: regions_overlaps[key][regions_overlaps[key].NumberOverlaps == 0][['Chromosome', 'Start', 'End']] for key in regions.keys()}\n",
    "                db_regions = set(pd.concat([ctx_db.regions_to_db[x] for x in ctx_db.regions_to_db.keys()])['Query'])\n",
    "                ctx_db.regions_to_db = {x: target_to_query(regions_np[x], list(db_regions), fraction_overlap = 0.4) for x in regions_np.keys()}\n",
    "                t1_start = time.time()\n",
    "                menr['CTX_'+key+'_No_promoters'] = run_cistarget(ctx_db = ctx_db,\n",
    "                                   region_sets = regions_np,\n",
    "                                   specie = species,\n",
    "                                   auc_threshold = ctx_auc_threshold,\n",
    "                                   nes_threshold = ctx_nes_threshold,\n",
    "                                   rank_threshold = ctx_rank_threshold,\n",
    "                                   annotation = annotation,\n",
    "                                   motif_similarity_fdr = motif_similarity_fdr, \n",
    "                                   path_to_motif_annotations = path_to_motif_annotations,\n",
    "                                   n_cpu = n_cpu,\n",
    "                                   _temp_dir= _temp_dir,\n",
    "                                   annotation_version = annotation_version,\n",
    "                                   **kwargs)\n",
    "                m2=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "                t1_stop = time.time()\n",
    "                time_ctx_np = t1_stop-t1_start\n",
    "                out_folder = os.path.join(save_path,'CTX_'+key+'_No_promoters')\n",
    "                check_folder = os.path.isdir(out_folder)\n",
    "                if not check_folder:\n",
    "                    os.makedirs(out_folder)\n",
    "                    log.info(\"Created folder:\" + out_folder)\n",
    "                else:\n",
    "                    log.info(out_folder + \" folder already exists.\")\n",
    "                for x in menr['CTX_'+key+'_No_promoters'].keys():\n",
    "                    out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                    menr['CTX_'+key+'_No_promoters'][str(x)].motif_enrichment.to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "                \n",
    "                if(save_partial):\n",
    "                    with open(os.path.join(save_path,'CTX_'+key+'_No_promoters' + '.pkl'), 'wb') as f:\n",
    "                      dill.dump(menr['CTX_'+key+'_No_promoters'], f, protocol=-1)\n",
    "        ## DEM\n",
    "        if dem_db_path is not None:\n",
    "            log.info('Running DEM for '+key)\n",
    "            regions = region_sets[key]\n",
    "            dem_db = DEMDatabase(dem_db_path, regions)  \n",
    "            if exclude_motifs is not None:\n",
    "                out = pd.read_csv(exclude_motifs, header=None).iloc[:,0].tolist()\n",
    "                dem_db.db_scores = dem_db.db_scores.drop(out)\n",
    "            if exclude_collection is not None:\n",
    "                for col in exclude_collection:\n",
    "                    dem_db.db_scores = dem_db.db_scores[~dem_db.db_scores.index.str.contains(col)]\n",
    "            t1_start = time.time()\n",
    "            menr['DEM_'+key+'_All'] = DEM(dem_db = dem_db,\n",
    "                               region_sets = regions,\n",
    "                               log2fc_thr = dem_log2fc_thr,\n",
    "                               motif_hit_thr = dem_motif_hit_thr,\n",
    "                               max_bg_regions = dem_max_bg_regions,\n",
    "                               specie = species,\n",
    "                               genome_annotation = annot_dem,\n",
    "                               promoter_space = promoter_space,\n",
    "                               motif_annotation =   annotation,\n",
    "                               motif_similarity_fdr = motif_similarity_fdr, \n",
    "                               path_to_motif_annotations = path_to_motif_annotations,\n",
    "                               n_cpu = n_cpu,\n",
    "                               annotation_version = annotation_version,\n",
    "                               tmp_dir = save_path,\n",
    "                               _temp_dir= _temp_dir,\n",
    "                               **kwargs)\n",
    "            m3=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "            t1_stop = time.time()\n",
    "            time_dem_all = t1_stop-t1_start\n",
    "            out_folder = os.path.join(save_path,'DEM_'+key+'_All')\n",
    "            check_folder = os.path.isdir(out_folder)\n",
    "            if not check_folder:\n",
    "                os.makedirs(out_folder)\n",
    "                log.info(\"Created folder : \"+ out_folder)\n",
    "            else:\n",
    "                log.info(out_folder + \" folder already exists.\")\n",
    "            for x in menr['DEM_'+key+'_All'].motif_enrichment.keys():\n",
    "                out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                menr['DEM_'+key+'_All'].motif_enrichment[str(x)].to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "            if(save_partial):\n",
    "                with open(os.path.join(save_path, 'DEM_'+key+'_All'+'.pkl'), 'wb') as f:\n",
    "                  dill.dump(menr['DEM_'+key+'_All'], f, protocol=-1)\n",
    "                \n",
    "            if run_without_promoters is True:\n",
    "                log.info('Running DEM without promoters for '+key)\n",
    "                ## REMOVE PROMOTERS\n",
    "                regions_overlaps = {key: regions[key].count_overlaps(annot) for key in regions.keys()}\n",
    "                regions_np = {key: regions_overlaps[key][regions_overlaps[key].NumberOverlaps == 0][['Chromosome', 'Start', 'End']] for key in regions.keys()}\n",
    "                db_regions = set(pd.concat([dem_db.regions_to_db[x] for x in dem_db.regions_to_db.keys()])['Query'])\n",
    "                dem_db.regions_to_db = {x: target_to_query(regions_np[x], list(db_regions), fraction_overlap = 0.4) for x in regions_np.keys()}\n",
    "                t1_start = time.time()\n",
    "                menr['DEM_'+key+'_No_promoters'] = DEM(dem_db = dem_db,\n",
    "                               region_sets = regions_np,\n",
    "                               log2fc_thr = dem_log2fc_thr,\n",
    "                               motif_hit_thr = dem_motif_hit_thr,\n",
    "                               max_bg_regions = dem_max_bg_regions,\n",
    "                               specie = species,\n",
    "                               promoter_space = promoter_space,\n",
    "                               motif_annotation = annotation,\n",
    "                               motif_similarity_fdr = motif_similarity_fdr, \n",
    "                               path_to_motif_annotations = path_to_motif_annotations,\n",
    "                               n_cpu = n_cpu,\n",
    "                               annotation_version = annotation_version,\n",
    "                               tmp_dir = save_path,\n",
    "                               _temp_dir= _temp_dir,\n",
    "                               **kwargs)\n",
    "                m4=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "                t1_stop = time.time()\n",
    "                time_dem_np = t1_stop-t1_start\n",
    "                out_folder = os.path.join(save_path,'DEM_'+key+'_No_promoters')\n",
    "                check_folder = os.path.isdir(out_folder)\n",
    "                if not check_folder:\n",
    "                    os.makedirs(out_folder)\n",
    "                    log.info(\"Created folder : \"+ out_folder)\n",
    "                else:\n",
    "                    log.info(out_folder + \" folder already exists.\")\n",
    "                for x in menr['DEM_'+key+'_No_promoters'].motif_enrichment.keys():\n",
    "                    out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                    menr['DEM_'+key+'_No_promoters'].motif_enrichment[str(x)].to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "                if(save_partial):\n",
    "                    with open(os.path.join(save_path, 'DEM_'+key+'_No_promoters'+'.pkl'), 'wb') as f:\n",
    "                      dill.dump(menr['DEM_'+key+'_All'], f, protocol=-1)\n",
    "                    \n",
    "        times = [time_ctx_all, time_ctx_np, time_dem_all, time_dem_np]\n",
    "        df = pd.DataFrame(times, index=['CTX_all', 'CTX_np', 'DEM_all', 'DEM_np'], columns=['Time'])\n",
    "        df.to_csv(save_path+key+'running_times.tsv', sep='\\t') \n",
    "        memory=[m1,m2,m3,m4]\n",
    "        df = pd.DataFrame(memory, index=['CTX_all', 'CTX_np', 'DEM_all', 'DEM_np'], columns=['Memory'])\n",
    "        df.to_csv(save_path+key+'cummulative_memory.tsv', sep='\\t')  \n",
    "        memory=[m1,m2-m1,m3-m2,m4-m3]\n",
    "        df = pd.DataFrame(memory, index=['CTX_all', 'CTX_np', 'DEM_all', 'DEM_np'], columns=['Memory'])\n",
    "        df.to_csv(save_path+key+'memory_per_step.tsv', sep='\\t')  \n",
    "                    \n",
    "    log.info('Saving object')         \n",
    "    with open(os.path.join(save_path,'menr.pkl'), 'wb') as f:\n",
    "        dill.dump(menr, f, protocol=-1)\n",
    "    \n",
    "    import time\n",
    "    log.info('Finished! Took {} minutes'.format((time.time() - start_time)/60)) \n",
    "            \n",
    "# Load region binarized topics\n",
    "import pickle\n",
    "outDir = '/staging/leuven/stg_00002/lcb/cbravo/Multiomics_pipeline/analysis/DPCL/speed_benchmark/low_simulation/DPCL_cisTopicObject_3K_fragments_80_cells/'\n",
    "infile = open(outDir+'binarized_topic_region.pkl', 'rb')\n",
    "binarized_topic_region = pickle.load(infile)\n",
    "infile.close()\n",
    "# Load DARs\n",
    "import pickle\n",
    "infile = open(outDir+'DARs.pkl', 'rb')\n",
    "DARs_dict = pickle.load(infile)\n",
    "infile.close()\n",
    "# Format region sets\n",
    "import re\n",
    "import pyranges as pr\n",
    "from pycistarget.utils import *\n",
    "region_sets = {}\n",
    "region_sets['Topics'] = {key: pr.PyRanges(region_names_to_coordinates(binarized_topic_region[key].index.tolist())) for key in binarized_topic_region.keys()}\n",
    "region_sets['DARs'] = {re.sub('[^A-Za-z0-9]+', '_', key): pr.PyRanges(region_names_to_coordinates(DARs_dict[key].index.tolist())) for key in DARs_dict.keys()}\n",
    "# Create save_path\n",
    "save_path = outDir + 'pycistarget/'\n",
    "# Create save_Dir\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "\n",
    "# Run pycistarget\n",
    "run_pycistarget(region_sets,\n",
    "                 ctx_db_path = '/staging/leuven/stg_00002/lcb/cbravo/Multiomics_pipeline/analysis/DPCL/ctx_db/cluster_V10_DPCL_feather_v2.regions_vs_motifs.rankings.feather',\n",
    "                 species = 'homo_sapiens',\n",
    "                 save_path = save_path,\n",
    "                 dem_db_path = '/staging/leuven/stg_00002/lcb/cbravo/Multiomics_pipeline/analysis/DPCL/ctx_db/cluster_V10_DPCL_feather_v2.regions_vs_motifs.scores.feather',\n",
    "                 run_without_promoters = True,\n",
    "                 biomart_host = 'http://www.ensembl.org',\n",
    "                 promoter_space = 500,\n",
    "                 ctx_auc_threshold = 0.005,\n",
    "                 ctx_nes_threshold = 3.0,\n",
    "                 ctx_rank_threshold = 0.05,\n",
    "                 dem_log2fc_thr = 0.5,\n",
    "                 dem_motif_hit_thr = 3.0,\n",
    "                 dem_max_bg_regions = 500,\n",
    "                 path_to_motif_annotations = '/staging/leuven/stg_00002/lcb/cbravo/cluster_motif_collection_V10_no_desso_no_factorbook/snapshots/motifs-v10nr_clust-nr.mgi-m0.00001-o0.0.tbl',\n",
    "                 annotation_version = 'v10nr_clust',\n",
    "                 annotation = ['Direct_annot', 'Orthology_annot'],\n",
    "                 n_cpu = 8,\n",
    "                 _temp_dir = '/scratch/leuven/313/vsc31305/ray_spill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5902292-c27f-4ae3-8a81-ee6340cbc72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --partition=batch\n",
    "#SBATCH --cluster wice\n",
    "#SBATCH --account lp_wice_pilot\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=carmen.bravogonzalezblas@kuleuven.be\n",
    "#SBATCH --ntasks=1\n",
    "\n",
    "#SBATCH --cpus-per-task=20\n",
    "#SBATCH --time=3:00:00\n",
    "#SBATCH --mem=180G\n",
    "\n",
    "#SBATCH --job-name=DPCL_cisTopicObject_3K_fragments_80_cells\n",
    "#SBATCH --output=DPCL_cisTopicObject_3K_fragments_80_cells.out\n",
    "#SBATCH --error=DPCL_cisTopicObject_3K_fragments_80_cells.err\n",
    "\n",
    "singularity exec -B /lustre1,/staging,/data,/vsc-hard-mounts,/scratch,/local_scratch /data/leuven/software/biomed/singularity_images/scenicplus/scenicplus.sif python DPCL_cisTopicObject_3K_fragments_80_cells.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ea0b9b-6a60-427a-84bb-55cde7fc1d9a",
   "metadata": {},
   "source": [
    "# DPCL_cisTopicObject_3K_fragments_1K_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190c7cf2-a145-451f-8966-8593c7f7dd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import pandas as pd\n",
    "import dill\n",
    "import pyranges as pr\n",
    "from pycistarget.motif_enrichment_cistarget import *\n",
    "from pycistarget.motif_enrichment_dem import *\n",
    "from pycistarget.utils import *\n",
    "import pybiomart as pbm\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "def run_pycistarget(region_sets: Dict[str, pr.PyRanges],\n",
    "                 species: str,\n",
    "                 save_path: str,\n",
    "                 custom_annot: pd.DataFrame = None,\n",
    "                 save_partial: bool = False,\n",
    "                 ctx_db_path: str = None,\n",
    "                 dem_db_path: str = None,\n",
    "                 run_without_promoters: bool = False,\n",
    "                 biomart_host: str = 'http://www.ensembl.org',\n",
    "                 promoter_space: int = 500,\n",
    "                 ctx_auc_threshold: float = 0.005,\n",
    "                 ctx_nes_threshold: float = 3.0,\n",
    "                 ctx_rank_threshold: float = 0.05,\n",
    "                 dem_log2fc_thr: float = 0.5,\n",
    "                 dem_motif_hit_thr: float = 3.0,\n",
    "                 dem_max_bg_regions: int = 500,\n",
    "                 annotation : List[str] = ['Direct_annot', 'Orthology_annot'],\n",
    "                 motif_similarity_fdr: float = 0.000001,\n",
    "                 path_to_motif_annotations: str = None,\n",
    "                 annotation_version: str = 'v9',\n",
    "                 n_cpu : int = 1,\n",
    "                 _temp_dir: str = None,\n",
    "                 exclude_motifs: str = None,\n",
    "                 exclude_collection: List[str] = None,\n",
    "                 **kwargs):\n",
    "    # Create logger\n",
    "    level = logging.INFO\n",
    "    log_format = '%(asctime)s %(name)-12s %(levelname)-8s %(message)s'\n",
    "    handlers = [logging.StreamHandler(stream=sys.stdout)]\n",
    "    logging.basicConfig(level=level, format=log_format, handlers=handlers)\n",
    "    log = logging.getLogger('pycisTarget_wrapper')\n",
    "    \n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    check_folder = os.path.isdir(save_path)\n",
    "    if not check_folder:\n",
    "        os.makedirs(save_path)\n",
    "        log.info(\"Created folder : \" + save_path)\n",
    "    else:\n",
    "        log.info(save_path + \" folder already exists.\")\n",
    "        \n",
    "    def get_species_annotation(species: str):\n",
    "        dataset = pbm.Dataset(name=species,  host=biomart_host)\n",
    "        annot = dataset.query(attributes=['chromosome_name', 'transcription_start_site', 'strand', 'external_gene_name', 'transcript_biotype'])\n",
    "        annot.columns = ['Chromosome', 'Start', 'Strand', 'Gene', 'Transcript_type']\n",
    "        annot['Chromosome'] = annot['Chromosome'].astype('str')\n",
    "        filterf = annot['Chromosome'].str.contains('CHR|GL|JH|MT|KI')\n",
    "        annot = annot[~filterf]\n",
    "        annot['Chromosome'] = annot['Chromosome'].replace(r'(\\b\\S)', r'chr\\1')\n",
    "        annot = annot[annot.Transcript_type == 'protein_coding']\n",
    "        annot = annot.dropna(subset = ['Chromosome', 'Start'])\n",
    "        # Check if chromosomes have chr\n",
    "        check = region_sets[list(region_sets.keys())[0]]\n",
    "        if not any(['chr' in c for c in check[list(check.keys())[0]].df['Chromosome']]):\n",
    "            annot.Chromosome = annot.Chromosome.str.replace('chr', '')\n",
    "        if not any(['chr' in x for x in annot.Chromosome]):\n",
    "            annot.Chromosome = [f'chr{x}' for x in annot.Chromosome]\n",
    "        annot_dem=annot.copy()\n",
    "        # Define promoter space\n",
    "        annot['End'] = annot['Start'].astype(int)+promoter_space\n",
    "        annot['Start'] = annot['Start'].astype(int)-promoter_space\n",
    "        annot = pr.PyRanges(annot[['Chromosome', 'Start', 'End']])\n",
    "        return annot, annot_dem\n",
    "        \n",
    "    # Prepare annotation\n",
    "    if species == 'homo_sapiens':\n",
    "        annot, annot_dem = get_species_annotation('hsapiens_gene_ensembl')\n",
    "    elif species == 'mus_musculus':\n",
    "        annot, annot_dem = get_species_annotation('mmusculus_gene_ensembl')\n",
    "    elif species == 'drosophila_melanogaster':\n",
    "        annot, annot_dem = get_species_annotation('dmelanogaster_gene_ensembl')\n",
    "    elif species == 'gallus_gallus':\n",
    "        annot, annot_dem = get_species_annotation('ggallus_gene_ensembl')\n",
    "    elif species == 'custom':\n",
    "        annot_dem = custom_annot\n",
    "        annot = annot_dem.copy()\n",
    "        # Define promoter space\n",
    "        annot['End'] = annot['Start'].astype(int)+promoter_space\n",
    "        annot['Start'] = annot['Start'].astype(int)-promoter_space\n",
    "        annot = pr.PyRanges(annot[['Chromosome', 'Start', 'End']])\n",
    "    else:\n",
    "        raise TypeError(\"Species not recognized\")\n",
    "\n",
    "    menr = {}\n",
    "    for key in region_sets.keys():\n",
    "        if ctx_db_path is not None:\n",
    "            log.info('Loading cisTarget database for ' + key)\n",
    "            ## CISTARGET\n",
    "            regions = region_sets[key]\n",
    "            ctx_db = cisTargetDatabase(ctx_db_path, regions)  \n",
    "            if exclude_motifs is not None:\n",
    "                out = pd.read_csv(exclude_motifs, header=None).iloc[:,0].tolist()\n",
    "                ctx_db.db_rankings = ctx_db.db_rankings.drop(out)\n",
    "            if exclude_collection is not None:\n",
    "                for col in exclude_collection:\n",
    "                    ctx_db.db_rankings = ctx_db.db_rankings[~ctx_db.db_rankings.index.str.contains(col)]\n",
    "            ## DEFAULT\n",
    "            import time\n",
    "            t1_start = time.time()\n",
    "            log.info('Running cisTarget for '+key)\n",
    "            menr['CTX_'+key+'_All'] = run_cistarget(ctx_db = ctx_db,\n",
    "                                   region_sets = regions,\n",
    "                                   specie = species,\n",
    "                                   auc_threshold = ctx_auc_threshold,\n",
    "                                   nes_threshold = ctx_nes_threshold,\n",
    "                                   rank_threshold = ctx_rank_threshold,\n",
    "                                   annotation = annotation,\n",
    "                                   motif_similarity_fdr = motif_similarity_fdr,\n",
    "                                   path_to_motif_annotations = path_to_motif_annotations,\n",
    "                                   n_cpu = n_cpu,\n",
    "                                   _temp_dir= _temp_dir,\n",
    "                                   annotation_version = annotation_version,\n",
    "                                   **kwargs)\n",
    "            m1=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "            t1_stop = time.time()\n",
    "            time_ctx_all = t1_stop-t1_start\n",
    "            out_folder = os.path.join(save_path,'CTX_'+key+'_All')\n",
    "            check_folder = os.path.isdir(out_folder)\n",
    "            if not check_folder:\n",
    "                os.makedirs(out_folder)\n",
    "                log.info(\"Created folder : \" + out_folder)\n",
    "            else:\n",
    "                log.info(out_folder + \" folder already exists.\")\n",
    "            for x in menr['CTX_'+key+'_All'].keys():\n",
    "                out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                menr['CTX_'+key+'_All'][str(x)].motif_enrichment.to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "            if(save_partial):\n",
    "                with open(os.path.join(save_path,'CTX_'+key+'_All' + '.pkl'), 'wb') as f:\n",
    "                    dill.dump(menr['CTX_'+key+'_All'], f, protocol=-1)\n",
    "\n",
    "            if run_without_promoters is True:\n",
    "                ## REMOVE PROMOTERS\n",
    "                log.info('Running cisTarget without promoters for '+key)\n",
    "                regions_overlaps = {key: regions[key].count_overlaps(annot) for key in regions.keys()}\n",
    "                regions_np = {key: regions_overlaps[key][regions_overlaps[key].NumberOverlaps == 0][['Chromosome', 'Start', 'End']] for key in regions.keys()}\n",
    "                db_regions = set(pd.concat([ctx_db.regions_to_db[x] for x in ctx_db.regions_to_db.keys()])['Query'])\n",
    "                ctx_db.regions_to_db = {x: target_to_query(regions_np[x], list(db_regions), fraction_overlap = 0.4) for x in regions_np.keys()}\n",
    "                t1_start = time.time()\n",
    "                menr['CTX_'+key+'_No_promoters'] = run_cistarget(ctx_db = ctx_db,\n",
    "                                   region_sets = regions_np,\n",
    "                                   specie = species,\n",
    "                                   auc_threshold = ctx_auc_threshold,\n",
    "                                   nes_threshold = ctx_nes_threshold,\n",
    "                                   rank_threshold = ctx_rank_threshold,\n",
    "                                   annotation = annotation,\n",
    "                                   motif_similarity_fdr = motif_similarity_fdr, \n",
    "                                   path_to_motif_annotations = path_to_motif_annotations,\n",
    "                                   n_cpu = n_cpu,\n",
    "                                   _temp_dir= _temp_dir,\n",
    "                                   annotation_version = annotation_version,\n",
    "                                   **kwargs)\n",
    "                m2=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "                t1_stop = time.time()\n",
    "                time_ctx_np = t1_stop-t1_start\n",
    "                out_folder = os.path.join(save_path,'CTX_'+key+'_No_promoters')\n",
    "                check_folder = os.path.isdir(out_folder)\n",
    "                if not check_folder:\n",
    "                    os.makedirs(out_folder)\n",
    "                    log.info(\"Created folder:\" + out_folder)\n",
    "                else:\n",
    "                    log.info(out_folder + \" folder already exists.\")\n",
    "                for x in menr['CTX_'+key+'_No_promoters'].keys():\n",
    "                    out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                    menr['CTX_'+key+'_No_promoters'][str(x)].motif_enrichment.to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "                \n",
    "                if(save_partial):\n",
    "                    with open(os.path.join(save_path,'CTX_'+key+'_No_promoters' + '.pkl'), 'wb') as f:\n",
    "                      dill.dump(menr['CTX_'+key+'_No_promoters'], f, protocol=-1)\n",
    "        ## DEM\n",
    "        if dem_db_path is not None:\n",
    "            log.info('Running DEM for '+key)\n",
    "            regions = region_sets[key]\n",
    "            dem_db = DEMDatabase(dem_db_path, regions)  \n",
    "            if exclude_motifs is not None:\n",
    "                out = pd.read_csv(exclude_motifs, header=None).iloc[:,0].tolist()\n",
    "                dem_db.db_scores = dem_db.db_scores.drop(out)\n",
    "            if exclude_collection is not None:\n",
    "                for col in exclude_collection:\n",
    "                    dem_db.db_scores = dem_db.db_scores[~dem_db.db_scores.index.str.contains(col)]\n",
    "            t1_start = time.time()\n",
    "            menr['DEM_'+key+'_All'] = DEM(dem_db = dem_db,\n",
    "                               region_sets = regions,\n",
    "                               log2fc_thr = dem_log2fc_thr,\n",
    "                               motif_hit_thr = dem_motif_hit_thr,\n",
    "                               max_bg_regions = dem_max_bg_regions,\n",
    "                               specie = species,\n",
    "                               genome_annotation = annot_dem,\n",
    "                               promoter_space = promoter_space,\n",
    "                               motif_annotation =   annotation,\n",
    "                               motif_similarity_fdr = motif_similarity_fdr, \n",
    "                               path_to_motif_annotations = path_to_motif_annotations,\n",
    "                               n_cpu = n_cpu,\n",
    "                               annotation_version = annotation_version,\n",
    "                               tmp_dir = save_path,\n",
    "                               _temp_dir= _temp_dir,\n",
    "                               **kwargs)\n",
    "            m3=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "            t1_stop = time.time()\n",
    "            time_dem_all = t1_stop-t1_start\n",
    "            out_folder = os.path.join(save_path,'DEM_'+key+'_All')\n",
    "            check_folder = os.path.isdir(out_folder)\n",
    "            if not check_folder:\n",
    "                os.makedirs(out_folder)\n",
    "                log.info(\"Created folder : \"+ out_folder)\n",
    "            else:\n",
    "                log.info(out_folder + \" folder already exists.\")\n",
    "            for x in menr['DEM_'+key+'_All'].motif_enrichment.keys():\n",
    "                out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                menr['DEM_'+key+'_All'].motif_enrichment[str(x)].to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "            if(save_partial):\n",
    "                with open(os.path.join(save_path, 'DEM_'+key+'_All'+'.pkl'), 'wb') as f:\n",
    "                  dill.dump(menr['DEM_'+key+'_All'], f, protocol=-1)\n",
    "                \n",
    "            if run_without_promoters is True:\n",
    "                log.info('Running DEM without promoters for '+key)\n",
    "                ## REMOVE PROMOTERS\n",
    "                regions_overlaps = {key: regions[key].count_overlaps(annot) for key in regions.keys()}\n",
    "                regions_np = {key: regions_overlaps[key][regions_overlaps[key].NumberOverlaps == 0][['Chromosome', 'Start', 'End']] for key in regions.keys()}\n",
    "                db_regions = set(pd.concat([dem_db.regions_to_db[x] for x in dem_db.regions_to_db.keys()])['Query'])\n",
    "                dem_db.regions_to_db = {x: target_to_query(regions_np[x], list(db_regions), fraction_overlap = 0.4) for x in regions_np.keys()}\n",
    "                t1_start = time.time()\n",
    "                menr['DEM_'+key+'_No_promoters'] = DEM(dem_db = dem_db,\n",
    "                               region_sets = regions_np,\n",
    "                               log2fc_thr = dem_log2fc_thr,\n",
    "                               motif_hit_thr = dem_motif_hit_thr,\n",
    "                               max_bg_regions = dem_max_bg_regions,\n",
    "                               specie = species,\n",
    "                               promoter_space = promoter_space,\n",
    "                               motif_annotation = annotation,\n",
    "                               motif_similarity_fdr = motif_similarity_fdr, \n",
    "                               path_to_motif_annotations = path_to_motif_annotations,\n",
    "                               n_cpu = n_cpu,\n",
    "                               annotation_version = annotation_version,\n",
    "                               tmp_dir = save_path,\n",
    "                               _temp_dir= _temp_dir,\n",
    "                               **kwargs)\n",
    "                m4=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "                t1_stop = time.time()\n",
    "                time_dem_np = t1_stop-t1_start\n",
    "                out_folder = os.path.join(save_path,'DEM_'+key+'_No_promoters')\n",
    "                check_folder = os.path.isdir(out_folder)\n",
    "                if not check_folder:\n",
    "                    os.makedirs(out_folder)\n",
    "                    log.info(\"Created folder : \"+ out_folder)\n",
    "                else:\n",
    "                    log.info(out_folder + \" folder already exists.\")\n",
    "                for x in menr['DEM_'+key+'_No_promoters'].motif_enrichment.keys():\n",
    "                    out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                    menr['DEM_'+key+'_No_promoters'].motif_enrichment[str(x)].to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "                if(save_partial):\n",
    "                    with open(os.path.join(save_path, 'DEM_'+key+'_No_promoters'+'.pkl'), 'wb') as f:\n",
    "                      dill.dump(menr['DEM_'+key+'_All'], f, protocol=-1)\n",
    "                    \n",
    "        times = [time_ctx_all, time_ctx_np, time_dem_all, time_dem_np]\n",
    "        df = pd.DataFrame(times, index=['CTX_all', 'CTX_np', 'DEM_all', 'DEM_np'], columns=['Time'])\n",
    "        df.to_csv(save_path+key+'running_times.tsv', sep='\\t') \n",
    "        memory=[m1,m2,m3,m4]\n",
    "        df = pd.DataFrame(memory, index=['CTX_all', 'CTX_np', 'DEM_all', 'DEM_np'], columns=['Memory'])\n",
    "        df.to_csv(save_path+key+'cummulative_memory.tsv', sep='\\t')  \n",
    "        memory=[m1,m2-m1,m3-m2,m4-m3]\n",
    "        df = pd.DataFrame(memory, index=['CTX_all', 'CTX_np', 'DEM_all', 'DEM_np'], columns=['Memory'])\n",
    "        df.to_csv(save_path+key+'memory_per_step.tsv', sep='\\t')  \n",
    "                    \n",
    "    log.info('Saving object')         \n",
    "    with open(os.path.join(save_path,'menr.pkl'), 'wb') as f:\n",
    "        dill.dump(menr, f, protocol=-1)\n",
    "    \n",
    "    import time\n",
    "    log.info('Finished! Took {} minutes'.format((time.time() - start_time)/60)) \n",
    "            \n",
    "# Load region binarized topics\n",
    "import pickle\n",
    "outDir = '/staging/leuven/stg_00002/lcb/cbravo/Multiomics_pipeline/analysis/DPCL/speed_benchmark/low_simulation/DPCL_cisTopicObject_3K_fragments_1K_cells/'\n",
    "infile = open(outDir+'binarized_topic_region.pkl', 'rb')\n",
    "binarized_topic_region = pickle.load(infile)\n",
    "infile.close()\n",
    "# Load DARs\n",
    "import pickle\n",
    "infile = open(outDir+'DARs.pkl', 'rb')\n",
    "DARs_dict = pickle.load(infile)\n",
    "infile.close()\n",
    "# Format region sets\n",
    "import re\n",
    "import pyranges as pr\n",
    "from pycistarget.utils import *\n",
    "region_sets = {}\n",
    "region_sets['Topics'] = {key: pr.PyRanges(region_names_to_coordinates(binarized_topic_region[key].index.tolist())) for key in binarized_topic_region.keys()}\n",
    "region_sets['DARs'] = {re.sub('[^A-Za-z0-9]+', '_', key): pr.PyRanges(region_names_to_coordinates(DARs_dict[key].index.tolist())) for key in DARs_dict.keys()}\n",
    "# Create save_path\n",
    "save_path = outDir + 'pycistarget/'\n",
    "# Create save_Dir\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "\n",
    "# Run pycistarget\n",
    "run_pycistarget(region_sets,\n",
    "                 ctx_db_path = '/staging/leuven/stg_00002/lcb/cbravo/Multiomics_pipeline/analysis/DPCL/ctx_db/cluster_V10_DPCL_feather_v2.regions_vs_motifs.rankings.feather',\n",
    "                 species = 'homo_sapiens',\n",
    "                 save_path = save_path,\n",
    "                 dem_db_path = '/staging/leuven/stg_00002/lcb/cbravo/Multiomics_pipeline/analysis/DPCL/ctx_db/cluster_V10_DPCL_feather_v2.regions_vs_motifs.scores.feather',\n",
    "                 run_without_promoters = True,\n",
    "                 biomart_host = 'http://www.ensembl.org',\n",
    "                 promoter_space = 500,\n",
    "                 ctx_auc_threshold = 0.005,\n",
    "                 ctx_nes_threshold = 3.0,\n",
    "                 ctx_rank_threshold = 0.05,\n",
    "                 dem_log2fc_thr = 0.5,\n",
    "                 dem_motif_hit_thr = 3.0,\n",
    "                 dem_max_bg_regions = 500,\n",
    "                 path_to_motif_annotations = '/staging/leuven/stg_00002/lcb/cbravo/cluster_motif_collection_V10_no_desso_no_factorbook/snapshots/motifs-v10nr_clust-nr.mgi-m0.00001-o0.0.tbl',\n",
    "                 annotation_version = 'v10nr_clust',\n",
    "                 annotation = ['Direct_annot', 'Orthology_annot'],\n",
    "                 n_cpu = 8,\n",
    "                 _temp_dir = '/scratch/leuven/313/vsc31305/ray_spill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce88e07-69ae-43fe-9c86-a6837d56ab5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --partition=batch\n",
    "#SBATCH --cluster wice\n",
    "#SBATCH --account lp_wice_pilot\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=carmen.bravogonzalezblas@kuleuven.be\n",
    "#SBATCH --ntasks=1\n",
    "\n",
    "#SBATCH --cpus-per-task=20\n",
    "#SBATCH --time=3:00:00\n",
    "#SBATCH --mem=180G\n",
    "\n",
    "#SBATCH --job-name=DPCL_cisTopicObject_3K_fragments_1K_cells\n",
    "#SBATCH --output=DPCL_cisTopicObject_3K_fragments_1K_cells.out\n",
    "#SBATCH --error=DPCL_cisTopicObject_3K_fragments_1K_cells.err\n",
    "\n",
    "singularity exec -B /lustre1,/staging,/data,/vsc-hard-mounts,/scratch,/local_scratch /data/leuven/software/biomed/singularity_images/scenicplus/scenicplus.sif python DPCL_cisTopicObject_3K_fragments_1K_cells.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4779857-fc56-44be-8a5d-3cae810bac00",
   "metadata": {},
   "source": [
    "# DPCL_cisTopicObject_3K_fragments_10K_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0de664-e51d-4631-8d2b-dc5492f18c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import pandas as pd\n",
    "import dill\n",
    "import pyranges as pr\n",
    "from pycistarget.motif_enrichment_cistarget import *\n",
    "from pycistarget.motif_enrichment_dem import *\n",
    "from pycistarget.utils import *\n",
    "import pybiomart as pbm\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "def run_pycistarget(region_sets: Dict[str, pr.PyRanges],\n",
    "                 species: str,\n",
    "                 save_path: str,\n",
    "                 custom_annot: pd.DataFrame = None,\n",
    "                 save_partial: bool = False,\n",
    "                 ctx_db_path: str = None,\n",
    "                 dem_db_path: str = None,\n",
    "                 run_without_promoters: bool = False,\n",
    "                 biomart_host: str = 'http://www.ensembl.org',\n",
    "                 promoter_space: int = 500,\n",
    "                 ctx_auc_threshold: float = 0.005,\n",
    "                 ctx_nes_threshold: float = 3.0,\n",
    "                 ctx_rank_threshold: float = 0.05,\n",
    "                 dem_log2fc_thr: float = 0.5,\n",
    "                 dem_motif_hit_thr: float = 3.0,\n",
    "                 dem_max_bg_regions: int = 500,\n",
    "                 annotation : List[str] = ['Direct_annot', 'Orthology_annot'],\n",
    "                 motif_similarity_fdr: float = 0.000001,\n",
    "                 path_to_motif_annotations: str = None,\n",
    "                 annotation_version: str = 'v9',\n",
    "                 n_cpu : int = 1,\n",
    "                 _temp_dir: str = None,\n",
    "                 exclude_motifs: str = None,\n",
    "                 exclude_collection: List[str] = None,\n",
    "                 **kwargs):\n",
    "    # Create logger\n",
    "    level = logging.INFO\n",
    "    log_format = '%(asctime)s %(name)-12s %(levelname)-8s %(message)s'\n",
    "    handlers = [logging.StreamHandler(stream=sys.stdout)]\n",
    "    logging.basicConfig(level=level, format=log_format, handlers=handlers)\n",
    "    log = logging.getLogger('pycisTarget_wrapper')\n",
    "    \n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    check_folder = os.path.isdir(save_path)\n",
    "    if not check_folder:\n",
    "        os.makedirs(save_path)\n",
    "        log.info(\"Created folder : \" + save_path)\n",
    "    else:\n",
    "        log.info(save_path + \" folder already exists.\")\n",
    "        \n",
    "    def get_species_annotation(species: str):\n",
    "        dataset = pbm.Dataset(name=species,  host=biomart_host)\n",
    "        annot = dataset.query(attributes=['chromosome_name', 'transcription_start_site', 'strand', 'external_gene_name', 'transcript_biotype'])\n",
    "        annot.columns = ['Chromosome', 'Start', 'Strand', 'Gene', 'Transcript_type']\n",
    "        annot['Chromosome'] = annot['Chromosome'].astype('str')\n",
    "        filterf = annot['Chromosome'].str.contains('CHR|GL|JH|MT|KI')\n",
    "        annot = annot[~filterf]\n",
    "        annot['Chromosome'] = annot['Chromosome'].replace(r'(\\b\\S)', r'chr\\1')\n",
    "        annot = annot[annot.Transcript_type == 'protein_coding']\n",
    "        annot = annot.dropna(subset = ['Chromosome', 'Start'])\n",
    "        # Check if chromosomes have chr\n",
    "        check = region_sets[list(region_sets.keys())[0]]\n",
    "        if not any(['chr' in c for c in check[list(check.keys())[0]].df['Chromosome']]):\n",
    "            annot.Chromosome = annot.Chromosome.str.replace('chr', '')\n",
    "        if not any(['chr' in x for x in annot.Chromosome]):\n",
    "            annot.Chromosome = [f'chr{x}' for x in annot.Chromosome]\n",
    "        annot_dem=annot.copy()\n",
    "        # Define promoter space\n",
    "        annot['End'] = annot['Start'].astype(int)+promoter_space\n",
    "        annot['Start'] = annot['Start'].astype(int)-promoter_space\n",
    "        annot = pr.PyRanges(annot[['Chromosome', 'Start', 'End']])\n",
    "        return annot, annot_dem\n",
    "        \n",
    "    # Prepare annotation\n",
    "    if species == 'homo_sapiens':\n",
    "        annot, annot_dem = get_species_annotation('hsapiens_gene_ensembl')\n",
    "    elif species == 'mus_musculus':\n",
    "        annot, annot_dem = get_species_annotation('mmusculus_gene_ensembl')\n",
    "    elif species == 'drosophila_melanogaster':\n",
    "        annot, annot_dem = get_species_annotation('dmelanogaster_gene_ensembl')\n",
    "    elif species == 'gallus_gallus':\n",
    "        annot, annot_dem = get_species_annotation('ggallus_gene_ensembl')\n",
    "    elif species == 'custom':\n",
    "        annot_dem = custom_annot\n",
    "        annot = annot_dem.copy()\n",
    "        # Define promoter space\n",
    "        annot['End'] = annot['Start'].astype(int)+promoter_space\n",
    "        annot['Start'] = annot['Start'].astype(int)-promoter_space\n",
    "        annot = pr.PyRanges(annot[['Chromosome', 'Start', 'End']])\n",
    "    else:\n",
    "        raise TypeError(\"Species not recognized\")\n",
    "\n",
    "    menr = {}\n",
    "    for key in region_sets.keys():\n",
    "        if ctx_db_path is not None:\n",
    "            log.info('Loading cisTarget database for ' + key)\n",
    "            ## CISTARGET\n",
    "            regions = region_sets[key]\n",
    "            ctx_db = cisTargetDatabase(ctx_db_path, regions)  \n",
    "            if exclude_motifs is not None:\n",
    "                out = pd.read_csv(exclude_motifs, header=None).iloc[:,0].tolist()\n",
    "                ctx_db.db_rankings = ctx_db.db_rankings.drop(out)\n",
    "            if exclude_collection is not None:\n",
    "                for col in exclude_collection:\n",
    "                    ctx_db.db_rankings = ctx_db.db_rankings[~ctx_db.db_rankings.index.str.contains(col)]\n",
    "            ## DEFAULT\n",
    "            import time\n",
    "            t1_start = time.time()\n",
    "            log.info('Running cisTarget for '+key)\n",
    "            menr['CTX_'+key+'_All'] = run_cistarget(ctx_db = ctx_db,\n",
    "                                   region_sets = regions,\n",
    "                                   specie = species,\n",
    "                                   auc_threshold = ctx_auc_threshold,\n",
    "                                   nes_threshold = ctx_nes_threshold,\n",
    "                                   rank_threshold = ctx_rank_threshold,\n",
    "                                   annotation = annotation,\n",
    "                                   motif_similarity_fdr = motif_similarity_fdr,\n",
    "                                   path_to_motif_annotations = path_to_motif_annotations,\n",
    "                                   n_cpu = n_cpu,\n",
    "                                   _temp_dir= _temp_dir,\n",
    "                                   annotation_version = annotation_version,\n",
    "                                   **kwargs)\n",
    "            m1=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "            t1_stop = time.time()\n",
    "            time_ctx_all = t1_stop-t1_start\n",
    "            out_folder = os.path.join(save_path,'CTX_'+key+'_All')\n",
    "            check_folder = os.path.isdir(out_folder)\n",
    "            if not check_folder:\n",
    "                os.makedirs(out_folder)\n",
    "                log.info(\"Created folder : \" + out_folder)\n",
    "            else:\n",
    "                log.info(out_folder + \" folder already exists.\")\n",
    "            for x in menr['CTX_'+key+'_All'].keys():\n",
    "                out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                menr['CTX_'+key+'_All'][str(x)].motif_enrichment.to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "            if(save_partial):\n",
    "                with open(os.path.join(save_path,'CTX_'+key+'_All' + '.pkl'), 'wb') as f:\n",
    "                    dill.dump(menr['CTX_'+key+'_All'], f, protocol=-1)\n",
    "\n",
    "            if run_without_promoters is True:\n",
    "                ## REMOVE PROMOTERS\n",
    "                log.info('Running cisTarget without promoters for '+key)\n",
    "                regions_overlaps = {key: regions[key].count_overlaps(annot) for key in regions.keys()}\n",
    "                regions_np = {key: regions_overlaps[key][regions_overlaps[key].NumberOverlaps == 0][['Chromosome', 'Start', 'End']] for key in regions.keys()}\n",
    "                db_regions = set(pd.concat([ctx_db.regions_to_db[x] for x in ctx_db.regions_to_db.keys()])['Query'])\n",
    "                ctx_db.regions_to_db = {x: target_to_query(regions_np[x], list(db_regions), fraction_overlap = 0.4) for x in regions_np.keys()}\n",
    "                t1_start = time.time()\n",
    "                menr['CTX_'+key+'_No_promoters'] = run_cistarget(ctx_db = ctx_db,\n",
    "                                   region_sets = regions_np,\n",
    "                                   specie = species,\n",
    "                                   auc_threshold = ctx_auc_threshold,\n",
    "                                   nes_threshold = ctx_nes_threshold,\n",
    "                                   rank_threshold = ctx_rank_threshold,\n",
    "                                   annotation = annotation,\n",
    "                                   motif_similarity_fdr = motif_similarity_fdr, \n",
    "                                   path_to_motif_annotations = path_to_motif_annotations,\n",
    "                                   n_cpu = n_cpu,\n",
    "                                   _temp_dir= _temp_dir,\n",
    "                                   annotation_version = annotation_version,\n",
    "                                   **kwargs)\n",
    "                m2=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "                t1_stop = time.time()\n",
    "                time_ctx_np = t1_stop-t1_start\n",
    "                out_folder = os.path.join(save_path,'CTX_'+key+'_No_promoters')\n",
    "                check_folder = os.path.isdir(out_folder)\n",
    "                if not check_folder:\n",
    "                    os.makedirs(out_folder)\n",
    "                    log.info(\"Created folder:\" + out_folder)\n",
    "                else:\n",
    "                    log.info(out_folder + \" folder already exists.\")\n",
    "                for x in menr['CTX_'+key+'_No_promoters'].keys():\n",
    "                    out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                    menr['CTX_'+key+'_No_promoters'][str(x)].motif_enrichment.to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "                \n",
    "                if(save_partial):\n",
    "                    with open(os.path.join(save_path,'CTX_'+key+'_No_promoters' + '.pkl'), 'wb') as f:\n",
    "                      dill.dump(menr['CTX_'+key+'_No_promoters'], f, protocol=-1)\n",
    "        ## DEM\n",
    "        if dem_db_path is not None:\n",
    "            log.info('Running DEM for '+key)\n",
    "            regions = region_sets[key]\n",
    "            dem_db = DEMDatabase(dem_db_path, regions)  \n",
    "            if exclude_motifs is not None:\n",
    "                out = pd.read_csv(exclude_motifs, header=None).iloc[:,0].tolist()\n",
    "                dem_db.db_scores = dem_db.db_scores.drop(out)\n",
    "            if exclude_collection is not None:\n",
    "                for col in exclude_collection:\n",
    "                    dem_db.db_scores = dem_db.db_scores[~dem_db.db_scores.index.str.contains(col)]\n",
    "            t1_start = time.time()\n",
    "            menr['DEM_'+key+'_All'] = DEM(dem_db = dem_db,\n",
    "                               region_sets = regions,\n",
    "                               log2fc_thr = dem_log2fc_thr,\n",
    "                               motif_hit_thr = dem_motif_hit_thr,\n",
    "                               max_bg_regions = dem_max_bg_regions,\n",
    "                               specie = species,\n",
    "                               genome_annotation = annot_dem,\n",
    "                               promoter_space = promoter_space,\n",
    "                               motif_annotation =   annotation,\n",
    "                               motif_similarity_fdr = motif_similarity_fdr, \n",
    "                               path_to_motif_annotations = path_to_motif_annotations,\n",
    "                               n_cpu = n_cpu,\n",
    "                               annotation_version = annotation_version,\n",
    "                               tmp_dir = save_path,\n",
    "                               _temp_dir= _temp_dir,\n",
    "                               **kwargs)\n",
    "            m3=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "            t1_stop = time.time()\n",
    "            time_dem_all = t1_stop-t1_start\n",
    "            out_folder = os.path.join(save_path,'DEM_'+key+'_All')\n",
    "            check_folder = os.path.isdir(out_folder)\n",
    "            if not check_folder:\n",
    "                os.makedirs(out_folder)\n",
    "                log.info(\"Created folder : \"+ out_folder)\n",
    "            else:\n",
    "                log.info(out_folder + \" folder already exists.\")\n",
    "            for x in menr['DEM_'+key+'_All'].motif_enrichment.keys():\n",
    "                out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                menr['DEM_'+key+'_All'].motif_enrichment[str(x)].to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "            if(save_partial):\n",
    "                with open(os.path.join(save_path, 'DEM_'+key+'_All'+'.pkl'), 'wb') as f:\n",
    "                  dill.dump(menr['DEM_'+key+'_All'], f, protocol=-1)\n",
    "                \n",
    "            if run_without_promoters is True:\n",
    "                log.info('Running DEM without promoters for '+key)\n",
    "                ## REMOVE PROMOTERS\n",
    "                regions_overlaps = {key: regions[key].count_overlaps(annot) for key in regions.keys()}\n",
    "                regions_np = {key: regions_overlaps[key][regions_overlaps[key].NumberOverlaps == 0][['Chromosome', 'Start', 'End']] for key in regions.keys()}\n",
    "                db_regions = set(pd.concat([dem_db.regions_to_db[x] for x in dem_db.regions_to_db.keys()])['Query'])\n",
    "                dem_db.regions_to_db = {x: target_to_query(regions_np[x], list(db_regions), fraction_overlap = 0.4) for x in regions_np.keys()}\n",
    "                t1_start = time.time()\n",
    "                menr['DEM_'+key+'_No_promoters'] = DEM(dem_db = dem_db,\n",
    "                               region_sets = regions_np,\n",
    "                               log2fc_thr = dem_log2fc_thr,\n",
    "                               motif_hit_thr = dem_motif_hit_thr,\n",
    "                               max_bg_regions = dem_max_bg_regions,\n",
    "                               specie = species,\n",
    "                               promoter_space = promoter_space,\n",
    "                               motif_annotation = annotation,\n",
    "                               motif_similarity_fdr = motif_similarity_fdr, \n",
    "                               path_to_motif_annotations = path_to_motif_annotations,\n",
    "                               n_cpu = n_cpu,\n",
    "                               annotation_version = annotation_version,\n",
    "                               tmp_dir = save_path,\n",
    "                               _temp_dir= _temp_dir,\n",
    "                               **kwargs)\n",
    "                m4=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "                t1_stop = time.time()\n",
    "                time_dem_np = t1_stop-t1_start\n",
    "                out_folder = os.path.join(save_path,'DEM_'+key+'_No_promoters')\n",
    "                check_folder = os.path.isdir(out_folder)\n",
    "                if not check_folder:\n",
    "                    os.makedirs(out_folder)\n",
    "                    log.info(\"Created folder : \"+ out_folder)\n",
    "                else:\n",
    "                    log.info(out_folder + \" folder already exists.\")\n",
    "                for x in menr['DEM_'+key+'_No_promoters'].motif_enrichment.keys():\n",
    "                    out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                    menr['DEM_'+key+'_No_promoters'].motif_enrichment[str(x)].to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "                if(save_partial):\n",
    "                    with open(os.path.join(save_path, 'DEM_'+key+'_No_promoters'+'.pkl'), 'wb') as f:\n",
    "                      dill.dump(menr['DEM_'+key+'_All'], f, protocol=-1)\n",
    "                    \n",
    "        times = [time_ctx_all, time_ctx_np, time_dem_all, time_dem_np]\n",
    "        df = pd.DataFrame(times, index=['CTX_all', 'CTX_np', 'DEM_all', 'DEM_np'], columns=['Time'])\n",
    "        df.to_csv(save_path+key+'running_times.tsv', sep='\\t') \n",
    "        memory=[m1,m2,m3,m4]\n",
    "        df = pd.DataFrame(memory, index=['CTX_all', 'CTX_np', 'DEM_all', 'DEM_np'], columns=['Memory'])\n",
    "        df.to_csv(save_path+key+'cummulative_memory.tsv', sep='\\t')  \n",
    "        memory=[m1,m2-m1,m3-m2,m4-m3]\n",
    "        df = pd.DataFrame(memory, index=['CTX_all', 'CTX_np', 'DEM_all', 'DEM_np'], columns=['Memory'])\n",
    "        df.to_csv(save_path+key+'memory_per_step.tsv', sep='\\t')  \n",
    "                    \n",
    "    log.info('Saving object')         \n",
    "    with open(os.path.join(save_path,'menr.pkl'), 'wb') as f:\n",
    "        dill.dump(menr, f, protocol=-1)\n",
    "    \n",
    "    import time\n",
    "    log.info('Finished! Took {} minutes'.format((time.time() - start_time)/60)) \n",
    "            \n",
    "# Load region binarized topics\n",
    "import pickle\n",
    "outDir = '/staging/leuven/stg_00002/lcb/cbravo/Multiomics_pipeline/analysis/DPCL/speed_benchmark/low_simulation/DPCL_cisTopicObject_3K_fragments_10K_cells/'\n",
    "infile = open(outDir+'binarized_topic_region.pkl', 'rb')\n",
    "binarized_topic_region = pickle.load(infile)\n",
    "infile.close()\n",
    "# Load DARs\n",
    "import pickle\n",
    "infile = open(outDir+'DARs.pkl', 'rb')\n",
    "DARs_dict = pickle.load(infile)\n",
    "infile.close()\n",
    "# Format region sets\n",
    "import re\n",
    "import pyranges as pr\n",
    "from pycistarget.utils import *\n",
    "region_sets = {}\n",
    "region_sets['Topics'] = {key: pr.PyRanges(region_names_to_coordinates(binarized_topic_region[key].index.tolist())) for key in binarized_topic_region.keys()}\n",
    "region_sets['DARs'] = {re.sub('[^A-Za-z0-9]+', '_', key): pr.PyRanges(region_names_to_coordinates(DARs_dict[key].index.tolist())) for key in DARs_dict.keys()}\n",
    "# Create save_path\n",
    "save_path = outDir + 'pycistarget/'\n",
    "# Create save_Dir\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "\n",
    "# Run pycistarget\n",
    "run_pycistarget(region_sets,\n",
    "                 ctx_db_path = '/staging/leuven/stg_00002/lcb/cbravo/Multiomics_pipeline/analysis/DPCL/ctx_db/cluster_V10_DPCL_feather_v2.regions_vs_motifs.rankings.feather',\n",
    "                 species = 'homo_sapiens',\n",
    "                 save_path = save_path,\n",
    "                 dem_db_path = '/staging/leuven/stg_00002/lcb/cbravo/Multiomics_pipeline/analysis/DPCL/ctx_db/cluster_V10_DPCL_feather_v2.regions_vs_motifs.scores.feather',\n",
    "                 run_without_promoters = True,\n",
    "                 biomart_host = 'http://www.ensembl.org',\n",
    "                 promoter_space = 500,\n",
    "                 ctx_auc_threshold = 0.005,\n",
    "                 ctx_nes_threshold = 3.0,\n",
    "                 ctx_rank_threshold = 0.05,\n",
    "                 dem_log2fc_thr = 0.5,\n",
    "                 dem_motif_hit_thr = 3.0,\n",
    "                 dem_max_bg_regions = 500,\n",
    "                 path_to_motif_annotations = '/staging/leuven/stg_00002/lcb/cbravo/cluster_motif_collection_V10_no_desso_no_factorbook/snapshots/motifs-v10nr_clust-nr.mgi-m0.00001-o0.0.tbl',\n",
    "                 annotation_version = 'v10nr_clust',\n",
    "                 annotation = ['Direct_annot', 'Orthology_annot'],\n",
    "                 n_cpu = 8,\n",
    "                 _temp_dir = '/scratch/leuven/313/vsc31305/ray_spill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aefadf-7f18-4f5b-bc8b-b9dbc1914130",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --partition=batch\n",
    "#SBATCH --cluster wice\n",
    "#SBATCH --account lp_wice_pilot\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=carmen.bravogonzalezblas@kuleuven.be\n",
    "#SBATCH --ntasks=1\n",
    "\n",
    "#SBATCH --cpus-per-task=20\n",
    "#SBATCH --time=3:00:00\n",
    "#SBATCH --mem=180G\n",
    "\n",
    "#SBATCH --job-name=DPCL_cisTopicObject_3K_fragments_10K_cells\n",
    "#SBATCH --output=DPCL_cisTopicObject_3K_fragments_10K_cells.out\n",
    "#SBATCH --error=DPCL_cisTopicObject_3K_fragments_10K_cells.err\n",
    "\n",
    "singularity exec -B /lustre1,/staging,/data,/vsc-hard-mounts,/scratch,/local_scratch /data/leuven/software/biomed/singularity_images/scenicplus/scenicplus.sif python DPCL_cisTopicObject_3K_fragments_10K_cells.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c96cf15-dea5-40c4-90da-08fdc62275ed",
   "metadata": {},
   "source": [
    "# DPCL_cisTopicObject_3K_fragments_25K_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715c2331-653c-4445-b69e-7d8ea1f8a3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import pandas as pd\n",
    "import dill\n",
    "import pyranges as pr\n",
    "from pycistarget.motif_enrichment_cistarget import *\n",
    "from pycistarget.motif_enrichment_dem import *\n",
    "from pycistarget.utils import *\n",
    "import pybiomart as pbm\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "def run_pycistarget(region_sets: Dict[str, pr.PyRanges],\n",
    "                 species: str,\n",
    "                 save_path: str,\n",
    "                 custom_annot: pd.DataFrame = None,\n",
    "                 save_partial: bool = False,\n",
    "                 ctx_db_path: str = None,\n",
    "                 dem_db_path: str = None,\n",
    "                 run_without_promoters: bool = False,\n",
    "                 biomart_host: str = 'http://www.ensembl.org',\n",
    "                 promoter_space: int = 500,\n",
    "                 ctx_auc_threshold: float = 0.005,\n",
    "                 ctx_nes_threshold: float = 3.0,\n",
    "                 ctx_rank_threshold: float = 0.05,\n",
    "                 dem_log2fc_thr: float = 0.5,\n",
    "                 dem_motif_hit_thr: float = 3.0,\n",
    "                 dem_max_bg_regions: int = 500,\n",
    "                 annotation : List[str] = ['Direct_annot', 'Orthology_annot'],\n",
    "                 motif_similarity_fdr: float = 0.000001,\n",
    "                 path_to_motif_annotations: str = None,\n",
    "                 annotation_version: str = 'v9',\n",
    "                 n_cpu : int = 1,\n",
    "                 _temp_dir: str = None,\n",
    "                 exclude_motifs: str = None,\n",
    "                 exclude_collection: List[str] = None,\n",
    "                 **kwargs):\n",
    "    # Create logger\n",
    "    level = logging.INFO\n",
    "    log_format = '%(asctime)s %(name)-12s %(levelname)-8s %(message)s'\n",
    "    handlers = [logging.StreamHandler(stream=sys.stdout)]\n",
    "    logging.basicConfig(level=level, format=log_format, handlers=handlers)\n",
    "    log = logging.getLogger('pycisTarget_wrapper')\n",
    "    \n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    check_folder = os.path.isdir(save_path)\n",
    "    if not check_folder:\n",
    "        os.makedirs(save_path)\n",
    "        log.info(\"Created folder : \" + save_path)\n",
    "    else:\n",
    "        log.info(save_path + \" folder already exists.\")\n",
    "        \n",
    "    def get_species_annotation(species: str):\n",
    "        dataset = pbm.Dataset(name=species,  host=biomart_host)\n",
    "        annot = dataset.query(attributes=['chromosome_name', 'transcription_start_site', 'strand', 'external_gene_name', 'transcript_biotype'])\n",
    "        annot.columns = ['Chromosome', 'Start', 'Strand', 'Gene', 'Transcript_type']\n",
    "        annot['Chromosome'] = annot['Chromosome'].astype('str')\n",
    "        filterf = annot['Chromosome'].str.contains('CHR|GL|JH|MT|KI')\n",
    "        annot = annot[~filterf]\n",
    "        annot['Chromosome'] = annot['Chromosome'].replace(r'(\\b\\S)', r'chr\\1')\n",
    "        annot = annot[annot.Transcript_type == 'protein_coding']\n",
    "        annot = annot.dropna(subset = ['Chromosome', 'Start'])\n",
    "        # Check if chromosomes have chr\n",
    "        check = region_sets[list(region_sets.keys())[0]]\n",
    "        if not any(['chr' in c for c in check[list(check.keys())[0]].df['Chromosome']]):\n",
    "            annot.Chromosome = annot.Chromosome.str.replace('chr', '')\n",
    "        if not any(['chr' in x for x in annot.Chromosome]):\n",
    "            annot.Chromosome = [f'chr{x}' for x in annot.Chromosome]\n",
    "        annot_dem=annot.copy()\n",
    "        # Define promoter space\n",
    "        annot['End'] = annot['Start'].astype(int)+promoter_space\n",
    "        annot['Start'] = annot['Start'].astype(int)-promoter_space\n",
    "        annot = pr.PyRanges(annot[['Chromosome', 'Start', 'End']])\n",
    "        return annot, annot_dem\n",
    "        \n",
    "    # Prepare annotation\n",
    "    if species == 'homo_sapiens':\n",
    "        annot, annot_dem = get_species_annotation('hsapiens_gene_ensembl')\n",
    "    elif species == 'mus_musculus':\n",
    "        annot, annot_dem = get_species_annotation('mmusculus_gene_ensembl')\n",
    "    elif species == 'drosophila_melanogaster':\n",
    "        annot, annot_dem = get_species_annotation('dmelanogaster_gene_ensembl')\n",
    "    elif species == 'gallus_gallus':\n",
    "        annot, annot_dem = get_species_annotation('ggallus_gene_ensembl')\n",
    "    elif species == 'custom':\n",
    "        annot_dem = custom_annot\n",
    "        annot = annot_dem.copy()\n",
    "        # Define promoter space\n",
    "        annot['End'] = annot['Start'].astype(int)+promoter_space\n",
    "        annot['Start'] = annot['Start'].astype(int)-promoter_space\n",
    "        annot = pr.PyRanges(annot[['Chromosome', 'Start', 'End']])\n",
    "    else:\n",
    "        raise TypeError(\"Species not recognized\")\n",
    "\n",
    "    menr = {}\n",
    "    for key in region_sets.keys():\n",
    "        if ctx_db_path is not None:\n",
    "            log.info('Loading cisTarget database for ' + key)\n",
    "            ## CISTARGET\n",
    "            regions = region_sets[key]\n",
    "            ctx_db = cisTargetDatabase(ctx_db_path, regions)  \n",
    "            if exclude_motifs is not None:\n",
    "                out = pd.read_csv(exclude_motifs, header=None).iloc[:,0].tolist()\n",
    "                ctx_db.db_rankings = ctx_db.db_rankings.drop(out)\n",
    "            if exclude_collection is not None:\n",
    "                for col in exclude_collection:\n",
    "                    ctx_db.db_rankings = ctx_db.db_rankings[~ctx_db.db_rankings.index.str.contains(col)]\n",
    "            ## DEFAULT\n",
    "            import time\n",
    "            t1_start = time.time()\n",
    "            log.info('Running cisTarget for '+key)\n",
    "            menr['CTX_'+key+'_All'] = run_cistarget(ctx_db = ctx_db,\n",
    "                                   region_sets = regions,\n",
    "                                   specie = species,\n",
    "                                   auc_threshold = ctx_auc_threshold,\n",
    "                                   nes_threshold = ctx_nes_threshold,\n",
    "                                   rank_threshold = ctx_rank_threshold,\n",
    "                                   annotation = annotation,\n",
    "                                   motif_similarity_fdr = motif_similarity_fdr,\n",
    "                                   path_to_motif_annotations = path_to_motif_annotations,\n",
    "                                   n_cpu = n_cpu,\n",
    "                                   _temp_dir= _temp_dir,\n",
    "                                   annotation_version = annotation_version,\n",
    "                                   **kwargs)\n",
    "            m1=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "            t1_stop = time.time()\n",
    "            time_ctx_all = t1_stop-t1_start\n",
    "            out_folder = os.path.join(save_path,'CTX_'+key+'_All')\n",
    "            check_folder = os.path.isdir(out_folder)\n",
    "            if not check_folder:\n",
    "                os.makedirs(out_folder)\n",
    "                log.info(\"Created folder : \" + out_folder)\n",
    "            else:\n",
    "                log.info(out_folder + \" folder already exists.\")\n",
    "            for x in menr['CTX_'+key+'_All'].keys():\n",
    "                out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                menr['CTX_'+key+'_All'][str(x)].motif_enrichment.to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "            if(save_partial):\n",
    "                with open(os.path.join(save_path,'CTX_'+key+'_All' + '.pkl'), 'wb') as f:\n",
    "                    dill.dump(menr['CTX_'+key+'_All'], f, protocol=-1)\n",
    "\n",
    "            if run_without_promoters is True:\n",
    "                ## REMOVE PROMOTERS\n",
    "                log.info('Running cisTarget without promoters for '+key)\n",
    "                regions_overlaps = {key: regions[key].count_overlaps(annot) for key in regions.keys()}\n",
    "                regions_np = {key: regions_overlaps[key][regions_overlaps[key].NumberOverlaps == 0][['Chromosome', 'Start', 'End']] for key in regions.keys()}\n",
    "                db_regions = set(pd.concat([ctx_db.regions_to_db[x] for x in ctx_db.regions_to_db.keys()])['Query'])\n",
    "                ctx_db.regions_to_db = {x: target_to_query(regions_np[x], list(db_regions), fraction_overlap = 0.4) for x in regions_np.keys()}\n",
    "                t1_start = time.time()\n",
    "                menr['CTX_'+key+'_No_promoters'] = run_cistarget(ctx_db = ctx_db,\n",
    "                                   region_sets = regions_np,\n",
    "                                   specie = species,\n",
    "                                   auc_threshold = ctx_auc_threshold,\n",
    "                                   nes_threshold = ctx_nes_threshold,\n",
    "                                   rank_threshold = ctx_rank_threshold,\n",
    "                                   annotation = annotation,\n",
    "                                   motif_similarity_fdr = motif_similarity_fdr, \n",
    "                                   path_to_motif_annotations = path_to_motif_annotations,\n",
    "                                   n_cpu = n_cpu,\n",
    "                                   _temp_dir= _temp_dir,\n",
    "                                   annotation_version = annotation_version,\n",
    "                                   **kwargs)\n",
    "                m2=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "                t1_stop = time.time()\n",
    "                time_ctx_np = t1_stop-t1_start\n",
    "                out_folder = os.path.join(save_path,'CTX_'+key+'_No_promoters')\n",
    "                check_folder = os.path.isdir(out_folder)\n",
    "                if not check_folder:\n",
    "                    os.makedirs(out_folder)\n",
    "                    log.info(\"Created folder:\" + out_folder)\n",
    "                else:\n",
    "                    log.info(out_folder + \" folder already exists.\")\n",
    "                for x in menr['CTX_'+key+'_No_promoters'].keys():\n",
    "                    out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                    menr['CTX_'+key+'_No_promoters'][str(x)].motif_enrichment.to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "                \n",
    "                if(save_partial):\n",
    "                    with open(os.path.join(save_path,'CTX_'+key+'_No_promoters' + '.pkl'), 'wb') as f:\n",
    "                      dill.dump(menr['CTX_'+key+'_No_promoters'], f, protocol=-1)\n",
    "        ## DEM\n",
    "        if dem_db_path is not None:\n",
    "            log.info('Running DEM for '+key)\n",
    "            regions = region_sets[key]\n",
    "            dem_db = DEMDatabase(dem_db_path, regions)  \n",
    "            if exclude_motifs is not None:\n",
    "                out = pd.read_csv(exclude_motifs, header=None).iloc[:,0].tolist()\n",
    "                dem_db.db_scores = dem_db.db_scores.drop(out)\n",
    "            if exclude_collection is not None:\n",
    "                for col in exclude_collection:\n",
    "                    dem_db.db_scores = dem_db.db_scores[~dem_db.db_scores.index.str.contains(col)]\n",
    "            t1_start = time.time()\n",
    "            menr['DEM_'+key+'_All'] = DEM(dem_db = dem_db,\n",
    "                               region_sets = regions,\n",
    "                               log2fc_thr = dem_log2fc_thr,\n",
    "                               motif_hit_thr = dem_motif_hit_thr,\n",
    "                               max_bg_regions = dem_max_bg_regions,\n",
    "                               specie = species,\n",
    "                               genome_annotation = annot_dem,\n",
    "                               promoter_space = promoter_space,\n",
    "                               motif_annotation =   annotation,\n",
    "                               motif_similarity_fdr = motif_similarity_fdr, \n",
    "                               path_to_motif_annotations = path_to_motif_annotations,\n",
    "                               n_cpu = n_cpu,\n",
    "                               annotation_version = annotation_version,\n",
    "                               tmp_dir = save_path,\n",
    "                               _temp_dir= _temp_dir,\n",
    "                               **kwargs)\n",
    "            m3=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "            t1_stop = time.time()\n",
    "            time_dem_all = t1_stop-t1_start\n",
    "            out_folder = os.path.join(save_path,'DEM_'+key+'_All')\n",
    "            check_folder = os.path.isdir(out_folder)\n",
    "            if not check_folder:\n",
    "                os.makedirs(out_folder)\n",
    "                log.info(\"Created folder : \"+ out_folder)\n",
    "            else:\n",
    "                log.info(out_folder + \" folder already exists.\")\n",
    "            for x in menr['DEM_'+key+'_All'].motif_enrichment.keys():\n",
    "                out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                menr['DEM_'+key+'_All'].motif_enrichment[str(x)].to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "            if(save_partial):\n",
    "                with open(os.path.join(save_path, 'DEM_'+key+'_All'+'.pkl'), 'wb') as f:\n",
    "                  dill.dump(menr['DEM_'+key+'_All'], f, protocol=-1)\n",
    "                \n",
    "            if run_without_promoters is True:\n",
    "                log.info('Running DEM without promoters for '+key)\n",
    "                ## REMOVE PROMOTERS\n",
    "                regions_overlaps = {key: regions[key].count_overlaps(annot) for key in regions.keys()}\n",
    "                regions_np = {key: regions_overlaps[key][regions_overlaps[key].NumberOverlaps == 0][['Chromosome', 'Start', 'End']] for key in regions.keys()}\n",
    "                db_regions = set(pd.concat([dem_db.regions_to_db[x] for x in dem_db.regions_to_db.keys()])['Query'])\n",
    "                dem_db.regions_to_db = {x: target_to_query(regions_np[x], list(db_regions), fraction_overlap = 0.4) for x in regions_np.keys()}\n",
    "                t1_start = time.time()\n",
    "                menr['DEM_'+key+'_No_promoters'] = DEM(dem_db = dem_db,\n",
    "                               region_sets = regions_np,\n",
    "                               log2fc_thr = dem_log2fc_thr,\n",
    "                               motif_hit_thr = dem_motif_hit_thr,\n",
    "                               max_bg_regions = dem_max_bg_regions,\n",
    "                               specie = species,\n",
    "                               promoter_space = promoter_space,\n",
    "                               motif_annotation = annotation,\n",
    "                               motif_similarity_fdr = motif_similarity_fdr, \n",
    "                               path_to_motif_annotations = path_to_motif_annotations,\n",
    "                               n_cpu = n_cpu,\n",
    "                               annotation_version = annotation_version,\n",
    "                               tmp_dir = save_path,\n",
    "                               _temp_dir= _temp_dir,\n",
    "                               **kwargs)\n",
    "                m4=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "                t1_stop = time.time()\n",
    "                time_dem_np = t1_stop-t1_start\n",
    "                out_folder = os.path.join(save_path,'DEM_'+key+'_No_promoters')\n",
    "                check_folder = os.path.isdir(out_folder)\n",
    "                if not check_folder:\n",
    "                    os.makedirs(out_folder)\n",
    "                    log.info(\"Created folder : \"+ out_folder)\n",
    "                else:\n",
    "                    log.info(out_folder + \" folder already exists.\")\n",
    "                for x in menr['DEM_'+key+'_No_promoters'].motif_enrichment.keys():\n",
    "                    out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                    menr['DEM_'+key+'_No_promoters'].motif_enrichment[str(x)].to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "                if(save_partial):\n",
    "                    with open(os.path.join(save_path, 'DEM_'+key+'_No_promoters'+'.pkl'), 'wb') as f:\n",
    "                      dill.dump(menr['DEM_'+key+'_All'], f, protocol=-1)\n",
    "                    \n",
    "        times = [time_ctx_all, time_ctx_np, time_dem_all, time_dem_np]\n",
    "        df = pd.DataFrame(times, index=['CTX_all', 'CTX_np', 'DEM_all', 'DEM_np'], columns=['Time'])\n",
    "        df.to_csv(save_path+key+'running_times.tsv', sep='\\t') \n",
    "        memory=[m1,m2,m3,m4]\n",
    "        df = pd.DataFrame(memory, index=['CTX_all', 'CTX_np', 'DEM_all', 'DEM_np'], columns=['Memory'])\n",
    "        df.to_csv(save_path+key+'cummulative_memory.tsv', sep='\\t')  \n",
    "        memory=[m1,m2-m1,m3-m2,m4-m3]\n",
    "        df = pd.DataFrame(memory, index=['CTX_all', 'CTX_np', 'DEM_all', 'DEM_np'], columns=['Memory'])\n",
    "        df.to_csv(save_path+key+'memory_per_step.tsv', sep='\\t')  \n",
    "                    \n",
    "    log.info('Saving object')         \n",
    "    with open(os.path.join(save_path,'menr.pkl'), 'wb') as f:\n",
    "        dill.dump(menr, f, protocol=-1)\n",
    "    \n",
    "    import time\n",
    "    log.info('Finished! Took {} minutes'.format((time.time() - start_time)/60)) \n",
    "            \n",
    "# Load region binarized topics\n",
    "import pickle\n",
    "outDir = '/staging/leuven/stg_00002/lcb/cbravo/Multiomics_pipeline/analysis/DPCL/speed_benchmark/low_simulation/DPCL_cisTopicObject_3K_fragments_25K_cells/'\n",
    "infile = open(outDir+'binarized_topic_region.pkl', 'rb')\n",
    "binarized_topic_region = pickle.load(infile)\n",
    "infile.close()\n",
    "# Load DARs\n",
    "import pickle\n",
    "infile = open(outDir+'DARs.pkl', 'rb')\n",
    "DARs_dict = pickle.load(infile)\n",
    "infile.close()\n",
    "# Format region sets\n",
    "import re\n",
    "import pyranges as pr\n",
    "from pycistarget.utils import *\n",
    "region_sets = {}\n",
    "region_sets['Topics'] = {key: pr.PyRanges(region_names_to_coordinates(binarized_topic_region[key].index.tolist())) for key in binarized_topic_region.keys()}\n",
    "region_sets['DARs'] = {re.sub('[^A-Za-z0-9]+', '_', key): pr.PyRanges(region_names_to_coordinates(DARs_dict[key].index.tolist())) for key in DARs_dict.keys()}\n",
    "# Create save_path\n",
    "save_path = outDir + 'pycistarget/'\n",
    "# Create save_Dir\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "\n",
    "# Run pycistarget\n",
    "run_pycistarget(region_sets,\n",
    "                 ctx_db_path = '/staging/leuven/stg_00002/lcb/cbravo/Multiomics_pipeline/analysis/DPCL/ctx_db/cluster_V10_DPCL_feather_v2.regions_vs_motifs.rankings.feather',\n",
    "                 species = 'homo_sapiens',\n",
    "                 save_path = save_path,\n",
    "                 dem_db_path = '/staging/leuven/stg_00002/lcb/cbravo/Multiomics_pipeline/analysis/DPCL/ctx_db/cluster_V10_DPCL_feather_v2.regions_vs_motifs.scores.feather',\n",
    "                 run_without_promoters = True,\n",
    "                 biomart_host = 'http://www.ensembl.org',\n",
    "                 promoter_space = 500,\n",
    "                 ctx_auc_threshold = 0.005,\n",
    "                 ctx_nes_threshold = 3.0,\n",
    "                 ctx_rank_threshold = 0.05,\n",
    "                 dem_log2fc_thr = 0.5,\n",
    "                 dem_motif_hit_thr = 3.0,\n",
    "                 dem_max_bg_regions = 500,\n",
    "                 path_to_motif_annotations = '/staging/leuven/stg_00002/lcb/cbravo/cluster_motif_collection_V10_no_desso_no_factorbook/snapshots/motifs-v10nr_clust-nr.mgi-m0.00001-o0.0.tbl',\n",
    "                 annotation_version = 'v10nr_clust',\n",
    "                 annotation = ['Direct_annot', 'Orthology_annot'],\n",
    "                 n_cpu = 8,\n",
    "                 _temp_dir = '/scratch/leuven/313/vsc31305/ray_spill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9e5a35-a215-4472-b70c-1da8e14b1980",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --partition=batch\n",
    "#SBATCH --cluster wice\n",
    "#SBATCH --account lp_wice_pilot\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=carmen.bravogonzalezblas@kuleuven.be\n",
    "#SBATCH --ntasks=1\n",
    "\n",
    "#SBATCH --cpus-per-task=20\n",
    "#SBATCH --time=3:00:00\n",
    "#SBATCH --mem=180G\n",
    "\n",
    "#SBATCH --job-name=DPCL_cisTopicObject_3K_fragments_25K_cells\n",
    "#SBATCH --output=DPCL_cisTopicObject_3K_fragments_25K_cells.out\n",
    "#SBATCH --error=DPCL_cisTopicObject_3K_fragments_25K_cells.err\n",
    "\n",
    "singularity exec -B /lustre1,/staging,/data,/vsc-hard-mounts,/scratch,/local_scratch /data/leuven/software/biomed/singularity_images/scenicplus/scenicplus.sif python DPCL_cisTopicObject_3K_fragments_25K_cells.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56ddf9b-d686-45ed-aef6-a48b535fe7a3",
   "metadata": {},
   "source": [
    "# DPCL_cisTopicObject_10K_fragments_80_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661a329f-159c-446a-96e2-b9e84513e3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import pandas as pd\n",
    "import dill\n",
    "import pyranges as pr\n",
    "from pycistarget.motif_enrichment_cistarget import *\n",
    "from pycistarget.motif_enrichment_dem import *\n",
    "from pycistarget.utils import *\n",
    "import pybiomart as pbm\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "def run_pycistarget(region_sets: Dict[str, pr.PyRanges],\n",
    "                 species: str,\n",
    "                 save_path: str,\n",
    "                 custom_annot: pd.DataFrame = None,\n",
    "                 save_partial: bool = False,\n",
    "                 ctx_db_path: str = None,\n",
    "                 dem_db_path: str = None,\n",
    "                 run_without_promoters: bool = False,\n",
    "                 biomart_host: str = 'http://www.ensembl.org',\n",
    "                 promoter_space: int = 500,\n",
    "                 ctx_auc_threshold: float = 0.005,\n",
    "                 ctx_nes_threshold: float = 3.0,\n",
    "                 ctx_rank_threshold: float = 0.05,\n",
    "                 dem_log2fc_thr: float = 0.5,\n",
    "                 dem_motif_hit_thr: float = 3.0,\n",
    "                 dem_max_bg_regions: int = 500,\n",
    "                 annotation : List[str] = ['Direct_annot', 'Orthology_annot'],\n",
    "                 motif_similarity_fdr: float = 0.000001,\n",
    "                 path_to_motif_annotations: str = None,\n",
    "                 annotation_version: str = 'v9',\n",
    "                 n_cpu : int = 1,\n",
    "                 _temp_dir: str = None,\n",
    "                 exclude_motifs: str = None,\n",
    "                 exclude_collection: List[str] = None,\n",
    "                 **kwargs):\n",
    "    # Create logger\n",
    "    level = logging.INFO\n",
    "    log_format = '%(asctime)s %(name)-12s %(levelname)-8s %(message)s'\n",
    "    handlers = [logging.StreamHandler(stream=sys.stdout)]\n",
    "    logging.basicConfig(level=level, format=log_format, handlers=handlers)\n",
    "    log = logging.getLogger('pycisTarget_wrapper')\n",
    "    \n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    check_folder = os.path.isdir(save_path)\n",
    "    if not check_folder:\n",
    "        os.makedirs(save_path)\n",
    "        log.info(\"Created folder : \" + save_path)\n",
    "    else:\n",
    "        log.info(save_path + \" folder already exists.\")\n",
    "        \n",
    "    def get_species_annotation(species: str):\n",
    "        dataset = pbm.Dataset(name=species,  host=biomart_host)\n",
    "        annot = dataset.query(attributes=['chromosome_name', 'transcription_start_site', 'strand', 'external_gene_name', 'transcript_biotype'])\n",
    "        annot.columns = ['Chromosome', 'Start', 'Strand', 'Gene', 'Transcript_type']\n",
    "        annot['Chromosome'] = annot['Chromosome'].astype('str')\n",
    "        filterf = annot['Chromosome'].str.contains('CHR|GL|JH|MT|KI')\n",
    "        annot = annot[~filterf]\n",
    "        annot['Chromosome'] = annot['Chromosome'].replace(r'(\\b\\S)', r'chr\\1')\n",
    "        annot = annot[annot.Transcript_type == 'protein_coding']\n",
    "        annot = annot.dropna(subset = ['Chromosome', 'Start'])\n",
    "        # Check if chromosomes have chr\n",
    "        check = region_sets[list(region_sets.keys())[0]]\n",
    "        if not any(['chr' in c for c in check[list(check.keys())[0]].df['Chromosome']]):\n",
    "            annot.Chromosome = annot.Chromosome.str.replace('chr', '')\n",
    "        if not any(['chr' in x for x in annot.Chromosome]):\n",
    "            annot.Chromosome = [f'chr{x}' for x in annot.Chromosome]\n",
    "        annot_dem=annot.copy()\n",
    "        # Define promoter space\n",
    "        annot['End'] = annot['Start'].astype(int)+promoter_space\n",
    "        annot['Start'] = annot['Start'].astype(int)-promoter_space\n",
    "        annot = pr.PyRanges(annot[['Chromosome', 'Start', 'End']])\n",
    "        return annot, annot_dem\n",
    "        \n",
    "    # Prepare annotation\n",
    "    if species == 'homo_sapiens':\n",
    "        annot, annot_dem = get_species_annotation('hsapiens_gene_ensembl')\n",
    "    elif species == 'mus_musculus':\n",
    "        annot, annot_dem = get_species_annotation('mmusculus_gene_ensembl')\n",
    "    elif species == 'drosophila_melanogaster':\n",
    "        annot, annot_dem = get_species_annotation('dmelanogaster_gene_ensembl')\n",
    "    elif species == 'gallus_gallus':\n",
    "        annot, annot_dem = get_species_annotation('ggallus_gene_ensembl')\n",
    "    elif species == 'custom':\n",
    "        annot_dem = custom_annot\n",
    "        annot = annot_dem.copy()\n",
    "        # Define promoter space\n",
    "        annot['End'] = annot['Start'].astype(int)+promoter_space\n",
    "        annot['Start'] = annot['Start'].astype(int)-promoter_space\n",
    "        annot = pr.PyRanges(annot[['Chromosome', 'Start', 'End']])\n",
    "    else:\n",
    "        raise TypeError(\"Species not recognized\")\n",
    "\n",
    "    menr = {}\n",
    "    for key in region_sets.keys():\n",
    "        if ctx_db_path is not None:\n",
    "            log.info('Loading cisTarget database for ' + key)\n",
    "            ## CISTARGET\n",
    "            regions = region_sets[key]\n",
    "            ctx_db = cisTargetDatabase(ctx_db_path, regions)  \n",
    "            if exclude_motifs is not None:\n",
    "                out = pd.read_csv(exclude_motifs, header=None).iloc[:,0].tolist()\n",
    "                ctx_db.db_rankings = ctx_db.db_rankings.drop(out)\n",
    "            if exclude_collection is not None:\n",
    "                for col in exclude_collection:\n",
    "                    ctx_db.db_rankings = ctx_db.db_rankings[~ctx_db.db_rankings.index.str.contains(col)]\n",
    "            ## DEFAULT\n",
    "            import time\n",
    "            t1_start = time.time()\n",
    "            log.info('Running cisTarget for '+key)\n",
    "            menr['CTX_'+key+'_All'] = run_cistarget(ctx_db = ctx_db,\n",
    "                                   region_sets = regions,\n",
    "                                   specie = species,\n",
    "                                   auc_threshold = ctx_auc_threshold,\n",
    "                                   nes_threshold = ctx_nes_threshold,\n",
    "                                   rank_threshold = ctx_rank_threshold,\n",
    "                                   annotation = annotation,\n",
    "                                   motif_similarity_fdr = motif_similarity_fdr,\n",
    "                                   path_to_motif_annotations = path_to_motif_annotations,\n",
    "                                   n_cpu = n_cpu,\n",
    "                                   _temp_dir= _temp_dir,\n",
    "                                   annotation_version = annotation_version,\n",
    "                                   **kwargs)\n",
    "            m1=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "            t1_stop = time.time()\n",
    "            time_ctx_all = t1_stop-t1_start\n",
    "            out_folder = os.path.join(save_path,'CTX_'+key+'_All')\n",
    "            check_folder = os.path.isdir(out_folder)\n",
    "            if not check_folder:\n",
    "                os.makedirs(out_folder)\n",
    "                log.info(\"Created folder : \" + out_folder)\n",
    "            else:\n",
    "                log.info(out_folder + \" folder already exists.\")\n",
    "            for x in menr['CTX_'+key+'_All'].keys():\n",
    "                out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                menr['CTX_'+key+'_All'][str(x)].motif_enrichment.to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "            if(save_partial):\n",
    "                with open(os.path.join(save_path,'CTX_'+key+'_All' + '.pkl'), 'wb') as f:\n",
    "                    dill.dump(menr['CTX_'+key+'_All'], f, protocol=-1)\n",
    "\n",
    "            if run_without_promoters is True:\n",
    "                ## REMOVE PROMOTERS\n",
    "                log.info('Running cisTarget without promoters for '+key)\n",
    "                regions_overlaps = {key: regions[key].count_overlaps(annot) for key in regions.keys()}\n",
    "                regions_np = {key: regions_overlaps[key][regions_overlaps[key].NumberOverlaps == 0][['Chromosome', 'Start', 'End']] for key in regions.keys()}\n",
    "                db_regions = set(pd.concat([ctx_db.regions_to_db[x] for x in ctx_db.regions_to_db.keys()])['Query'])\n",
    "                ctx_db.regions_to_db = {x: target_to_query(regions_np[x], list(db_regions), fraction_overlap = 0.4) for x in regions_np.keys()}\n",
    "                t1_start = time.time()\n",
    "                menr['CTX_'+key+'_No_promoters'] = run_cistarget(ctx_db = ctx_db,\n",
    "                                   region_sets = regions_np,\n",
    "                                   specie = species,\n",
    "                                   auc_threshold = ctx_auc_threshold,\n",
    "                                   nes_threshold = ctx_nes_threshold,\n",
    "                                   rank_threshold = ctx_rank_threshold,\n",
    "                                   annotation = annotation,\n",
    "                                   motif_similarity_fdr = motif_similarity_fdr, \n",
    "                                   path_to_motif_annotations = path_to_motif_annotations,\n",
    "                                   n_cpu = n_cpu,\n",
    "                                   _temp_dir= _temp_dir,\n",
    "                                   annotation_version = annotation_version,\n",
    "                                   **kwargs)\n",
    "                m2=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "                t1_stop = time.time()\n",
    "                time_ctx_np = t1_stop-t1_start\n",
    "                out_folder = os.path.join(save_path,'CTX_'+key+'_No_promoters')\n",
    "                check_folder = os.path.isdir(out_folder)\n",
    "                if not check_folder:\n",
    "                    os.makedirs(out_folder)\n",
    "                    log.info(\"Created folder:\" + out_folder)\n",
    "                else:\n",
    "                    log.info(out_folder + \" folder already exists.\")\n",
    "                for x in menr['CTX_'+key+'_No_promoters'].keys():\n",
    "                    out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                    menr['CTX_'+key+'_No_promoters'][str(x)].motif_enrichment.to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "                \n",
    "                if(save_partial):\n",
    "                    with open(os.path.join(save_path,'CTX_'+key+'_No_promoters' + '.pkl'), 'wb') as f:\n",
    "                      dill.dump(menr['CTX_'+key+'_No_promoters'], f, protocol=-1)\n",
    "        ## DEM\n",
    "        if dem_db_path is not None:\n",
    "            log.info('Running DEM for '+key)\n",
    "            regions = region_sets[key]\n",
    "            dem_db = DEMDatabase(dem_db_path, regions)  \n",
    "            if exclude_motifs is not None:\n",
    "                out = pd.read_csv(exclude_motifs, header=None).iloc[:,0].tolist()\n",
    "                dem_db.db_scores = dem_db.db_scores.drop(out)\n",
    "            if exclude_collection is not None:\n",
    "                for col in exclude_collection:\n",
    "                    dem_db.db_scores = dem_db.db_scores[~dem_db.db_scores.index.str.contains(col)]\n",
    "            t1_start = time.time()\n",
    "            menr['DEM_'+key+'_All'] = DEM(dem_db = dem_db,\n",
    "                               region_sets = regions,\n",
    "                               log2fc_thr = dem_log2fc_thr,\n",
    "                               motif_hit_thr = dem_motif_hit_thr,\n",
    "                               max_bg_regions = dem_max_bg_regions,\n",
    "                               specie = species,\n",
    "                               genome_annotation = annot_dem,\n",
    "                               promoter_space = promoter_space,\n",
    "                               motif_annotation =   annotation,\n",
    "                               motif_similarity_fdr = motif_similarity_fdr, \n",
    "                               path_to_motif_annotations = path_to_motif_annotations,\n",
    "                               n_cpu = n_cpu,\n",
    "                               annotation_version = annotation_version,\n",
    "                               tmp_dir = save_path,\n",
    "                               _temp_dir= _temp_dir,\n",
    "                               **kwargs)\n",
    "            m3=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "            t1_stop = time.time()\n",
    "            time_dem_all = t1_stop-t1_start\n",
    "            out_folder = os.path.join(save_path,'DEM_'+key+'_All')\n",
    "            check_folder = os.path.isdir(out_folder)\n",
    "            if not check_folder:\n",
    "                os.makedirs(out_folder)\n",
    "                log.info(\"Created folder : \"+ out_folder)\n",
    "            else:\n",
    "                log.info(out_folder + \" folder already exists.\")\n",
    "            for x in menr['DEM_'+key+'_All'].motif_enrichment.keys():\n",
    "                out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                menr['DEM_'+key+'_All'].motif_enrichment[str(x)].to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "            if(save_partial):\n",
    "                with open(os.path.join(save_path, 'DEM_'+key+'_All'+'.pkl'), 'wb') as f:\n",
    "                  dill.dump(menr['DEM_'+key+'_All'], f, protocol=-1)\n",
    "                \n",
    "            if run_without_promoters is True:\n",
    "                log.info('Running DEM without promoters for '+key)\n",
    "                ## REMOVE PROMOTERS\n",
    "                regions_overlaps = {key: regions[key].count_overlaps(annot) for key in regions.keys()}\n",
    "                regions_np = {key: regions_overlaps[key][regions_overlaps[key].NumberOverlaps == 0][['Chromosome', 'Start', 'End']] for key in regions.keys()}\n",
    "                db_regions = set(pd.concat([dem_db.regions_to_db[x] for x in dem_db.regions_to_db.keys()])['Query'])\n",
    "                dem_db.regions_to_db = {x: target_to_query(regions_np[x], list(db_regions), fraction_overlap = 0.4) for x in regions_np.keys()}\n",
    "                t1_start = time.time()\n",
    "                menr['DEM_'+key+'_No_promoters'] = DEM(dem_db = dem_db,\n",
    "                               region_sets = regions_np,\n",
    "                               log2fc_thr = dem_log2fc_thr,\n",
    "                               motif_hit_thr = dem_motif_hit_thr,\n",
    "                               max_bg_regions = dem_max_bg_regions,\n",
    "                               specie = species,\n",
    "                               promoter_space = promoter_space,\n",
    "                               motif_annotation = annotation,\n",
    "                               motif_similarity_fdr = motif_similarity_fdr, \n",
    "                               path_to_motif_annotations = path_to_motif_annotations,\n",
    "                               n_cpu = n_cpu,\n",
    "                               annotation_version = annotation_version,\n",
    "                               tmp_dir = save_path,\n",
    "                               _temp_dir= _temp_dir,\n",
    "                               **kwargs)\n",
    "                m4=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "                t1_stop = time.time()\n",
    "                time_dem_np = t1_stop-t1_start\n",
    "                out_folder = os.path.join(save_path,'DEM_'+key+'_No_promoters')\n",
    "                check_folder = os.path.isdir(out_folder)\n",
    "                if not check_folder:\n",
    "                    os.makedirs(out_folder)\n",
    "                    log.info(\"Created folder : \"+ out_folder)\n",
    "                else:\n",
    "                    log.info(out_folder + \" folder already exists.\")\n",
    "                for x in menr['DEM_'+key+'_No_promoters'].motif_enrichment.keys():\n",
    "                    out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                    menr['DEM_'+key+'_No_promoters'].motif_enrichment[str(x)].to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "                if(save_partial):\n",
    "                    with open(os.path.join(save_path, 'DEM_'+key+'_No_promoters'+'.pkl'), 'wb') as f:\n",
    "                      dill.dump(menr['DEM_'+key+'_All'], f, protocol=-1)\n",
    "                    \n",
    "        times = [time_ctx_all, time_ctx_np, time_dem_all, time_dem_np]\n",
    "        df = pd.DataFrame(times, index=['CTX_all', 'CTX_np', 'DEM_all', 'DEM_np'], columns=['Time'])\n",
    "        df.to_csv(save_path+key+'running_times.tsv', sep='\\t') \n",
    "        memory=[m1,m2,m3,m4]\n",
    "        df = pd.DataFrame(memory, index=['CTX_all', 'CTX_np', 'DEM_all', 'DEM_np'], columns=['Memory'])\n",
    "        df.to_csv(save_path+key+'cummulative_memory.tsv', sep='\\t')  \n",
    "        memory=[m1,m2-m1,m3-m2,m4-m3]\n",
    "        df = pd.DataFrame(memory, index=['CTX_all', 'CTX_np', 'DEM_all', 'DEM_np'], columns=['Memory'])\n",
    "        df.to_csv(save_path+key+'memory_per_step.tsv', sep='\\t')  \n",
    "                    \n",
    "    log.info('Saving object')         \n",
    "    with open(os.path.join(save_path,'menr.pkl'), 'wb') as f:\n",
    "        dill.dump(menr, f, protocol=-1)\n",
    "    \n",
    "    import time\n",
    "    log.info('Finished! Took {} minutes'.format((time.time() - start_time)/60)) \n",
    "            \n",
    "# Load region binarized topics\n",
    "import pickle\n",
    "outDir = '/staging/leuven/stg_00002/lcb/cbravo/Multiomics_pipeline/analysis/DPCL/speed_benchmark/medium_simulation/DPCL_cisTopicObject_10K_fragments_80_cells/'\n",
    "infile = open(outDir+'binarized_topic_region.pkl', 'rb')\n",
    "binarized_topic_region = pickle.load(infile)\n",
    "infile.close()\n",
    "# Load DARs\n",
    "import pickle\n",
    "infile = open(outDir+'DARs.pkl', 'rb')\n",
    "DARs_dict = pickle.load(infile)\n",
    "infile.close()\n",
    "# Format region sets\n",
    "import re\n",
    "import pyranges as pr\n",
    "from pycistarget.utils import *\n",
    "region_sets = {}\n",
    "region_sets['Topics'] = {key: pr.PyRanges(region_names_to_coordinates(binarized_topic_region[key].index.tolist())) for key in binarized_topic_region.keys()}\n",
    "region_sets['DARs'] = {re.sub('[^A-Za-z0-9]+', '_', key): pr.PyRanges(region_names_to_coordinates(DARs_dict[key].index.tolist())) for key in DARs_dict.keys()}\n",
    "# Create save_path\n",
    "save_path = outDir + 'pycistarget/'\n",
    "# Create save_Dir\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "\n",
    "# Run pycistarget\n",
    "run_pycistarget(region_sets,\n",
    "                 ctx_db_path = '/staging/leuven/stg_00002/lcb/cbravo/Multiomics_pipeline/analysis/DPCL/ctx_db/cluster_V10_DPCL_feather_v2.regions_vs_motifs.rankings.feather',\n",
    "                 species = 'homo_sapiens',\n",
    "                 save_path = save_path,\n",
    "                 dem_db_path = '/staging/leuven/stg_00002/lcb/cbravo/Multiomics_pipeline/analysis/DPCL/ctx_db/cluster_V10_DPCL_feather_v2.regions_vs_motifs.scores.feather',\n",
    "                 run_without_promoters = True,\n",
    "                 biomart_host = 'http://www.ensembl.org',\n",
    "                 promoter_space = 500,\n",
    "                 ctx_auc_threshold = 0.005,\n",
    "                 ctx_nes_threshold = 3.0,\n",
    "                 ctx_rank_threshold = 0.05,\n",
    "                 dem_log2fc_thr = 0.5,\n",
    "                 dem_motif_hit_thr = 3.0,\n",
    "                 dem_max_bg_regions = 500,\n",
    "                 path_to_motif_annotations = '/staging/leuven/stg_00002/lcb/cbravo/cluster_motif_collection_V10_no_desso_no_factorbook/snapshots/motifs-v10nr_clust-nr.mgi-m0.00001-o0.0.tbl',\n",
    "                 annotation_version = 'v10nr_clust',\n",
    "                 annotation = ['Direct_annot', 'Orthology_annot'],\n",
    "                 n_cpu = 8,\n",
    "                 _temp_dir = '/scratch/leuven/313/vsc31305/ray_spill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2316b60f-b748-430e-a36a-2ff2f2a7bc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --partition=batch\n",
    "#SBATCH --cluster wice\n",
    "#SBATCH --account lp_wice_pilot\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=carmen.bravogonzalezblas@kuleuven.be\n",
    "#SBATCH --ntasks=1\n",
    "\n",
    "#SBATCH --cpus-per-task=20\n",
    "#SBATCH --time=3:00:00\n",
    "#SBATCH --mem=180G\n",
    "\n",
    "#SBATCH --job-name=DPCL_cisTopicObject_10K_fragments_80_cells\n",
    "#SBATCH --output=DPCL_cisTopicObject_10K_fragments_80_cells.out\n",
    "#SBATCH --error=DPCL_cisTopicObject_10K_fragments_80_cells.err\n",
    "\n",
    "singularity exec -B /lustre1,/staging,/data,/vsc-hard-mounts,/scratch,/local_scratch /data/leuven/software/biomed/singularity_images/scenicplus/scenicplus.sif python DPCL_cisTopicObject_10K_fragments_80_cells.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b15df4-ad67-490d-8eb7-00ff555e3b24",
   "metadata": {},
   "source": [
    "# DPCL_cisTopicObject_10K_fragments_1K_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bf9a57-1082-4075-ae15-438e87969261",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import pandas as pd\n",
    "import dill\n",
    "import pyranges as pr\n",
    "from pycistarget.motif_enrichment_cistarget import *\n",
    "from pycistarget.motif_enrichment_dem import *\n",
    "from pycistarget.utils import *\n",
    "import pybiomart as pbm\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "def run_pycistarget(region_sets: Dict[str, pr.PyRanges],\n",
    "                 species: str,\n",
    "                 save_path: str,\n",
    "                 custom_annot: pd.DataFrame = None,\n",
    "                 save_partial: bool = False,\n",
    "                 ctx_db_path: str = None,\n",
    "                 dem_db_path: str = None,\n",
    "                 run_without_promoters: bool = False,\n",
    "                 biomart_host: str = 'http://www.ensembl.org',\n",
    "                 promoter_space: int = 500,\n",
    "                 ctx_auc_threshold: float = 0.005,\n",
    "                 ctx_nes_threshold: float = 3.0,\n",
    "                 ctx_rank_threshold: float = 0.05,\n",
    "                 dem_log2fc_thr: float = 0.5,\n",
    "                 dem_motif_hit_thr: float = 3.0,\n",
    "                 dem_max_bg_regions: int = 500,\n",
    "                 annotation : List[str] = ['Direct_annot', 'Orthology_annot'],\n",
    "                 motif_similarity_fdr: float = 0.000001,\n",
    "                 path_to_motif_annotations: str = None,\n",
    "                 annotation_version: str = 'v9',\n",
    "                 n_cpu : int = 1,\n",
    "                 _temp_dir: str = None,\n",
    "                 exclude_motifs: str = None,\n",
    "                 exclude_collection: List[str] = None,\n",
    "                 **kwargs):\n",
    "    # Create logger\n",
    "    level = logging.INFO\n",
    "    log_format = '%(asctime)s %(name)-12s %(levelname)-8s %(message)s'\n",
    "    handlers = [logging.StreamHandler(stream=sys.stdout)]\n",
    "    logging.basicConfig(level=level, format=log_format, handlers=handlers)\n",
    "    log = logging.getLogger('pycisTarget_wrapper')\n",
    "    \n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    check_folder = os.path.isdir(save_path)\n",
    "    if not check_folder:\n",
    "        os.makedirs(save_path)\n",
    "        log.info(\"Created folder : \" + save_path)\n",
    "    else:\n",
    "        log.info(save_path + \" folder already exists.\")\n",
    "        \n",
    "    def get_species_annotation(species: str):\n",
    "        dataset = pbm.Dataset(name=species,  host=biomart_host)\n",
    "        annot = dataset.query(attributes=['chromosome_name', 'transcription_start_site', 'strand', 'external_gene_name', 'transcript_biotype'])\n",
    "        annot.columns = ['Chromosome', 'Start', 'Strand', 'Gene', 'Transcript_type']\n",
    "        annot['Chromosome'] = annot['Chromosome'].astype('str')\n",
    "        filterf = annot['Chromosome'].str.contains('CHR|GL|JH|MT|KI')\n",
    "        annot = annot[~filterf]\n",
    "        annot['Chromosome'] = annot['Chromosome'].replace(r'(\\b\\S)', r'chr\\1')\n",
    "        annot = annot[annot.Transcript_type == 'protein_coding']\n",
    "        annot = annot.dropna(subset = ['Chromosome', 'Start'])\n",
    "        # Check if chromosomes have chr\n",
    "        check = region_sets[list(region_sets.keys())[0]]\n",
    "        if not any(['chr' in c for c in check[list(check.keys())[0]].df['Chromosome']]):\n",
    "            annot.Chromosome = annot.Chromosome.str.replace('chr', '')\n",
    "        if not any(['chr' in x for x in annot.Chromosome]):\n",
    "            annot.Chromosome = [f'chr{x}' for x in annot.Chromosome]\n",
    "        annot_dem=annot.copy()\n",
    "        # Define promoter space\n",
    "        annot['End'] = annot['Start'].astype(int)+promoter_space\n",
    "        annot['Start'] = annot['Start'].astype(int)-promoter_space\n",
    "        annot = pr.PyRanges(annot[['Chromosome', 'Start', 'End']])\n",
    "        return annot, annot_dem\n",
    "        \n",
    "    # Prepare annotation\n",
    "    if species == 'homo_sapiens':\n",
    "        annot, annot_dem = get_species_annotation('hsapiens_gene_ensembl')\n",
    "    elif species == 'mus_musculus':\n",
    "        annot, annot_dem = get_species_annotation('mmusculus_gene_ensembl')\n",
    "    elif species == 'drosophila_melanogaster':\n",
    "        annot, annot_dem = get_species_annotation('dmelanogaster_gene_ensembl')\n",
    "    elif species == 'gallus_gallus':\n",
    "        annot, annot_dem = get_species_annotation('ggallus_gene_ensembl')\n",
    "    elif species == 'custom':\n",
    "        annot_dem = custom_annot\n",
    "        annot = annot_dem.copy()\n",
    "        # Define promoter space\n",
    "        annot['End'] = annot['Start'].astype(int)+promoter_space\n",
    "        annot['Start'] = annot['Start'].astype(int)-promoter_space\n",
    "        annot = pr.PyRanges(annot[['Chromosome', 'Start', 'End']])\n",
    "    else:\n",
    "        raise TypeError(\"Species not recognized\")\n",
    "\n",
    "    menr = {}\n",
    "    for key in region_sets.keys():\n",
    "        if ctx_db_path is not None:\n",
    "            log.info('Loading cisTarget database for ' + key)\n",
    "            ## CISTARGET\n",
    "            regions = region_sets[key]\n",
    "            ctx_db = cisTargetDatabase(ctx_db_path, regions)  \n",
    "            if exclude_motifs is not None:\n",
    "                out = pd.read_csv(exclude_motifs, header=None).iloc[:,0].tolist()\n",
    "                ctx_db.db_rankings = ctx_db.db_rankings.drop(out)\n",
    "            if exclude_collection is not None:\n",
    "                for col in exclude_collection:\n",
    "                    ctx_db.db_rankings = ctx_db.db_rankings[~ctx_db.db_rankings.index.str.contains(col)]\n",
    "            ## DEFAULT\n",
    "            import time\n",
    "            t1_start = time.time()\n",
    "            log.info('Running cisTarget for '+key)\n",
    "            menr['CTX_'+key+'_All'] = run_cistarget(ctx_db = ctx_db,\n",
    "                                   region_sets = regions,\n",
    "                                   specie = species,\n",
    "                                   auc_threshold = ctx_auc_threshold,\n",
    "                                   nes_threshold = ctx_nes_threshold,\n",
    "                                   rank_threshold = ctx_rank_threshold,\n",
    "                                   annotation = annotation,\n",
    "                                   motif_similarity_fdr = motif_similarity_fdr,\n",
    "                                   path_to_motif_annotations = path_to_motif_annotations,\n",
    "                                   n_cpu = n_cpu,\n",
    "                                   _temp_dir= _temp_dir,\n",
    "                                   annotation_version = annotation_version,\n",
    "                                   **kwargs)\n",
    "            m1=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "            t1_stop = time.time()\n",
    "            time_ctx_all = t1_stop-t1_start\n",
    "            out_folder = os.path.join(save_path,'CTX_'+key+'_All')\n",
    "            check_folder = os.path.isdir(out_folder)\n",
    "            if not check_folder:\n",
    "                os.makedirs(out_folder)\n",
    "                log.info(\"Created folder : \" + out_folder)\n",
    "            else:\n",
    "                log.info(out_folder + \" folder already exists.\")\n",
    "            for x in menr['CTX_'+key+'_All'].keys():\n",
    "                out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                menr['CTX_'+key+'_All'][str(x)].motif_enrichment.to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "            if(save_partial):\n",
    "                with open(os.path.join(save_path,'CTX_'+key+'_All' + '.pkl'), 'wb') as f:\n",
    "                    dill.dump(menr['CTX_'+key+'_All'], f, protocol=-1)\n",
    "\n",
    "            if run_without_promoters is True:\n",
    "                ## REMOVE PROMOTERS\n",
    "                log.info('Running cisTarget without promoters for '+key)\n",
    "                regions_overlaps = {key: regions[key].count_overlaps(annot) for key in regions.keys()}\n",
    "                regions_np = {key: regions_overlaps[key][regions_overlaps[key].NumberOverlaps == 0][['Chromosome', 'Start', 'End']] for key in regions.keys()}\n",
    "                db_regions = set(pd.concat([ctx_db.regions_to_db[x] for x in ctx_db.regions_to_db.keys()])['Query'])\n",
    "                ctx_db.regions_to_db = {x: target_to_query(regions_np[x], list(db_regions), fraction_overlap = 0.4) for x in regions_np.keys()}\n",
    "                t1_start = time.time()\n",
    "                menr['CTX_'+key+'_No_promoters'] = run_cistarget(ctx_db = ctx_db,\n",
    "                                   region_sets = regions_np,\n",
    "                                   specie = species,\n",
    "                                   auc_threshold = ctx_auc_threshold,\n",
    "                                   nes_threshold = ctx_nes_threshold,\n",
    "                                   rank_threshold = ctx_rank_threshold,\n",
    "                                   annotation = annotation,\n",
    "                                   motif_similarity_fdr = motif_similarity_fdr, \n",
    "                                   path_to_motif_annotations = path_to_motif_annotations,\n",
    "                                   n_cpu = n_cpu,\n",
    "                                   _temp_dir= _temp_dir,\n",
    "                                   annotation_version = annotation_version,\n",
    "                                   **kwargs)\n",
    "                m2=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "                t1_stop = time.time()\n",
    "                time_ctx_np = t1_stop-t1_start\n",
    "                out_folder = os.path.join(save_path,'CTX_'+key+'_No_promoters')\n",
    "                check_folder = os.path.isdir(out_folder)\n",
    "                if not check_folder:\n",
    "                    os.makedirs(out_folder)\n",
    "                    log.info(\"Created folder:\" + out_folder)\n",
    "                else:\n",
    "                    log.info(out_folder + \" folder already exists.\")\n",
    "                for x in menr['CTX_'+key+'_No_promoters'].keys():\n",
    "                    out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                    menr['CTX_'+key+'_No_promoters'][str(x)].motif_enrichment.to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "                \n",
    "                if(save_partial):\n",
    "                    with open(os.path.join(save_path,'CTX_'+key+'_No_promoters' + '.pkl'), 'wb') as f:\n",
    "                      dill.dump(menr['CTX_'+key+'_No_promoters'], f, protocol=-1)\n",
    "        ## DEM\n",
    "        if dem_db_path is not None:\n",
    "            log.info('Running DEM for '+key)\n",
    "            regions = region_sets[key]\n",
    "            dem_db = DEMDatabase(dem_db_path, regions)  \n",
    "            if exclude_motifs is not None:\n",
    "                out = pd.read_csv(exclude_motifs, header=None).iloc[:,0].tolist()\n",
    "                dem_db.db_scores = dem_db.db_scores.drop(out)\n",
    "            if exclude_collection is not None:\n",
    "                for col in exclude_collection:\n",
    "                    dem_db.db_scores = dem_db.db_scores[~dem_db.db_scores.index.str.contains(col)]\n",
    "            t1_start = time.time()\n",
    "            menr['DEM_'+key+'_All'] = DEM(dem_db = dem_db,\n",
    "                               region_sets = regions,\n",
    "                               log2fc_thr = dem_log2fc_thr,\n",
    "                               motif_hit_thr = dem_motif_hit_thr,\n",
    "                               max_bg_regions = dem_max_bg_regions,\n",
    "                               specie = species,\n",
    "                               genome_annotation = annot_dem,\n",
    "                               promoter_space = promoter_space,\n",
    "                               motif_annotation =   annotation,\n",
    "                               motif_similarity_fdr = motif_similarity_fdr, \n",
    "                               path_to_motif_annotations = path_to_motif_annotations,\n",
    "                               n_cpu = n_cpu,\n",
    "                               annotation_version = annotation_version,\n",
    "                               tmp_dir = save_path,\n",
    "                               _temp_dir= _temp_dir,\n",
    "                               **kwargs)\n",
    "            m3=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "            t1_stop = time.time()\n",
    "            time_dem_all = t1_stop-t1_start\n",
    "            out_folder = os.path.join(save_path,'DEM_'+key+'_All')\n",
    "            check_folder = os.path.isdir(out_folder)\n",
    "            if not check_folder:\n",
    "                os.makedirs(out_folder)\n",
    "                log.info(\"Created folder : \"+ out_folder)\n",
    "            else:\n",
    "                log.info(out_folder + \" folder already exists.\")\n",
    "            for x in menr['DEM_'+key+'_All'].motif_enrichment.keys():\n",
    "                out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                menr['DEM_'+key+'_All'].motif_enrichment[str(x)].to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "            if(save_partial):\n",
    "                with open(os.path.join(save_path, 'DEM_'+key+'_All'+'.pkl'), 'wb') as f:\n",
    "                  dill.dump(menr['DEM_'+key+'_All'], f, protocol=-1)\n",
    "                \n",
    "            if run_without_promoters is True:\n",
    "                log.info('Running DEM without promoters for '+key)\n",
    "                ## REMOVE PROMOTERS\n",
    "                regions_overlaps = {key: regions[key].count_overlaps(annot) for key in regions.keys()}\n",
    "                regions_np = {key: regions_overlaps[key][regions_overlaps[key].NumberOverlaps == 0][['Chromosome', 'Start', 'End']] for key in regions.keys()}\n",
    "                db_regions = set(pd.concat([dem_db.regions_to_db[x] for x in dem_db.regions_to_db.keys()])['Query'])\n",
    "                dem_db.regions_to_db = {x: target_to_query(regions_np[x], list(db_regions), fraction_overlap = 0.4) for x in regions_np.keys()}\n",
    "                t1_start = time.time()\n",
    "                menr['DEM_'+key+'_No_promoters'] = DEM(dem_db = dem_db,\n",
    "                               region_sets = regions_np,\n",
    "                               log2fc_thr = dem_log2fc_thr,\n",
    "                               motif_hit_thr = dem_motif_hit_thr,\n",
    "                               max_bg_regions = dem_max_bg_regions,\n",
    "                               specie = species,\n",
    "                               promoter_space = promoter_space,\n",
    "                               motif_annotation = annotation,\n",
    "                               motif_similarity_fdr = motif_similarity_fdr, \n",
    "                               path_to_motif_annotations = path_to_motif_annotations,\n",
    "                               n_cpu = n_cpu,\n",
    "                               annotation_version = annotation_version,\n",
    "                               tmp_dir = save_path,\n",
    "                               _temp_dir= _temp_dir,\n",
    "                               **kwargs)\n",
    "                m4=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "                t1_stop = time.time()\n",
    "                time_dem_np = t1_stop-t1_start\n",
    "                out_folder = os.path.join(save_path,'DEM_'+key+'_No_promoters')\n",
    "                check_folder = os.path.isdir(out_folder)\n",
    "                if not check_folder:\n",
    "                    os.makedirs(out_folder)\n",
    "                    log.info(\"Created folder : \"+ out_folder)\n",
    "                else:\n",
    "                    log.info(out_folder + \" folder already exists.\")\n",
    "                for x in menr['DEM_'+key+'_No_promoters'].motif_enrichment.keys():\n",
    "                    out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                    menr['DEM_'+key+'_No_promoters'].motif_enrichment[str(x)].to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "                if(save_partial):\n",
    "                    with open(os.path.join(save_path, 'DEM_'+key+'_No_promoters'+'.pkl'), 'wb') as f:\n",
    "                      dill.dump(menr['DEM_'+key+'_All'], f, protocol=-1)\n",
    "                    \n",
    "        times = [time_ctx_all, time_ctx_np, time_dem_all, time_dem_np]\n",
    "        df = pd.DataFrame(times, index=['CTX_all', 'CTX_np', 'DEM_all', 'DEM_np'], columns=['Time'])\n",
    "        df.to_csv(save_path+key+'running_times.tsv', sep='\\t') \n",
    "        memory=[m1,m2,m3,m4]\n",
    "        df = pd.DataFrame(memory, index=['CTX_all', 'CTX_np', 'DEM_all', 'DEM_np'], columns=['Memory'])\n",
    "        df.to_csv(save_path+key+'cummulative_memory.tsv', sep='\\t')  \n",
    "        memory=[m1,m2-m1,m3-m2,m4-m3]\n",
    "        df = pd.DataFrame(memory, index=['CTX_all', 'CTX_np', 'DEM_all', 'DEM_np'], columns=['Memory'])\n",
    "        df.to_csv(save_path+key+'memory_per_step.tsv', sep='\\t')  \n",
    "                    \n",
    "    log.info('Saving object')         \n",
    "    with open(os.path.join(save_path,'menr.pkl'), 'wb') as f:\n",
    "        dill.dump(menr, f, protocol=-1)\n",
    "    \n",
    "    import time\n",
    "    log.info('Finished! Took {} minutes'.format((time.time() - start_time)/60)) \n",
    "            \n",
    "# Load region binarized topics\n",
    "import pickle\n",
    "outDir = '/staging/leuven/stg_00002/lcb/cbravo/Multiomics_pipeline/analysis/DPCL/speed_benchmark/medium_simulation/DPCL_cisTopicObject_10K_fragments_1K_cells/'\n",
    "infile = open(outDir+'binarized_topic_region.pkl', 'rb')\n",
    "binarized_topic_region = pickle.load(infile)\n",
    "infile.close()\n",
    "# Load DARs\n",
    "import pickle\n",
    "infile = open(outDir+'DARs.pkl', 'rb')\n",
    "DARs_dict = pickle.load(infile)\n",
    "infile.close()\n",
    "# Format region sets\n",
    "import re\n",
    "import pyranges as pr\n",
    "from pycistarget.utils import *\n",
    "region_sets = {}\n",
    "region_sets['Topics'] = {key: pr.PyRanges(region_names_to_coordinates(binarized_topic_region[key].index.tolist())) for key in binarized_topic_region.keys()}\n",
    "region_sets['DARs'] = {re.sub('[^A-Za-z0-9]+', '_', key): pr.PyRanges(region_names_to_coordinates(DARs_dict[key].index.tolist())) for key in DARs_dict.keys()}\n",
    "# Create save_path\n",
    "save_path = outDir + 'pycistarget/'\n",
    "# Create save_Dir\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "\n",
    "# Run pycistarget\n",
    "run_pycistarget(region_sets,\n",
    "                 ctx_db_path = '/staging/leuven/stg_00002/lcb/cbravo/Multiomics_pipeline/analysis/DPCL/ctx_db/cluster_V10_DPCL_feather_v2.regions_vs_motifs.rankings.feather',\n",
    "                 species = 'homo_sapiens',\n",
    "                 save_path = save_path,\n",
    "                 dem_db_path = '/staging/leuven/stg_00002/lcb/cbravo/Multiomics_pipeline/analysis/DPCL/ctx_db/cluster_V10_DPCL_feather_v2.regions_vs_motifs.scores.feather',\n",
    "                 run_without_promoters = True,\n",
    "                 biomart_host = 'http://www.ensembl.org',\n",
    "                 promoter_space = 500,\n",
    "                 ctx_auc_threshold = 0.005,\n",
    "                 ctx_nes_threshold = 3.0,\n",
    "                 ctx_rank_threshold = 0.05,\n",
    "                 dem_log2fc_thr = 0.5,\n",
    "                 dem_motif_hit_thr = 3.0,\n",
    "                 dem_max_bg_regions = 500,\n",
    "                 path_to_motif_annotations = '/staging/leuven/stg_00002/lcb/cbravo/cluster_motif_collection_V10_no_desso_no_factorbook/snapshots/motifs-v10nr_clust-nr.mgi-m0.00001-o0.0.tbl',\n",
    "                 annotation_version = 'v10nr_clust',\n",
    "                 annotation = ['Direct_annot', 'Orthology_annot'],\n",
    "                 n_cpu = 8,\n",
    "                 _temp_dir = '/scratch/leuven/313/vsc31305/ray_spill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d67cf75-a89a-41a7-b5ef-33b2593f7f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --partition=batch\n",
    "#SBATCH --cluster wice\n",
    "#SBATCH --account lp_wice_pilot\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=carmen.bravogonzalezblas@kuleuven.be\n",
    "#SBATCH --ntasks=1\n",
    "\n",
    "#SBATCH --cpus-per-task=20\n",
    "#SBATCH --time=3:00:00\n",
    "#SBATCH --mem=180G\n",
    "\n",
    "#SBATCH --job-name=DPCL_cisTopicObject_10K_fragments_1K_cells\n",
    "#SBATCH --output=DPCL_cisTopicObject_10K_fragments_1K_cells.out\n",
    "#SBATCH --error=DPCL_cisTopicObject_10K_fragments_1K_cells.err\n",
    "\n",
    "singularity exec -B /lustre1,/staging,/data,/vsc-hard-mounts,/scratch,/local_scratch /data/leuven/software/biomed/singularity_images/scenicplus/scenicplus.sif python DPCL_cisTopicObject_10K_fragments_1K_cells.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9106bf-9103-4553-8fd8-141c28acf6a8",
   "metadata": {},
   "source": [
    "# DPCL_cisTopicObject_10K_fragments_10K_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc3a0f7-39b8-4afa-a7f2-9afd3ca31cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import pandas as pd\n",
    "import dill\n",
    "import pyranges as pr\n",
    "from pycistarget.motif_enrichment_cistarget import *\n",
    "from pycistarget.motif_enrichment_dem import *\n",
    "from pycistarget.utils import *\n",
    "import pybiomart as pbm\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "def run_pycistarget(region_sets: Dict[str, pr.PyRanges],\n",
    "                 species: str,\n",
    "                 save_path: str,\n",
    "                 custom_annot: pd.DataFrame = None,\n",
    "                 save_partial: bool = False,\n",
    "                 ctx_db_path: str = None,\n",
    "                 dem_db_path: str = None,\n",
    "                 run_without_promoters: bool = False,\n",
    "                 biomart_host: str = 'http://www.ensembl.org',\n",
    "                 promoter_space: int = 500,\n",
    "                 ctx_auc_threshold: float = 0.005,\n",
    "                 ctx_nes_threshold: float = 3.0,\n",
    "                 ctx_rank_threshold: float = 0.05,\n",
    "                 dem_log2fc_thr: float = 0.5,\n",
    "                 dem_motif_hit_thr: float = 3.0,\n",
    "                 dem_max_bg_regions: int = 500,\n",
    "                 annotation : List[str] = ['Direct_annot', 'Orthology_annot'],\n",
    "                 motif_similarity_fdr: float = 0.000001,\n",
    "                 path_to_motif_annotations: str = None,\n",
    "                 annotation_version: str = 'v9',\n",
    "                 n_cpu : int = 1,\n",
    "                 _temp_dir: str = None,\n",
    "                 exclude_motifs: str = None,\n",
    "                 exclude_collection: List[str] = None,\n",
    "                 **kwargs):\n",
    "    # Create logger\n",
    "    level = logging.INFO\n",
    "    log_format = '%(asctime)s %(name)-12s %(levelname)-8s %(message)s'\n",
    "    handlers = [logging.StreamHandler(stream=sys.stdout)]\n",
    "    logging.basicConfig(level=level, format=log_format, handlers=handlers)\n",
    "    log = logging.getLogger('pycisTarget_wrapper')\n",
    "    \n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    check_folder = os.path.isdir(save_path)\n",
    "    if not check_folder:\n",
    "        os.makedirs(save_path)\n",
    "        log.info(\"Created folder : \" + save_path)\n",
    "    else:\n",
    "        log.info(save_path + \" folder already exists.\")\n",
    "        \n",
    "    def get_species_annotation(species: str):\n",
    "        dataset = pbm.Dataset(name=species,  host=biomart_host)\n",
    "        annot = dataset.query(attributes=['chromosome_name', 'transcription_start_site', 'strand', 'external_gene_name', 'transcript_biotype'])\n",
    "        annot.columns = ['Chromosome', 'Start', 'Strand', 'Gene', 'Transcript_type']\n",
    "        annot['Chromosome'] = annot['Chromosome'].astype('str')\n",
    "        filterf = annot['Chromosome'].str.contains('CHR|GL|JH|MT|KI')\n",
    "        annot = annot[~filterf]\n",
    "        annot['Chromosome'] = annot['Chromosome'].replace(r'(\\b\\S)', r'chr\\1')\n",
    "        annot = annot[annot.Transcript_type == 'protein_coding']\n",
    "        annot = annot.dropna(subset = ['Chromosome', 'Start'])\n",
    "        # Check if chromosomes have chr\n",
    "        check = region_sets[list(region_sets.keys())[0]]\n",
    "        if not any(['chr' in c for c in check[list(check.keys())[0]].df['Chromosome']]):\n",
    "            annot.Chromosome = annot.Chromosome.str.replace('chr', '')\n",
    "        if not any(['chr' in x for x in annot.Chromosome]):\n",
    "            annot.Chromosome = [f'chr{x}' for x in annot.Chromosome]\n",
    "        annot_dem=annot.copy()\n",
    "        # Define promoter space\n",
    "        annot['End'] = annot['Start'].astype(int)+promoter_space\n",
    "        annot['Start'] = annot['Start'].astype(int)-promoter_space\n",
    "        annot = pr.PyRanges(annot[['Chromosome', 'Start', 'End']])\n",
    "        return annot, annot_dem\n",
    "        \n",
    "    # Prepare annotation\n",
    "    if species == 'homo_sapiens':\n",
    "        annot, annot_dem = get_species_annotation('hsapiens_gene_ensembl')\n",
    "    elif species == 'mus_musculus':\n",
    "        annot, annot_dem = get_species_annotation('mmusculus_gene_ensembl')\n",
    "    elif species == 'drosophila_melanogaster':\n",
    "        annot, annot_dem = get_species_annotation('dmelanogaster_gene_ensembl')\n",
    "    elif species == 'gallus_gallus':\n",
    "        annot, annot_dem = get_species_annotation('ggallus_gene_ensembl')\n",
    "    elif species == 'custom':\n",
    "        annot_dem = custom_annot\n",
    "        annot = annot_dem.copy()\n",
    "        # Define promoter space\n",
    "        annot['End'] = annot['Start'].astype(int)+promoter_space\n",
    "        annot['Start'] = annot['Start'].astype(int)-promoter_space\n",
    "        annot = pr.PyRanges(annot[['Chromosome', 'Start', 'End']])\n",
    "    else:\n",
    "        raise TypeError(\"Species not recognized\")\n",
    "\n",
    "    menr = {}\n",
    "    for key in region_sets.keys():\n",
    "        if ctx_db_path is not None:\n",
    "            log.info('Loading cisTarget database for ' + key)\n",
    "            ## CISTARGET\n",
    "            regions = region_sets[key]\n",
    "            ctx_db = cisTargetDatabase(ctx_db_path, regions)  \n",
    "            if exclude_motifs is not None:\n",
    "                out = pd.read_csv(exclude_motifs, header=None).iloc[:,0].tolist()\n",
    "                ctx_db.db_rankings = ctx_db.db_rankings.drop(out)\n",
    "            if exclude_collection is not None:\n",
    "                for col in exclude_collection:\n",
    "                    ctx_db.db_rankings = ctx_db.db_rankings[~ctx_db.db_rankings.index.str.contains(col)]\n",
    "            ## DEFAULT\n",
    "            import time\n",
    "            t1_start = time.time()\n",
    "            log.info('Running cisTarget for '+key)\n",
    "            menr['CTX_'+key+'_All'] = run_cistarget(ctx_db = ctx_db,\n",
    "                                   region_sets = regions,\n",
    "                                   specie = species,\n",
    "                                   auc_threshold = ctx_auc_threshold,\n",
    "                                   nes_threshold = ctx_nes_threshold,\n",
    "                                   rank_threshold = ctx_rank_threshold,\n",
    "                                   annotation = annotation,\n",
    "                                   motif_similarity_fdr = motif_similarity_fdr,\n",
    "                                   path_to_motif_annotations = path_to_motif_annotations,\n",
    "                                   n_cpu = n_cpu,\n",
    "                                   _temp_dir= _temp_dir,\n",
    "                                   annotation_version = annotation_version,\n",
    "                                   **kwargs)\n",
    "            m1=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "            t1_stop = time.time()\n",
    "            time_ctx_all = t1_stop-t1_start\n",
    "            out_folder = os.path.join(save_path,'CTX_'+key+'_All')\n",
    "            check_folder = os.path.isdir(out_folder)\n",
    "            if not check_folder:\n",
    "                os.makedirs(out_folder)\n",
    "                log.info(\"Created folder : \" + out_folder)\n",
    "            else:\n",
    "                log.info(out_folder + \" folder already exists.\")\n",
    "            for x in menr['CTX_'+key+'_All'].keys():\n",
    "                out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                menr['CTX_'+key+'_All'][str(x)].motif_enrichment.to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "            if(save_partial):\n",
    "                with open(os.path.join(save_path,'CTX_'+key+'_All' + '.pkl'), 'wb') as f:\n",
    "                    dill.dump(menr['CTX_'+key+'_All'], f, protocol=-1)\n",
    "\n",
    "            if run_without_promoters is True:\n",
    "                ## REMOVE PROMOTERS\n",
    "                log.info('Running cisTarget without promoters for '+key)\n",
    "                regions_overlaps = {key: regions[key].count_overlaps(annot) for key in regions.keys()}\n",
    "                regions_np = {key: regions_overlaps[key][regions_overlaps[key].NumberOverlaps == 0][['Chromosome', 'Start', 'End']] for key in regions.keys()}\n",
    "                db_regions = set(pd.concat([ctx_db.regions_to_db[x] for x in ctx_db.regions_to_db.keys()])['Query'])\n",
    "                ctx_db.regions_to_db = {x: target_to_query(regions_np[x], list(db_regions), fraction_overlap = 0.4) for x in regions_np.keys()}\n",
    "                t1_start = time.time()\n",
    "                menr['CTX_'+key+'_No_promoters'] = run_cistarget(ctx_db = ctx_db,\n",
    "                                   region_sets = regions_np,\n",
    "                                   specie = species,\n",
    "                                   auc_threshold = ctx_auc_threshold,\n",
    "                                   nes_threshold = ctx_nes_threshold,\n",
    "                                   rank_threshold = ctx_rank_threshold,\n",
    "                                   annotation = annotation,\n",
    "                                   motif_similarity_fdr = motif_similarity_fdr, \n",
    "                                   path_to_motif_annotations = path_to_motif_annotations,\n",
    "                                   n_cpu = n_cpu,\n",
    "                                   _temp_dir= _temp_dir,\n",
    "                                   annotation_version = annotation_version,\n",
    "                                   **kwargs)\n",
    "                m2=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "                t1_stop = time.time()\n",
    "                time_ctx_np = t1_stop-t1_start\n",
    "                out_folder = os.path.join(save_path,'CTX_'+key+'_No_promoters')\n",
    "                check_folder = os.path.isdir(out_folder)\n",
    "                if not check_folder:\n",
    "                    os.makedirs(out_folder)\n",
    "                    log.info(\"Created folder:\" + out_folder)\n",
    "                else:\n",
    "                    log.info(out_folder + \" folder already exists.\")\n",
    "                for x in menr['CTX_'+key+'_No_promoters'].keys():\n",
    "                    out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                    menr['CTX_'+key+'_No_promoters'][str(x)].motif_enrichment.to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "                \n",
    "                if(save_partial):\n",
    "                    with open(os.path.join(save_path,'CTX_'+key+'_No_promoters' + '.pkl'), 'wb') as f:\n",
    "                      dill.dump(menr['CTX_'+key+'_No_promoters'], f, protocol=-1)\n",
    "        ## DEM\n",
    "        if dem_db_path is not None:\n",
    "            log.info('Running DEM for '+key)\n",
    "            regions = region_sets[key]\n",
    "            dem_db = DEMDatabase(dem_db_path, regions)  \n",
    "            if exclude_motifs is not None:\n",
    "                out = pd.read_csv(exclude_motifs, header=None).iloc[:,0].tolist()\n",
    "                dem_db.db_scores = dem_db.db_scores.drop(out)\n",
    "            if exclude_collection is not None:\n",
    "                for col in exclude_collection:\n",
    "                    dem_db.db_scores = dem_db.db_scores[~dem_db.db_scores.index.str.contains(col)]\n",
    "            t1_start = time.time()\n",
    "            menr['DEM_'+key+'_All'] = DEM(dem_db = dem_db,\n",
    "                               region_sets = regions,\n",
    "                               log2fc_thr = dem_log2fc_thr,\n",
    "                               motif_hit_thr = dem_motif_hit_thr,\n",
    "                               max_bg_regions = dem_max_bg_regions,\n",
    "                               specie = species,\n",
    "                               genome_annotation = annot_dem,\n",
    "                               promoter_space = promoter_space,\n",
    "                               motif_annotation =   annotation,\n",
    "                               motif_similarity_fdr = motif_similarity_fdr, \n",
    "                               path_to_motif_annotations = path_to_motif_annotations,\n",
    "                               n_cpu = n_cpu,\n",
    "                               annotation_version = annotation_version,\n",
    "                               tmp_dir = save_path,\n",
    "                               _temp_dir= _temp_dir,\n",
    "                               **kwargs)\n",
    "            m3=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "            t1_stop = time.time()\n",
    "            time_dem_all = t1_stop-t1_start\n",
    "            out_folder = os.path.join(save_path,'DEM_'+key+'_All')\n",
    "            check_folder = os.path.isdir(out_folder)\n",
    "            if not check_folder:\n",
    "                os.makedirs(out_folder)\n",
    "                log.info(\"Created folder : \"+ out_folder)\n",
    "            else:\n",
    "                log.info(out_folder + \" folder already exists.\")\n",
    "            for x in menr['DEM_'+key+'_All'].motif_enrichment.keys():\n",
    "                out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                menr['DEM_'+key+'_All'].motif_enrichment[str(x)].to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "            if(save_partial):\n",
    "                with open(os.path.join(save_path, 'DEM_'+key+'_All'+'.pkl'), 'wb') as f:\n",
    "                  dill.dump(menr['DEM_'+key+'_All'], f, protocol=-1)\n",
    "                \n",
    "            if run_without_promoters is True:\n",
    "                log.info('Running DEM without promoters for '+key)\n",
    "                ## REMOVE PROMOTERS\n",
    "                regions_overlaps = {key: regions[key].count_overlaps(annot) for key in regions.keys()}\n",
    "                regions_np = {key: regions_overlaps[key][regions_overlaps[key].NumberOverlaps == 0][['Chromosome', 'Start', 'End']] for key in regions.keys()}\n",
    "                db_regions = set(pd.concat([dem_db.regions_to_db[x] for x in dem_db.regions_to_db.keys()])['Query'])\n",
    "                dem_db.regions_to_db = {x: target_to_query(regions_np[x], list(db_regions), fraction_overlap = 0.4) for x in regions_np.keys()}\n",
    "                t1_start = time.time()\n",
    "                menr['DEM_'+key+'_No_promoters'] = DEM(dem_db = dem_db,\n",
    "                               region_sets = regions_np,\n",
    "                               log2fc_thr = dem_log2fc_thr,\n",
    "                               motif_hit_thr = dem_motif_hit_thr,\n",
    "                               max_bg_regions = dem_max_bg_regions,\n",
    "                               specie = species,\n",
    "                               promoter_space = promoter_space,\n",
    "                               motif_annotation = annotation,\n",
    "                               motif_similarity_fdr = motif_similarity_fdr, \n",
    "                               path_to_motif_annotations = path_to_motif_annotations,\n",
    "                               n_cpu = n_cpu,\n",
    "                               annotation_version = annotation_version,\n",
    "                               tmp_dir = save_path,\n",
    "                               _temp_dir= _temp_dir,\n",
    "                               **kwargs)\n",
    "                m4=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "                t1_stop = time.time()\n",
    "                time_dem_np = t1_stop-t1_start\n",
    "                out_folder = os.path.join(save_path,'DEM_'+key+'_No_promoters')\n",
    "                check_folder = os.path.isdir(out_folder)\n",
    "                if not check_folder:\n",
    "                    os.makedirs(out_folder)\n",
    "                    log.info(\"Created folder : \"+ out_folder)\n",
    "                else:\n",
    "                    log.info(out_folder + \" folder already exists.\")\n",
    "                for x in menr['DEM_'+key+'_No_promoters'].motif_enrichment.keys():\n",
    "                    out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                    menr['DEM_'+key+'_No_promoters'].motif_enrichment[str(x)].to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "                if(save_partial):\n",
    "                    with open(os.path.join(save_path, 'DEM_'+key+'_No_promoters'+'.pkl'), 'wb') as f:\n",
    "                      dill.dump(menr['DEM_'+key+'_All'], f, protocol=-1)\n",
    "                    \n",
    "        times = [time_ctx_all, time_ctx_np, time_dem_all, time_dem_np]\n",
    "        df = pd.DataFrame(times, index=['CTX_all', 'CTX_np', 'DEM_all', 'DEM_np'], columns=['Time'])\n",
    "        df.to_csv(save_path+key+'running_times.tsv', sep='\\t') \n",
    "        memory=[m1,m2,m3,m4]\n",
    "        df = pd.DataFrame(memory, index=['CTX_all', 'CTX_np', 'DEM_all', 'DEM_np'], columns=['Memory'])\n",
    "        df.to_csv(save_path+key+'cummulative_memory.tsv', sep='\\t')  \n",
    "        memory=[m1,m2-m1,m3-m2,m4-m3]\n",
    "        df = pd.DataFrame(memory, index=['CTX_all', 'CTX_np', 'DEM_all', 'DEM_np'], columns=['Memory'])\n",
    "        df.to_csv(save_path+key+'memory_per_step.tsv', sep='\\t')  \n",
    "                    \n",
    "    log.info('Saving object')         \n",
    "    with open(os.path.join(save_path,'menr.pkl'), 'wb') as f:\n",
    "        dill.dump(menr, f, protocol=-1)\n",
    "    \n",
    "    import time\n",
    "    log.info('Finished! Took {} minutes'.format((time.time() - start_time)/60)) \n",
    "            \n",
    "# Load region binarized topics\n",
    "import pickle\n",
    "outDir = '/staging/leuven/stg_00002/lcb/cbravo/Multiomics_pipeline/analysis/DPCL/speed_benchmark/medium_simulation/DPCL_cisTopicObject_10K_fragments_10K_cells/'\n",
    "infile = open(outDir+'binarized_topic_region.pkl', 'rb')\n",
    "binarized_topic_region = pickle.load(infile)\n",
    "infile.close()\n",
    "# Load DARs\n",
    "import pickle\n",
    "infile = open(outDir+'DARs.pkl', 'rb')\n",
    "DARs_dict = pickle.load(infile)\n",
    "infile.close()\n",
    "# Format region sets\n",
    "import re\n",
    "import pyranges as pr\n",
    "from pycistarget.utils import *\n",
    "region_sets = {}\n",
    "region_sets['Topics'] = {key: pr.PyRanges(region_names_to_coordinates(binarized_topic_region[key].index.tolist())) for key in binarized_topic_region.keys()}\n",
    "region_sets['DARs'] = {re.sub('[^A-Za-z0-9]+', '_', key): pr.PyRanges(region_names_to_coordinates(DARs_dict[key].index.tolist())) for key in DARs_dict.keys()}\n",
    "# Create save_path\n",
    "save_path = outDir + 'pycistarget/'\n",
    "# Create save_Dir\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "\n",
    "# Run pycistarget\n",
    "run_pycistarget(region_sets,\n",
    "                 ctx_db_path = '/staging/leuven/stg_00002/lcb/cbravo/Multiomics_pipeline/analysis/DPCL/ctx_db/cluster_V10_DPCL_feather_v2.regions_vs_motifs.rankings.feather',\n",
    "                 species = 'homo_sapiens',\n",
    "                 save_path = save_path,\n",
    "                 dem_db_path = '/staging/leuven/stg_00002/lcb/cbravo/Multiomics_pipeline/analysis/DPCL/ctx_db/cluster_V10_DPCL_feather_v2.regions_vs_motifs.scores.feather',\n",
    "                 run_without_promoters = True,\n",
    "                 biomart_host = 'http://www.ensembl.org',\n",
    "                 promoter_space = 500,\n",
    "                 ctx_auc_threshold = 0.005,\n",
    "                 ctx_nes_threshold = 3.0,\n",
    "                 ctx_rank_threshold = 0.05,\n",
    "                 dem_log2fc_thr = 0.5,\n",
    "                 dem_motif_hit_thr = 3.0,\n",
    "                 dem_max_bg_regions = 500,\n",
    "                 path_to_motif_annotations = '/staging/leuven/stg_00002/lcb/cbravo/cluster_motif_collection_V10_no_desso_no_factorbook/snapshots/motifs-v10nr_clust-nr.mgi-m0.00001-o0.0.tbl',\n",
    "                 annotation_version = 'v10nr_clust',\n",
    "                 annotation = ['Direct_annot', 'Orthology_annot'],\n",
    "                 n_cpu = 8,\n",
    "                 _temp_dir = '/scratch/leuven/313/vsc31305/ray_spill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315e6d92-4b18-4b13-b653-70731056e273",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --partition=batch\n",
    "#SBATCH --cluster wice\n",
    "#SBATCH --account lp_wice_pilot\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=carmen.bravogonzalezblas@kuleuven.be\n",
    "#SBATCH --ntasks=1\n",
    "\n",
    "#SBATCH --cpus-per-task=20\n",
    "#SBATCH --time=3:00:00\n",
    "#SBATCH --mem=180G\n",
    "\n",
    "#SBATCH --job-name=DPCL_cisTopicObject_10K_fragments_10K_cells\n",
    "#SBATCH --output=DPCL_cisTopicObject_10K_fragments_10K_cells.out\n",
    "#SBATCH --error=DPCL_cisTopicObject_10K_fragments_10K_cells.err\n",
    "\n",
    "singularity exec -B /lustre1,/staging,/data,/vsc-hard-mounts,/scratch,/local_scratch /data/leuven/software/biomed/singularity_images/scenicplus/scenicplus.sif python DPCL_cisTopicObject_10K_fragments_10K_cells.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0024bee3-c5f4-410d-97f2-348fcb2aba6d",
   "metadata": {},
   "source": [
    "# DPCL_cisTopicObject_10K_fragments_25K_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bae8451-090d-45aa-a469-7ba26dcedb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import pandas as pd\n",
    "import dill\n",
    "import pyranges as pr\n",
    "from pycistarget.motif_enrichment_cistarget import *\n",
    "from pycistarget.motif_enrichment_dem import *\n",
    "from pycistarget.utils import *\n",
    "import pybiomart as pbm\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "def run_pycistarget(region_sets: Dict[str, pr.PyRanges],\n",
    "                 species: str,\n",
    "                 save_path: str,\n",
    "                 custom_annot: pd.DataFrame = None,\n",
    "                 save_partial: bool = False,\n",
    "                 ctx_db_path: str = None,\n",
    "                 dem_db_path: str = None,\n",
    "                 run_without_promoters: bool = False,\n",
    "                 biomart_host: str = 'http://www.ensembl.org',\n",
    "                 promoter_space: int = 500,\n",
    "                 ctx_auc_threshold: float = 0.005,\n",
    "                 ctx_nes_threshold: float = 3.0,\n",
    "                 ctx_rank_threshold: float = 0.05,\n",
    "                 dem_log2fc_thr: float = 0.5,\n",
    "                 dem_motif_hit_thr: float = 3.0,\n",
    "                 dem_max_bg_regions: int = 500,\n",
    "                 annotation : List[str] = ['Direct_annot', 'Orthology_annot'],\n",
    "                 motif_similarity_fdr: float = 0.000001,\n",
    "                 path_to_motif_annotations: str = None,\n",
    "                 annotation_version: str = 'v9',\n",
    "                 n_cpu : int = 1,\n",
    "                 _temp_dir: str = None,\n",
    "                 exclude_motifs: str = None,\n",
    "                 exclude_collection: List[str] = None,\n",
    "                 **kwargs):\n",
    "    # Create logger\n",
    "    level = logging.INFO\n",
    "    log_format = '%(asctime)s %(name)-12s %(levelname)-8s %(message)s'\n",
    "    handlers = [logging.StreamHandler(stream=sys.stdout)]\n",
    "    logging.basicConfig(level=level, format=log_format, handlers=handlers)\n",
    "    log = logging.getLogger('pycisTarget_wrapper')\n",
    "    \n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    check_folder = os.path.isdir(save_path)\n",
    "    if not check_folder:\n",
    "        os.makedirs(save_path)\n",
    "        log.info(\"Created folder : \" + save_path)\n",
    "    else:\n",
    "        log.info(save_path + \" folder already exists.\")\n",
    "        \n",
    "    def get_species_annotation(species: str):\n",
    "        dataset = pbm.Dataset(name=species,  host=biomart_host)\n",
    "        annot = dataset.query(attributes=['chromosome_name', 'transcription_start_site', 'strand', 'external_gene_name', 'transcript_biotype'])\n",
    "        annot.columns = ['Chromosome', 'Start', 'Strand', 'Gene', 'Transcript_type']\n",
    "        annot['Chromosome'] = annot['Chromosome'].astype('str')\n",
    "        filterf = annot['Chromosome'].str.contains('CHR|GL|JH|MT|KI')\n",
    "        annot = annot[~filterf]\n",
    "        annot['Chromosome'] = annot['Chromosome'].replace(r'(\\b\\S)', r'chr\\1')\n",
    "        annot = annot[annot.Transcript_type == 'protein_coding']\n",
    "        annot = annot.dropna(subset = ['Chromosome', 'Start'])\n",
    "        # Check if chromosomes have chr\n",
    "        check = region_sets[list(region_sets.keys())[0]]\n",
    "        if not any(['chr' in c for c in check[list(check.keys())[0]].df['Chromosome']]):\n",
    "            annot.Chromosome = annot.Chromosome.str.replace('chr', '')\n",
    "        if not any(['chr' in x for x in annot.Chromosome]):\n",
    "            annot.Chromosome = [f'chr{x}' for x in annot.Chromosome]\n",
    "        annot_dem=annot.copy()\n",
    "        # Define promoter space\n",
    "        annot['End'] = annot['Start'].astype(int)+promoter_space\n",
    "        annot['Start'] = annot['Start'].astype(int)-promoter_space\n",
    "        annot = pr.PyRanges(annot[['Chromosome', 'Start', 'End']])\n",
    "        return annot, annot_dem\n",
    "        \n",
    "    # Prepare annotation\n",
    "    if species == 'homo_sapiens':\n",
    "        annot, annot_dem = get_species_annotation('hsapiens_gene_ensembl')\n",
    "    elif species == 'mus_musculus':\n",
    "        annot, annot_dem = get_species_annotation('mmusculus_gene_ensembl')\n",
    "    elif species == 'drosophila_melanogaster':\n",
    "        annot, annot_dem = get_species_annotation('dmelanogaster_gene_ensembl')\n",
    "    elif species == 'gallus_gallus':\n",
    "        annot, annot_dem = get_species_annotation('ggallus_gene_ensembl')\n",
    "    elif species == 'custom':\n",
    "        annot_dem = custom_annot\n",
    "        annot = annot_dem.copy()\n",
    "        # Define promoter space\n",
    "        annot['End'] = annot['Start'].astype(int)+promoter_space\n",
    "        annot['Start'] = annot['Start'].astype(int)-promoter_space\n",
    "        annot = pr.PyRanges(annot[['Chromosome', 'Start', 'End']])\n",
    "    else:\n",
    "        raise TypeError(\"Species not recognized\")\n",
    "\n",
    "    menr = {}\n",
    "    for key in region_sets.keys():\n",
    "        if ctx_db_path is not None:\n",
    "            log.info('Loading cisTarget database for ' + key)\n",
    "            ## CISTARGET\n",
    "            regions = region_sets[key]\n",
    "            ctx_db = cisTargetDatabase(ctx_db_path, regions)  \n",
    "            if exclude_motifs is not None:\n",
    "                out = pd.read_csv(exclude_motifs, header=None).iloc[:,0].tolist()\n",
    "                ctx_db.db_rankings = ctx_db.db_rankings.drop(out)\n",
    "            if exclude_collection is not None:\n",
    "                for col in exclude_collection:\n",
    "                    ctx_db.db_rankings = ctx_db.db_rankings[~ctx_db.db_rankings.index.str.contains(col)]\n",
    "            ## DEFAULT\n",
    "            import time\n",
    "            t1_start = time.time()\n",
    "            log.info('Running cisTarget for '+key)\n",
    "            menr['CTX_'+key+'_All'] = run_cistarget(ctx_db = ctx_db,\n",
    "                                   region_sets = regions,\n",
    "                                   specie = species,\n",
    "                                   auc_threshold = ctx_auc_threshold,\n",
    "                                   nes_threshold = ctx_nes_threshold,\n",
    "                                   rank_threshold = ctx_rank_threshold,\n",
    "                                   annotation = annotation,\n",
    "                                   motif_similarity_fdr = motif_similarity_fdr,\n",
    "                                   path_to_motif_annotations = path_to_motif_annotations,\n",
    "                                   n_cpu = n_cpu,\n",
    "                                   _temp_dir= _temp_dir,\n",
    "                                   annotation_version = annotation_version,\n",
    "                                   **kwargs)\n",
    "            m1=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "            t1_stop = time.time()\n",
    "            time_ctx_all = t1_stop-t1_start\n",
    "            out_folder = os.path.join(save_path,'CTX_'+key+'_All')\n",
    "            check_folder = os.path.isdir(out_folder)\n",
    "            if not check_folder:\n",
    "                os.makedirs(out_folder)\n",
    "                log.info(\"Created folder : \" + out_folder)\n",
    "            else:\n",
    "                log.info(out_folder + \" folder already exists.\")\n",
    "            for x in menr['CTX_'+key+'_All'].keys():\n",
    "                out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                menr['CTX_'+key+'_All'][str(x)].motif_enrichment.to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "            if(save_partial):\n",
    "                with open(os.path.join(save_path,'CTX_'+key+'_All' + '.pkl'), 'wb') as f:\n",
    "                    dill.dump(menr['CTX_'+key+'_All'], f, protocol=-1)\n",
    "\n",
    "            if run_without_promoters is True:\n",
    "                ## REMOVE PROMOTERS\n",
    "                log.info('Running cisTarget without promoters for '+key)\n",
    "                regions_overlaps = {key: regions[key].count_overlaps(annot) for key in regions.keys()}\n",
    "                regions_np = {key: regions_overlaps[key][regions_overlaps[key].NumberOverlaps == 0][['Chromosome', 'Start', 'End']] for key in regions.keys()}\n",
    "                db_regions = set(pd.concat([ctx_db.regions_to_db[x] for x in ctx_db.regions_to_db.keys()])['Query'])\n",
    "                ctx_db.regions_to_db = {x: target_to_query(regions_np[x], list(db_regions), fraction_overlap = 0.4) for x in regions_np.keys()}\n",
    "                t1_start = time.time()\n",
    "                menr['CTX_'+key+'_No_promoters'] = run_cistarget(ctx_db = ctx_db,\n",
    "                                   region_sets = regions_np,\n",
    "                                   specie = species,\n",
    "                                   auc_threshold = ctx_auc_threshold,\n",
    "                                   nes_threshold = ctx_nes_threshold,\n",
    "                                   rank_threshold = ctx_rank_threshold,\n",
    "                                   annotation = annotation,\n",
    "                                   motif_similarity_fdr = motif_similarity_fdr, \n",
    "                                   path_to_motif_annotations = path_to_motif_annotations,\n",
    "                                   n_cpu = n_cpu,\n",
    "                                   _temp_dir= _temp_dir,\n",
    "                                   annotation_version = annotation_version,\n",
    "                                   **kwargs)\n",
    "                m2=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "                t1_stop = time.time()\n",
    "                time_ctx_np = t1_stop-t1_start\n",
    "                out_folder = os.path.join(save_path,'CTX_'+key+'_No_promoters')\n",
    "                check_folder = os.path.isdir(out_folder)\n",
    "                if not check_folder:\n",
    "                    os.makedirs(out_folder)\n",
    "                    log.info(\"Created folder:\" + out_folder)\n",
    "                else:\n",
    "                    log.info(out_folder + \" folder already exists.\")\n",
    "                for x in menr['CTX_'+key+'_No_promoters'].keys():\n",
    "                    out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                    menr['CTX_'+key+'_No_promoters'][str(x)].motif_enrichment.to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "                \n",
    "                if(save_partial):\n",
    "                    with open(os.path.join(save_path,'CTX_'+key+'_No_promoters' + '.pkl'), 'wb') as f:\n",
    "                      dill.dump(menr['CTX_'+key+'_No_promoters'], f, protocol=-1)\n",
    "        ## DEM\n",
    "        if dem_db_path is not None:\n",
    "            log.info('Running DEM for '+key)\n",
    "            regions = region_sets[key]\n",
    "            dem_db = DEMDatabase(dem_db_path, regions)  \n",
    "            if exclude_motifs is not None:\n",
    "                out = pd.read_csv(exclude_motifs, header=None).iloc[:,0].tolist()\n",
    "                dem_db.db_scores = dem_db.db_scores.drop(out)\n",
    "            if exclude_collection is not None:\n",
    "                for col in exclude_collection:\n",
    "                    dem_db.db_scores = dem_db.db_scores[~dem_db.db_scores.index.str.contains(col)]\n",
    "            t1_start = time.time()\n",
    "            menr['DEM_'+key+'_All'] = DEM(dem_db = dem_db,\n",
    "                               region_sets = regions,\n",
    "                               log2fc_thr = dem_log2fc_thr,\n",
    "                               motif_hit_thr = dem_motif_hit_thr,\n",
    "                               max_bg_regions = dem_max_bg_regions,\n",
    "                               specie = species,\n",
    "                               genome_annotation = annot_dem,\n",
    "                               promoter_space = promoter_space,\n",
    "                               motif_annotation =   annotation,\n",
    "                               motif_similarity_fdr = motif_similarity_fdr, \n",
    "                               path_to_motif_annotations = path_to_motif_annotations,\n",
    "                               n_cpu = n_cpu,\n",
    "                               annotation_version = annotation_version,\n",
    "                               tmp_dir = save_path,\n",
    "                               _temp_dir= _temp_dir,\n",
    "                               **kwargs)\n",
    "            m3=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "            t1_stop = time.time()\n",
    "            time_dem_all = t1_stop-t1_start\n",
    "            out_folder = os.path.join(save_path,'DEM_'+key+'_All')\n",
    "            check_folder = os.path.isdir(out_folder)\n",
    "            if not check_folder:\n",
    "                os.makedirs(out_folder)\n",
    "                log.info(\"Created folder : \"+ out_folder)\n",
    "            else:\n",
    "                log.info(out_folder + \" folder already exists.\")\n",
    "            for x in menr['DEM_'+key+'_All'].motif_enrichment.keys():\n",
    "                out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                menr['DEM_'+key+'_All'].motif_enrichment[str(x)].to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "            if(save_partial):\n",
    "                with open(os.path.join(save_path, 'DEM_'+key+'_All'+'.pkl'), 'wb') as f:\n",
    "                  dill.dump(menr['DEM_'+key+'_All'], f, protocol=-1)\n",
    "                \n",
    "            if run_without_promoters is True:\n",
    "                log.info('Running DEM without promoters for '+key)\n",
    "                ## REMOVE PROMOTERS\n",
    "                regions_overlaps = {key: regions[key].count_overlaps(annot) for key in regions.keys()}\n",
    "                regions_np = {key: regions_overlaps[key][regions_overlaps[key].NumberOverlaps == 0][['Chromosome', 'Start', 'End']] for key in regions.keys()}\n",
    "                db_regions = set(pd.concat([dem_db.regions_to_db[x] for x in dem_db.regions_to_db.keys()])['Query'])\n",
    "                dem_db.regions_to_db = {x: target_to_query(regions_np[x], list(db_regions), fraction_overlap = 0.4) for x in regions_np.keys()}\n",
    "                t1_start = time.time()\n",
    "                menr['DEM_'+key+'_No_promoters'] = DEM(dem_db = dem_db,\n",
    "                               region_sets = regions_np,\n",
    "                               log2fc_thr = dem_log2fc_thr,\n",
    "                               motif_hit_thr = dem_motif_hit_thr,\n",
    "                               max_bg_regions = dem_max_bg_regions,\n",
    "                               specie = species,\n",
    "                               promoter_space = promoter_space,\n",
    "                               motif_annotation = annotation,\n",
    "                               motif_similarity_fdr = motif_similarity_fdr, \n",
    "                               path_to_motif_annotations = path_to_motif_annotations,\n",
    "                               n_cpu = n_cpu,\n",
    "                               annotation_version = annotation_version,\n",
    "                               tmp_dir = save_path,\n",
    "                               _temp_dir= _temp_dir,\n",
    "                               **kwargs)\n",
    "                m4=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "                t1_stop = time.time()\n",
    "                time_dem_np = t1_stop-t1_start\n",
    "                out_folder = os.path.join(save_path,'DEM_'+key+'_No_promoters')\n",
    "                check_folder = os.path.isdir(out_folder)\n",
    "                if not check_folder:\n",
    "                    os.makedirs(out_folder)\n",
    "                    log.info(\"Created folder : \"+ out_folder)\n",
    "                else:\n",
    "                    log.info(out_folder + \" folder already exists.\")\n",
    "                for x in menr['DEM_'+key+'_No_promoters'].motif_enrichment.keys():\n",
    "                    out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                    menr['DEM_'+key+'_No_promoters'].motif_enrichment[str(x)].to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "                if(save_partial):\n",
    "                    with open(os.path.join(save_path, 'DEM_'+key+'_No_promoters'+'.pkl'), 'wb') as f:\n",
    "                      dill.dump(menr['DEM_'+key+'_All'], f, protocol=-1)\n",
    "                    \n",
    "        times = [time_ctx_all, time_ctx_np, time_dem_all, time_dem_np]\n",
    "        df = pd.DataFrame(times, index=['CTX_all', 'CTX_np', 'DEM_all', 'DEM_np'], columns=['Time'])\n",
    "        df.to_csv(save_path+key+'running_times.tsv', sep='\\t') \n",
    "        memory=[m1,m2,m3,m4]\n",
    "        df = pd.DataFrame(memory, index=['CTX_all', 'CTX_np', 'DEM_all', 'DEM_np'], columns=['Memory'])\n",
    "        df.to_csv(save_path+key+'cummulative_memory.tsv', sep='\\t')  \n",
    "        memory=[m1,m2-m1,m3-m2,m4-m3]\n",
    "        df = pd.DataFrame(memory, index=['CTX_all', 'CTX_np', 'DEM_all', 'DEM_np'], columns=['Memory'])\n",
    "        df.to_csv(save_path+key+'memory_per_step.tsv', sep='\\t')  \n",
    "                    \n",
    "    log.info('Saving object')         \n",
    "    with open(os.path.join(save_path,'menr.pkl'), 'wb') as f:\n",
    "        dill.dump(menr, f, protocol=-1)\n",
    "    \n",
    "    import time\n",
    "    log.info('Finished! Took {} minutes'.format((time.time() - start_time)/60)) \n",
    "            \n",
    "# Load region binarized topics\n",
    "import pickle\n",
    "outDir = '/staging/leuven/stg_00002/lcb/cbravo/Multiomics_pipeline/analysis/DPCL/speed_benchmark/medium_simulation/DPCL_cisTopicObject_10K_fragments_25K_cells/'\n",
    "infile = open(outDir+'binarized_topic_region.pkl', 'rb')\n",
    "binarized_topic_region = pickle.load(infile)\n",
    "infile.close()\n",
    "# Load DARs\n",
    "import pickle\n",
    "infile = open(outDir+'DARs.pkl', 'rb')\n",
    "DARs_dict = pickle.load(infile)\n",
    "infile.close()\n",
    "# Format region sets\n",
    "import re\n",
    "import pyranges as pr\n",
    "from pycistarget.utils import *\n",
    "region_sets = {}\n",
    "region_sets['Topics'] = {key: pr.PyRanges(region_names_to_coordinates(binarized_topic_region[key].index.tolist())) for key in binarized_topic_region.keys()}\n",
    "region_sets['DARs'] = {re.sub('[^A-Za-z0-9]+', '_', key): pr.PyRanges(region_names_to_coordinates(DARs_dict[key].index.tolist())) for key in DARs_dict.keys()}\n",
    "# Create save_path\n",
    "save_path = outDir + 'pycistarget/'\n",
    "# Create save_Dir\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "\n",
    "# Run pycistarget\n",
    "run_pycistarget(region_sets,\n",
    "                 ctx_db_path = '/staging/leuven/stg_00002/lcb/cbravo/Multiomics_pipeline/analysis/DPCL/ctx_db/cluster_V10_DPCL_feather_v2.regions_vs_motifs.rankings.feather',\n",
    "                 species = 'homo_sapiens',\n",
    "                 save_path = save_path,\n",
    "                 dem_db_path = '/staging/leuven/stg_00002/lcb/cbravo/Multiomics_pipeline/analysis/DPCL/ctx_db/cluster_V10_DPCL_feather_v2.regions_vs_motifs.scores.feather',\n",
    "                 run_without_promoters = True,\n",
    "                 biomart_host = 'http://www.ensembl.org',\n",
    "                 promoter_space = 500,\n",
    "                 ctx_auc_threshold = 0.005,\n",
    "                 ctx_nes_threshold = 3.0,\n",
    "                 ctx_rank_threshold = 0.05,\n",
    "                 dem_log2fc_thr = 0.5,\n",
    "                 dem_motif_hit_thr = 3.0,\n",
    "                 dem_max_bg_regions = 500,\n",
    "                 path_to_motif_annotations = '/staging/leuven/stg_00002/lcb/cbravo/cluster_motif_collection_V10_no_desso_no_factorbook/snapshots/motifs-v10nr_clust-nr.mgi-m0.00001-o0.0.tbl',\n",
    "                 annotation_version = 'v10nr_clust',\n",
    "                 annotation = ['Direct_annot', 'Orthology_annot'],\n",
    "                 n_cpu = 8,\n",
    "                 _temp_dir = '/scratch/leuven/313/vsc31305/ray_spill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0bb350-f44d-4033-9d28-653946556d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --partition=batch\n",
    "#SBATCH --cluster wice\n",
    "#SBATCH --account lp_wice_pilot\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=carmen.bravogonzalezblas@kuleuven.be\n",
    "#SBATCH --ntasks=1\n",
    "\n",
    "#SBATCH --cpus-per-task=20\n",
    "#SBATCH --time=3:00:00\n",
    "#SBATCH --mem=180G\n",
    "\n",
    "#SBATCH --job-name=DPCL_cisTopicObject_10K_fragments_25K_cells\n",
    "#SBATCH --output=DPCL_cisTopicObject_10K_fragments_25K_cells.out\n",
    "#SBATCH --error=DPCL_cisTopicObject_10K_fragments_25K_cells.err\n",
    "\n",
    "singularity exec -B /lustre1,/staging,/data,/vsc-hard-mounts,/scratch,/local_scratch /data/leuven/software/biomed/singularity_images/scenicplus/scenicplus.sif python DPCL_cisTopicObject_10K_fragments_25K_cells.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8586bea-2dde-49f8-9f15-828bff98f15c",
   "metadata": {},
   "source": [
    "# DPCL_cisTopicObject_20K_fragments_80_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4217ec2a-df07-46fc-994b-724244a7376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import pandas as pd\n",
    "import dill\n",
    "import pyranges as pr\n",
    "from pycistarget.motif_enrichment_cistarget import *\n",
    "from pycistarget.motif_enrichment_dem import *\n",
    "from pycistarget.utils import *\n",
    "import pybiomart as pbm\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "def run_pycistarget(region_sets: Dict[str, pr.PyRanges],\n",
    "                 species: str,\n",
    "                 save_path: str,\n",
    "                 custom_annot: pd.DataFrame = None,\n",
    "                 save_partial: bool = False,\n",
    "                 ctx_db_path: str = None,\n",
    "                 dem_db_path: str = None,\n",
    "                 run_without_promoters: bool = False,\n",
    "                 biomart_host: str = 'http://www.ensembl.org',\n",
    "                 promoter_space: int = 500,\n",
    "                 ctx_auc_threshold: float = 0.005,\n",
    "                 ctx_nes_threshold: float = 3.0,\n",
    "                 ctx_rank_threshold: float = 0.05,\n",
    "                 dem_log2fc_thr: float = 0.5,\n",
    "                 dem_motif_hit_thr: float = 3.0,\n",
    "                 dem_max_bg_regions: int = 500,\n",
    "                 annotation : List[str] = ['Direct_annot', 'Orthology_annot'],\n",
    "                 motif_similarity_fdr: float = 0.000001,\n",
    "                 path_to_motif_annotations: str = None,\n",
    "                 annotation_version: str = 'v9',\n",
    "                 n_cpu : int = 1,\n",
    "                 _temp_dir: str = None,\n",
    "                 exclude_motifs: str = None,\n",
    "                 exclude_collection: List[str] = None,\n",
    "                 **kwargs):\n",
    "    # Create logger\n",
    "    level = logging.INFO\n",
    "    log_format = '%(asctime)s %(name)-12s %(levelname)-8s %(message)s'\n",
    "    handlers = [logging.StreamHandler(stream=sys.stdout)]\n",
    "    logging.basicConfig(level=level, format=log_format, handlers=handlers)\n",
    "    log = logging.getLogger('pycisTarget_wrapper')\n",
    "    \n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    check_folder = os.path.isdir(save_path)\n",
    "    if not check_folder:\n",
    "        os.makedirs(save_path)\n",
    "        log.info(\"Created folder : \" + save_path)\n",
    "    else:\n",
    "        log.info(save_path + \" folder already exists.\")\n",
    "        \n",
    "    def get_species_annotation(species: str):\n",
    "        dataset = pbm.Dataset(name=species,  host=biomart_host)\n",
    "        annot = dataset.query(attributes=['chromosome_name', 'transcription_start_site', 'strand', 'external_gene_name', 'transcript_biotype'])\n",
    "        annot.columns = ['Chromosome', 'Start', 'Strand', 'Gene', 'Transcript_type']\n",
    "        annot['Chromosome'] = annot['Chromosome'].astype('str')\n",
    "        filterf = annot['Chromosome'].str.contains('CHR|GL|JH|MT|KI')\n",
    "        annot = annot[~filterf]\n",
    "        annot['Chromosome'] = annot['Chromosome'].replace(r'(\\b\\S)', r'chr\\1')\n",
    "        annot = annot[annot.Transcript_type == 'protein_coding']\n",
    "        annot = annot.dropna(subset = ['Chromosome', 'Start'])\n",
    "        # Check if chromosomes have chr\n",
    "        check = region_sets[list(region_sets.keys())[0]]\n",
    "        if not any(['chr' in c for c in check[list(check.keys())[0]].df['Chromosome']]):\n",
    "            annot.Chromosome = annot.Chromosome.str.replace('chr', '')\n",
    "        if not any(['chr' in x for x in annot.Chromosome]):\n",
    "            annot.Chromosome = [f'chr{x}' for x in annot.Chromosome]\n",
    "        annot_dem=annot.copy()\n",
    "        # Define promoter space\n",
    "        annot['End'] = annot['Start'].astype(int)+promoter_space\n",
    "        annot['Start'] = annot['Start'].astype(int)-promoter_space\n",
    "        annot = pr.PyRanges(annot[['Chromosome', 'Start', 'End']])\n",
    "        return annot, annot_dem\n",
    "        \n",
    "    # Prepare annotation\n",
    "    if species == 'homo_sapiens':\n",
    "        annot, annot_dem = get_species_annotation('hsapiens_gene_ensembl')\n",
    "    elif species == 'mus_musculus':\n",
    "        annot, annot_dem = get_species_annotation('mmusculus_gene_ensembl')\n",
    "    elif species == 'drosophila_melanogaster':\n",
    "        annot, annot_dem = get_species_annotation('dmelanogaster_gene_ensembl')\n",
    "    elif species == 'gallus_gallus':\n",
    "        annot, annot_dem = get_species_annotation('ggallus_gene_ensembl')\n",
    "    elif species == 'custom':\n",
    "        annot_dem = custom_annot\n",
    "        annot = annot_dem.copy()\n",
    "        # Define promoter space\n",
    "        annot['End'] = annot['Start'].astype(int)+promoter_space\n",
    "        annot['Start'] = annot['Start'].astype(int)-promoter_space\n",
    "        annot = pr.PyRanges(annot[['Chromosome', 'Start', 'End']])\n",
    "    else:\n",
    "        raise TypeError(\"Species not recognized\")\n",
    "\n",
    "    menr = {}\n",
    "    for key in region_sets.keys():\n",
    "        if ctx_db_path is not None:\n",
    "            log.info('Loading cisTarget database for ' + key)\n",
    "            ## CISTARGET\n",
    "            regions = region_sets[key]\n",
    "            ctx_db = cisTargetDatabase(ctx_db_path, regions)  \n",
    "            if exclude_motifs is not None:\n",
    "                out = pd.read_csv(exclude_motifs, header=None).iloc[:,0].tolist()\n",
    "                ctx_db.db_rankings = ctx_db.db_rankings.drop(out)\n",
    "            if exclude_collection is not None:\n",
    "                for col in exclude_collection:\n",
    "                    ctx_db.db_rankings = ctx_db.db_rankings[~ctx_db.db_rankings.index.str.contains(col)]\n",
    "            ## DEFAULT\n",
    "            import time\n",
    "            t1_start = time.time()\n",
    "            log.info('Running cisTarget for '+key)\n",
    "            menr['CTX_'+key+'_All'] = run_cistarget(ctx_db = ctx_db,\n",
    "                                   region_sets = regions,\n",
    "                                   specie = species,\n",
    "                                   auc_threshold = ctx_auc_threshold,\n",
    "                                   nes_threshold = ctx_nes_threshold,\n",
    "                                   rank_threshold = ctx_rank_threshold,\n",
    "                                   annotation = annotation,\n",
    "                                   motif_similarity_fdr = motif_similarity_fdr,\n",
    "                                   path_to_motif_annotations = path_to_motif_annotations,\n",
    "                                   n_cpu = n_cpu,\n",
    "                                   _temp_dir= _temp_dir,\n",
    "                                   annotation_version = annotation_version,\n",
    "                                   **kwargs)\n",
    "            m1=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "            t1_stop = time.time()\n",
    "            time_ctx_all = t1_stop-t1_start\n",
    "            out_folder = os.path.join(save_path,'CTX_'+key+'_All')\n",
    "            check_folder = os.path.isdir(out_folder)\n",
    "            if not check_folder:\n",
    "                os.makedirs(out_folder)\n",
    "                log.info(\"Created folder : \" + out_folder)\n",
    "            else:\n",
    "                log.info(out_folder + \" folder already exists.\")\n",
    "            for x in menr['CTX_'+key+'_All'].keys():\n",
    "                out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                menr['CTX_'+key+'_All'][str(x)].motif_enrichment.to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "            if(save_partial):\n",
    "                with open(os.path.join(save_path,'CTX_'+key+'_All' + '.pkl'), 'wb') as f:\n",
    "                    dill.dump(menr['CTX_'+key+'_All'], f, protocol=-1)\n",
    "\n",
    "            if run_without_promoters is True:\n",
    "                ## REMOVE PROMOTERS\n",
    "                log.info('Running cisTarget without promoters for '+key)\n",
    "                regions_overlaps = {key: regions[key].count_overlaps(annot) for key in regions.keys()}\n",
    "                regions_np = {key: regions_overlaps[key][regions_overlaps[key].NumberOverlaps == 0][['Chromosome', 'Start', 'End']] for key in regions.keys()}\n",
    "                db_regions = set(pd.concat([ctx_db.regions_to_db[x] for x in ctx_db.regions_to_db.keys()])['Query'])\n",
    "                ctx_db.regions_to_db = {x: target_to_query(regions_np[x], list(db_regions), fraction_overlap = 0.4) for x in regions_np.keys()}\n",
    "                t1_start = time.time()\n",
    "                menr['CTX_'+key+'_No_promoters'] = run_cistarget(ctx_db = ctx_db,\n",
    "                                   region_sets = regions_np,\n",
    "                                   specie = species,\n",
    "                                   auc_threshold = ctx_auc_threshold,\n",
    "                                   nes_threshold = ctx_nes_threshold,\n",
    "                                   rank_threshold = ctx_rank_threshold,\n",
    "                                   annotation = annotation,\n",
    "                                   motif_similarity_fdr = motif_similarity_fdr, \n",
    "                                   path_to_motif_annotations = path_to_motif_annotations,\n",
    "                                   n_cpu = n_cpu,\n",
    "                                   _temp_dir= _temp_dir,\n",
    "                                   annotation_version = annotation_version,\n",
    "                                   **kwargs)\n",
    "                m2=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "                t1_stop = time.time()\n",
    "                time_ctx_np = t1_stop-t1_start\n",
    "                out_folder = os.path.join(save_path,'CTX_'+key+'_No_promoters')\n",
    "                check_folder = os.path.isdir(out_folder)\n",
    "                if not check_folder:\n",
    "                    os.makedirs(out_folder)\n",
    "                    log.info(\"Created folder:\" + out_folder)\n",
    "                else:\n",
    "                    log.info(out_folder + \" folder already exists.\")\n",
    "                for x in menr['CTX_'+key+'_No_promoters'].keys():\n",
    "                    out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                    menr['CTX_'+key+'_No_promoters'][str(x)].motif_enrichment.to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "                \n",
    "                if(save_partial):\n",
    "                    with open(os.path.join(save_path,'CTX_'+key+'_No_promoters' + '.pkl'), 'wb') as f:\n",
    "                      dill.dump(menr['CTX_'+key+'_No_promoters'], f, protocol=-1)\n",
    "        ## DEM\n",
    "        if dem_db_path is not None:\n",
    "            log.info('Running DEM for '+key)\n",
    "            regions = region_sets[key]\n",
    "            dem_db = DEMDatabase(dem_db_path, regions)  \n",
    "            if exclude_motifs is not None:\n",
    "                out = pd.read_csv(exclude_motifs, header=None).iloc[:,0].tolist()\n",
    "                dem_db.db_scores = dem_db.db_scores.drop(out)\n",
    "            if exclude_collection is not None:\n",
    "                for col in exclude_collection:\n",
    "                    dem_db.db_scores = dem_db.db_scores[~dem_db.db_scores.index.str.contains(col)]\n",
    "            t1_start = time.time()\n",
    "            menr['DEM_'+key+'_All'] = DEM(dem_db = dem_db,\n",
    "                               region_sets = regions,\n",
    "                               log2fc_thr = dem_log2fc_thr,\n",
    "                               motif_hit_thr = dem_motif_hit_thr,\n",
    "                               max_bg_regions = dem_max_bg_regions,\n",
    "                               specie = species,\n",
    "                               genome_annotation = annot_dem,\n",
    "                               promoter_space = promoter_space,\n",
    "                               motif_annotation =   annotation,\n",
    "                               motif_similarity_fdr = motif_similarity_fdr, \n",
    "                               path_to_motif_annotations = path_to_motif_annotations,\n",
    "                               n_cpu = n_cpu,\n",
    "                               annotation_version = annotation_version,\n",
    "                               tmp_dir = save_path,\n",
    "                               _temp_dir= _temp_dir,\n",
    "                               **kwargs)\n",
    "            m3=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "            t1_stop = time.time()\n",
    "            time_dem_all = t1_stop-t1_start\n",
    "            out_folder = os.path.join(save_path,'DEM_'+key+'_All')\n",
    "            check_folder = os.path.isdir(out_folder)\n",
    "            if not check_folder:\n",
    "                os.makedirs(out_folder)\n",
    "                log.info(\"Created folder : \"+ out_folder)\n",
    "            else:\n",
    "                log.info(out_folder + \" folder already exists.\")\n",
    "            for x in menr['DEM_'+key+'_All'].motif_enrichment.keys():\n",
    "                out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                menr['DEM_'+key+'_All'].motif_enrichment[str(x)].to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "            if(save_partial):\n",
    "                with open(os.path.join(save_path, 'DEM_'+key+'_All'+'.pkl'), 'wb') as f:\n",
    "                  dill.dump(menr['DEM_'+key+'_All'], f, protocol=-1)\n",
    "                \n",
    "            if run_without_promoters is True:\n",
    "                log.info('Running DEM without promoters for '+key)\n",
    "                ## REMOVE PROMOTERS\n",
    "                regions_overlaps = {key: regions[key].count_overlaps(annot) for key in regions.keys()}\n",
    "                regions_np = {key: regions_overlaps[key][regions_overlaps[key].NumberOverlaps == 0][['Chromosome', 'Start', 'End']] for key in regions.keys()}\n",
    "                db_regions = set(pd.concat([dem_db.regions_to_db[x] for x in dem_db.regions_to_db.keys()])['Query'])\n",
    "                dem_db.regions_to_db = {x: target_to_query(regions_np[x], list(db_regions), fraction_overlap = 0.4) for x in regions_np.keys()}\n",
    "                t1_start = time.time()\n",
    "                menr['DEM_'+key+'_No_promoters'] = DEM(dem_db = dem_db,\n",
    "                               region_sets = regions_np,\n",
    "                               log2fc_thr = dem_log2fc_thr,\n",
    "                               motif_hit_thr = dem_motif_hit_thr,\n",
    "                               max_bg_regions = dem_max_bg_regions,\n",
    "                               specie = species,\n",
    "                               promoter_space = promoter_space,\n",
    "                               motif_annotation = annotation,\n",
    "                               motif_similarity_fdr = motif_similarity_fdr, \n",
    "                               path_to_motif_annotations = path_to_motif_annotations,\n",
    "                               n_cpu = n_cpu,\n",
    "                               annotation_version = annotation_version,\n",
    "                               tmp_dir = save_path,\n",
    "                               _temp_dir= _temp_dir,\n",
    "                               **kwargs)\n",
    "                m4=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "                t1_stop = time.time()\n",
    "                time_dem_np = t1_stop-t1_start\n",
    "                out_folder = os.path.join(save_path,'DEM_'+key+'_No_promoters')\n",
    "                check_folder = os.path.isdir(out_folder)\n",
    "                if not check_folder:\n",
    "                    os.makedirs(out_folder)\n",
    "                    log.info(\"Created folder : \"+ out_folder)\n",
    "                else:\n",
    "                    log.info(out_folder + \" folder already exists.\")\n",
    "                for x in menr['DEM_'+key+'_No_promoters'].motif_enrichment.keys():\n",
    "                    out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                    menr['DEM_'+key+'_No_promoters'].motif_enrichment[str(x)].to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "                if(save_partial):\n",
    "                    with open(os.path.join(save_path, 'DEM_'+key+'_No_promoters'+'.pkl'), 'wb') as f:\n",
    "                      dill.dump(menr['DEM_'+key+'_All'], f, protocol=-1)\n",
    "                    \n",
    "        times = [time_ctx_all, time_ctx_np, time_dem_all, time_dem_np]\n",
    "        df = pd.DataFrame(times, index=['CTX_all', 'CTX_np', 'DEM_all', 'DEM_np'], columns=['Time'])\n",
    "        df.to_csv(save_path+key+'running_times.tsv', sep='\\t') \n",
    "        memory=[m1,m2,m3,m4]\n",
    "        df = pd.DataFrame(memory, index=['CTX_all', 'CTX_np', 'DEM_all', 'DEM_np'], columns=['Memory'])\n",
    "        df.to_csv(save_path+key+'cummulative_memory.tsv', sep='\\t')  \n",
    "        memory=[m1,m2-m1,m3-m2,m4-m3]\n",
    "        df = pd.DataFrame(memory, index=['CTX_all', 'CTX_np', 'DEM_all', 'DEM_np'], columns=['Memory'])\n",
    "        df.to_csv(save_path+key+'memory_per_step.tsv', sep='\\t')  \n",
    "                    \n",
    "    log.info('Saving object')         \n",
    "    with open(os.path.join(save_path,'menr.pkl'), 'wb') as f:\n",
    "        dill.dump(menr, f, protocol=-1)\n",
    "    \n",
    "    import time\n",
    "    log.info('Finished! Took {} minutes'.format((time.time() - start_time)/60)) \n",
    "            \n",
    "# Load region binarized topics\n",
    "import pickle\n",
    "outDir = '/staging/leuven/stg_00002/lcb/cbravo/Multiomics_pipeline/analysis/DPCL/speed_benchmark/high_simulation/DPCL_cisTopicObject_20K_fragments_80_cells/'\n",
    "infile = open(outDir+'binarized_topic_region.pkl', 'rb')\n",
    "binarized_topic_region = pickle.load(infile)\n",
    "infile.close()\n",
    "# Load DARs\n",
    "import pickle\n",
    "infile = open(outDir+'DARs.pkl', 'rb')\n",
    "DARs_dict = pickle.load(infile)\n",
    "infile.close()\n",
    "# Format region sets\n",
    "import re\n",
    "import pyranges as pr\n",
    "from pycistarget.utils import *\n",
    "region_sets = {}\n",
    "region_sets['Topics'] = {key: pr.PyRanges(region_names_to_coordinates(binarized_topic_region[key].index.tolist())) for key in binarized_topic_region.keys()}\n",
    "region_sets['DARs'] = {re.sub('[^A-Za-z0-9]+', '_', key): pr.PyRanges(region_names_to_coordinates(DARs_dict[key].index.tolist())) for key in DARs_dict.keys()}\n",
    "# Create save_path\n",
    "save_path = outDir + 'pycistarget/'\n",
    "# Create save_Dir\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "\n",
    "# Run pycistarget\n",
    "run_pycistarget(region_sets,\n",
    "                 ctx_db_path = '/staging/leuven/stg_00002/lcb/cbravo/Multiomics_pipeline/analysis/DPCL/ctx_db/cluster_V10_DPCL_feather_v2.regions_vs_motifs.rankings.feather',\n",
    "                 species = 'homo_sapiens',\n",
    "                 save_path = save_path,\n",
    "                 dem_db_path = '/staging/leuven/stg_00002/lcb/cbravo/Multiomics_pipeline/analysis/DPCL/ctx_db/cluster_V10_DPCL_feather_v2.regions_vs_motifs.scores.feather',\n",
    "                 run_without_promoters = True,\n",
    "                 biomart_host = 'http://www.ensembl.org',\n",
    "                 promoter_space = 500,\n",
    "                 ctx_auc_threshold = 0.005,\n",
    "                 ctx_nes_threshold = 3.0,\n",
    "                 ctx_rank_threshold = 0.05,\n",
    "                 dem_log2fc_thr = 0.5,\n",
    "                 dem_motif_hit_thr = 3.0,\n",
    "                 dem_max_bg_regions = 500,\n",
    "                 path_to_motif_annotations = '/staging/leuven/stg_00002/lcb/cbravo/cluster_motif_collection_V10_no_desso_no_factorbook/snapshots/motifs-v10nr_clust-nr.mgi-m0.00001-o0.0.tbl',\n",
    "                 annotation_version = 'v10nr_clust',\n",
    "                 annotation = ['Direct_annot', 'Orthology_annot'],\n",
    "                 n_cpu = 8,\n",
    "                 _temp_dir = '/scratch/leuven/313/vsc31305/ray_spill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6aa560c-31ad-446b-a53e-cba33df38bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --partition=batch\n",
    "#SBATCH --cluster wice\n",
    "#SBATCH --account lp_wice_pilot\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=carmen.bravogonzalezblas@kuleuven.be\n",
    "#SBATCH --ntasks=1\n",
    "\n",
    "#SBATCH --cpus-per-task=20\n",
    "#SBATCH --time=3:00:00\n",
    "#SBATCH --mem=180G\n",
    "\n",
    "#SBATCH --job-name=DPCL_cisTopicObject_20K_fragments_80_cells\n",
    "#SBATCH --output=DPCL_cisTopicObject_20K_fragments_80_cells.out\n",
    "#SBATCH --error=DPCL_cisTopicObject_20K_fragments_80_cells.err\n",
    "\n",
    "singularity exec -B /lustre1,/staging,/data,/vsc-hard-mounts,/scratch,/local_scratch /data/leuven/software/biomed/singularity_images/scenicplus/scenicplus.sif python DPCL_cisTopicObject_20K_fragments_80_cells.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3754f3-a656-439b-a633-509ae151a702",
   "metadata": {},
   "source": [
    "# DPCL_cisTopicObject_20K_fragments_1K_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a731a71-8fba-437b-8c8c-6cd07d3b7315",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import pandas as pd\n",
    "import dill\n",
    "import pyranges as pr\n",
    "from pycistarget.motif_enrichment_cistarget import *\n",
    "from pycistarget.motif_enrichment_dem import *\n",
    "from pycistarget.utils import *\n",
    "import pybiomart as pbm\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "def run_pycistarget(region_sets: Dict[str, pr.PyRanges],\n",
    "                 species: str,\n",
    "                 save_path: str,\n",
    "                 custom_annot: pd.DataFrame = None,\n",
    "                 save_partial: bool = False,\n",
    "                 ctx_db_path: str = None,\n",
    "                 dem_db_path: str = None,\n",
    "                 run_without_promoters: bool = False,\n",
    "                 biomart_host: str = 'http://www.ensembl.org',\n",
    "                 promoter_space: int = 500,\n",
    "                 ctx_auc_threshold: float = 0.005,\n",
    "                 ctx_nes_threshold: float = 3.0,\n",
    "                 ctx_rank_threshold: float = 0.05,\n",
    "                 dem_log2fc_thr: float = 0.5,\n",
    "                 dem_motif_hit_thr: float = 3.0,\n",
    "                 dem_max_bg_regions: int = 500,\n",
    "                 annotation : List[str] = ['Direct_annot', 'Orthology_annot'],\n",
    "                 motif_similarity_fdr: float = 0.000001,\n",
    "                 path_to_motif_annotations: str = None,\n",
    "                 annotation_version: str = 'v9',\n",
    "                 n_cpu : int = 1,\n",
    "                 _temp_dir: str = None,\n",
    "                 exclude_motifs: str = None,\n",
    "                 exclude_collection: List[str] = None,\n",
    "                 **kwargs):\n",
    "    # Create logger\n",
    "    level = logging.INFO\n",
    "    log_format = '%(asctime)s %(name)-12s %(levelname)-8s %(message)s'\n",
    "    handlers = [logging.StreamHandler(stream=sys.stdout)]\n",
    "    logging.basicConfig(level=level, format=log_format, handlers=handlers)\n",
    "    log = logging.getLogger('pycisTarget_wrapper')\n",
    "    \n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    check_folder = os.path.isdir(save_path)\n",
    "    if not check_folder:\n",
    "        os.makedirs(save_path)\n",
    "        log.info(\"Created folder : \" + save_path)\n",
    "    else:\n",
    "        log.info(save_path + \" folder already exists.\")\n",
    "        \n",
    "    def get_species_annotation(species: str):\n",
    "        dataset = pbm.Dataset(name=species,  host=biomart_host)\n",
    "        annot = dataset.query(attributes=['chromosome_name', 'transcription_start_site', 'strand', 'external_gene_name', 'transcript_biotype'])\n",
    "        annot.columns = ['Chromosome', 'Start', 'Strand', 'Gene', 'Transcript_type']\n",
    "        annot['Chromosome'] = annot['Chromosome'].astype('str')\n",
    "        filterf = annot['Chromosome'].str.contains('CHR|GL|JH|MT|KI')\n",
    "        annot = annot[~filterf]\n",
    "        annot['Chromosome'] = annot['Chromosome'].replace(r'(\\b\\S)', r'chr\\1')\n",
    "        annot = annot[annot.Transcript_type == 'protein_coding']\n",
    "        annot = annot.dropna(subset = ['Chromosome', 'Start'])\n",
    "        # Check if chromosomes have chr\n",
    "        check = region_sets[list(region_sets.keys())[0]]\n",
    "        if not any(['chr' in c for c in check[list(check.keys())[0]].df['Chromosome']]):\n",
    "            annot.Chromosome = annot.Chromosome.str.replace('chr', '')\n",
    "        if not any(['chr' in x for x in annot.Chromosome]):\n",
    "            annot.Chromosome = [f'chr{x}' for x in annot.Chromosome]\n",
    "        annot_dem=annot.copy()\n",
    "        # Define promoter space\n",
    "        annot['End'] = annot['Start'].astype(int)+promoter_space\n",
    "        annot['Start'] = annot['Start'].astype(int)-promoter_space\n",
    "        annot = pr.PyRanges(annot[['Chromosome', 'Start', 'End']])\n",
    "        return annot, annot_dem\n",
    "        \n",
    "    # Prepare annotation\n",
    "    if species == 'homo_sapiens':\n",
    "        annot, annot_dem = get_species_annotation('hsapiens_gene_ensembl')\n",
    "    elif species == 'mus_musculus':\n",
    "        annot, annot_dem = get_species_annotation('mmusculus_gene_ensembl')\n",
    "    elif species == 'drosophila_melanogaster':\n",
    "        annot, annot_dem = get_species_annotation('dmelanogaster_gene_ensembl')\n",
    "    elif species == 'gallus_gallus':\n",
    "        annot, annot_dem = get_species_annotation('ggallus_gene_ensembl')\n",
    "    elif species == 'custom':\n",
    "        annot_dem = custom_annot\n",
    "        annot = annot_dem.copy()\n",
    "        # Define promoter space\n",
    "        annot['End'] = annot['Start'].astype(int)+promoter_space\n",
    "        annot['Start'] = annot['Start'].astype(int)-promoter_space\n",
    "        annot = pr.PyRanges(annot[['Chromosome', 'Start', 'End']])\n",
    "    else:\n",
    "        raise TypeError(\"Species not recognized\")\n",
    "\n",
    "    menr = {}\n",
    "    for key in region_sets.keys():\n",
    "        if ctx_db_path is not None:\n",
    "            log.info('Loading cisTarget database for ' + key)\n",
    "            ## CISTARGET\n",
    "            regions = region_sets[key]\n",
    "            ctx_db = cisTargetDatabase(ctx_db_path, regions)  \n",
    "            if exclude_motifs is not None:\n",
    "                out = pd.read_csv(exclude_motifs, header=None).iloc[:,0].tolist()\n",
    "                ctx_db.db_rankings = ctx_db.db_rankings.drop(out)\n",
    "            if exclude_collection is not None:\n",
    "                for col in exclude_collection:\n",
    "                    ctx_db.db_rankings = ctx_db.db_rankings[~ctx_db.db_rankings.index.str.contains(col)]\n",
    "            ## DEFAULT\n",
    "            import time\n",
    "            t1_start = time.time()\n",
    "            log.info('Running cisTarget for '+key)\n",
    "            menr['CTX_'+key+'_All'] = run_cistarget(ctx_db = ctx_db,\n",
    "                                   region_sets = regions,\n",
    "                                   specie = species,\n",
    "                                   auc_threshold = ctx_auc_threshold,\n",
    "                                   nes_threshold = ctx_nes_threshold,\n",
    "                                   rank_threshold = ctx_rank_threshold,\n",
    "                                   annotation = annotation,\n",
    "                                   motif_similarity_fdr = motif_similarity_fdr,\n",
    "                                   path_to_motif_annotations = path_to_motif_annotations,\n",
    "                                   n_cpu = n_cpu,\n",
    "                                   _temp_dir= _temp_dir,\n",
    "                                   annotation_version = annotation_version,\n",
    "                                   **kwargs)\n",
    "            m1=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "            t1_stop = time.time()\n",
    "            time_ctx_all = t1_stop-t1_start\n",
    "            out_folder = os.path.join(save_path,'CTX_'+key+'_All')\n",
    "            check_folder = os.path.isdir(out_folder)\n",
    "            if not check_folder:\n",
    "                os.makedirs(out_folder)\n",
    "                log.info(\"Created folder : \" + out_folder)\n",
    "            else:\n",
    "                log.info(out_folder + \" folder already exists.\")\n",
    "            for x in menr['CTX_'+key+'_All'].keys():\n",
    "                out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                menr['CTX_'+key+'_All'][str(x)].motif_enrichment.to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "            if(save_partial):\n",
    "                with open(os.path.join(save_path,'CTX_'+key+'_All' + '.pkl'), 'wb') as f:\n",
    "                    dill.dump(menr['CTX_'+key+'_All'], f, protocol=-1)\n",
    "\n",
    "            if run_without_promoters is True:\n",
    "                ## REMOVE PROMOTERS\n",
    "                log.info('Running cisTarget without promoters for '+key)\n",
    "                regions_overlaps = {key: regions[key].count_overlaps(annot) for key in regions.keys()}\n",
    "                regions_np = {key: regions_overlaps[key][regions_overlaps[key].NumberOverlaps == 0][['Chromosome', 'Start', 'End']] for key in regions.keys()}\n",
    "                db_regions = set(pd.concat([ctx_db.regions_to_db[x] for x in ctx_db.regions_to_db.keys()])['Query'])\n",
    "                ctx_db.regions_to_db = {x: target_to_query(regions_np[x], list(db_regions), fraction_overlap = 0.4) for x in regions_np.keys()}\n",
    "                t1_start = time.time()\n",
    "                menr['CTX_'+key+'_No_promoters'] = run_cistarget(ctx_db = ctx_db,\n",
    "                                   region_sets = regions_np,\n",
    "                                   specie = species,\n",
    "                                   auc_threshold = ctx_auc_threshold,\n",
    "                                   nes_threshold = ctx_nes_threshold,\n",
    "                                   rank_threshold = ctx_rank_threshold,\n",
    "                                   annotation = annotation,\n",
    "                                   motif_similarity_fdr = motif_similarity_fdr, \n",
    "                                   path_to_motif_annotations = path_to_motif_annotations,\n",
    "                                   n_cpu = n_cpu,\n",
    "                                   _temp_dir= _temp_dir,\n",
    "                                   annotation_version = annotation_version,\n",
    "                                   **kwargs)\n",
    "                m2=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "                t1_stop = time.time()\n",
    "                time_ctx_np = t1_stop-t1_start\n",
    "                out_folder = os.path.join(save_path,'CTX_'+key+'_No_promoters')\n",
    "                check_folder = os.path.isdir(out_folder)\n",
    "                if not check_folder:\n",
    "                    os.makedirs(out_folder)\n",
    "                    log.info(\"Created folder:\" + out_folder)\n",
    "                else:\n",
    "                    log.info(out_folder + \" folder already exists.\")\n",
    "                for x in menr['CTX_'+key+'_No_promoters'].keys():\n",
    "                    out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                    menr['CTX_'+key+'_No_promoters'][str(x)].motif_enrichment.to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "                \n",
    "                if(save_partial):\n",
    "                    with open(os.path.join(save_path,'CTX_'+key+'_No_promoters' + '.pkl'), 'wb') as f:\n",
    "                      dill.dump(menr['CTX_'+key+'_No_promoters'], f, protocol=-1)\n",
    "        ## DEM\n",
    "        if dem_db_path is not None:\n",
    "            log.info('Running DEM for '+key)\n",
    "            regions = region_sets[key]\n",
    "            dem_db = DEMDatabase(dem_db_path, regions)  \n",
    "            if exclude_motifs is not None:\n",
    "                out = pd.read_csv(exclude_motifs, header=None).iloc[:,0].tolist()\n",
    "                dem_db.db_scores = dem_db.db_scores.drop(out)\n",
    "            if exclude_collection is not None:\n",
    "                for col in exclude_collection:\n",
    "                    dem_db.db_scores = dem_db.db_scores[~dem_db.db_scores.index.str.contains(col)]\n",
    "            t1_start = time.time()\n",
    "            menr['DEM_'+key+'_All'] = DEM(dem_db = dem_db,\n",
    "                               region_sets = regions,\n",
    "                               log2fc_thr = dem_log2fc_thr,\n",
    "                               motif_hit_thr = dem_motif_hit_thr,\n",
    "                               max_bg_regions = dem_max_bg_regions,\n",
    "                               specie = species,\n",
    "                               genome_annotation = annot_dem,\n",
    "                               promoter_space = promoter_space,\n",
    "                               motif_annotation =   annotation,\n",
    "                               motif_similarity_fdr = motif_similarity_fdr, \n",
    "                               path_to_motif_annotations = path_to_motif_annotations,\n",
    "                               n_cpu = n_cpu,\n",
    "                               annotation_version = annotation_version,\n",
    "                               tmp_dir = save_path,\n",
    "                               _temp_dir= _temp_dir,\n",
    "                               **kwargs)\n",
    "            m3=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "            t1_stop = time.time()\n",
    "            time_dem_all = t1_stop-t1_start\n",
    "            out_folder = os.path.join(save_path,'DEM_'+key+'_All')\n",
    "            check_folder = os.path.isdir(out_folder)\n",
    "            if not check_folder:\n",
    "                os.makedirs(out_folder)\n",
    "                log.info(\"Created folder : \"+ out_folder)\n",
    "            else:\n",
    "                log.info(out_folder + \" folder already exists.\")\n",
    "            for x in menr['DEM_'+key+'_All'].motif_enrichment.keys():\n",
    "                out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                menr['DEM_'+key+'_All'].motif_enrichment[str(x)].to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "            if(save_partial):\n",
    "                with open(os.path.join(save_path, 'DEM_'+key+'_All'+'.pkl'), 'wb') as f:\n",
    "                  dill.dump(menr['DEM_'+key+'_All'], f, protocol=-1)\n",
    "                \n",
    "            if run_without_promoters is True:\n",
    "                log.info('Running DEM without promoters for '+key)\n",
    "                ## REMOVE PROMOTERS\n",
    "                regions_overlaps = {key: regions[key].count_overlaps(annot) for key in regions.keys()}\n",
    "                regions_np = {key: regions_overlaps[key][regions_overlaps[key].NumberOverlaps == 0][['Chromosome', 'Start', 'End']] for key in regions.keys()}\n",
    "                db_regions = set(pd.concat([dem_db.regions_to_db[x] for x in dem_db.regions_to_db.keys()])['Query'])\n",
    "                dem_db.regions_to_db = {x: target_to_query(regions_np[x], list(db_regions), fraction_overlap = 0.4) for x in regions_np.keys()}\n",
    "                t1_start = time.time()\n",
    "                menr['DEM_'+key+'_No_promoters'] = DEM(dem_db = dem_db,\n",
    "                               region_sets = regions_np,\n",
    "                               log2fc_thr = dem_log2fc_thr,\n",
    "                               motif_hit_thr = dem_motif_hit_thr,\n",
    "                               max_bg_regions = dem_max_bg_regions,\n",
    "                               specie = species,\n",
    "                               promoter_space = promoter_space,\n",
    "                               motif_annotation = annotation,\n",
    "                               motif_similarity_fdr = motif_similarity_fdr, \n",
    "                               path_to_motif_annotations = path_to_motif_annotations,\n",
    "                               n_cpu = n_cpu,\n",
    "                               annotation_version = annotation_version,\n",
    "                               tmp_dir = save_path,\n",
    "                               _temp_dir= _temp_dir,\n",
    "                               **kwargs)\n",
    "                m4=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "                t1_stop = time.time()\n",
    "                time_dem_np = t1_stop-t1_start\n",
    "                out_folder = os.path.join(save_path,'DEM_'+key+'_No_promoters')\n",
    "                check_folder = os.path.isdir(out_folder)\n",
    "                if not check_folder:\n",
    "                    os.makedirs(out_folder)\n",
    "                    log.info(\"Created folder : \"+ out_folder)\n",
    "                else:\n",
    "                    log.info(out_folder + \" folder already exists.\")\n",
    "                for x in menr['DEM_'+key+'_No_promoters'].motif_enrichment.keys():\n",
    "                    out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                    menr['DEM_'+key+'_No_promoters'].motif_enrichment[str(x)].to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "                if(save_partial):\n",
    "                    with open(os.path.join(save_path, 'DEM_'+key+'_No_promoters'+'.pkl'), 'wb') as f:\n",
    "                      dill.dump(menr['DEM_'+key+'_All'], f, protocol=-1)\n",
    "                    \n",
    "        times = [time_ctx_all, time_ctx_np, time_dem_all, time_dem_np]\n",
    "        df = pd.DataFrame(times, index=['CTX_all', 'CTX_np', 'DEM_all', 'DEM_np'], columns=['Time'])\n",
    "        df.to_csv(save_path+key+'running_times.tsv', sep='\\t') \n",
    "        memory=[m1,m2,m3,m4]\n",
    "        df = pd.DataFrame(memory, index=['CTX_all', 'CTX_np', 'DEM_all', 'DEM_np'], columns=['Memory'])\n",
    "        df.to_csv(save_path+key+'cummulative_memory.tsv', sep='\\t')  \n",
    "        memory=[m1,m2-m1,m3-m2,m4-m3]\n",
    "        df = pd.DataFrame(memory, index=['CTX_all', 'CTX_np', 'DEM_all', 'DEM_np'], columns=['Memory'])\n",
    "        df.to_csv(save_path+key+'memory_per_step.tsv', sep='\\t')  \n",
    "                    \n",
    "    log.info('Saving object')         \n",
    "    with open(os.path.join(save_path,'menr.pkl'), 'wb') as f:\n",
    "        dill.dump(menr, f, protocol=-1)\n",
    "    \n",
    "    import time\n",
    "    log.info('Finished! Took {} minutes'.format((time.time() - start_time)/60)) \n",
    "            \n",
    "# Load region binarized topics\n",
    "import pickle\n",
    "outDir = '/staging/leuven/stg_00002/lcb/cbravo/Multiomics_pipeline/analysis/DPCL/speed_benchmark/high_simulation/DPCL_cisTopicObject_20K_fragments_1K_cells/'\n",
    "infile = open(outDir+'binarized_topic_region.pkl', 'rb')\n",
    "binarized_topic_region = pickle.load(infile)\n",
    "infile.close()\n",
    "# Load DARs\n",
    "import pickle\n",
    "infile = open(outDir+'DARs.pkl', 'rb')\n",
    "DARs_dict = pickle.load(infile)\n",
    "infile.close()\n",
    "# Format region sets\n",
    "import re\n",
    "import pyranges as pr\n",
    "from pycistarget.utils import *\n",
    "region_sets = {}\n",
    "region_sets['Topics'] = {key: pr.PyRanges(region_names_to_coordinates(binarized_topic_region[key].index.tolist())) for key in binarized_topic_region.keys()}\n",
    "region_sets['DARs'] = {re.sub('[^A-Za-z0-9]+', '_', key): pr.PyRanges(region_names_to_coordinates(DARs_dict[key].index.tolist())) for key in DARs_dict.keys()}\n",
    "# Create save_path\n",
    "save_path = outDir + 'pycistarget/'\n",
    "# Create save_Dir\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "\n",
    "# Run pycistarget\n",
    "run_pycistarget(region_sets,\n",
    "                 ctx_db_path = '/staging/leuven/stg_00002/lcb/cbravo/Multiomics_pipeline/analysis/DPCL/ctx_db/cluster_V10_DPCL_feather_v2.regions_vs_motifs.rankings.feather',\n",
    "                 species = 'homo_sapiens',\n",
    "                 save_path = save_path,\n",
    "                 dem_db_path = '/staging/leuven/stg_00002/lcb/cbravo/Multiomics_pipeline/analysis/DPCL/ctx_db/cluster_V10_DPCL_feather_v2.regions_vs_motifs.scores.feather',\n",
    "                 run_without_promoters = True,\n",
    "                 biomart_host = 'http://www.ensembl.org',\n",
    "                 promoter_space = 500,\n",
    "                 ctx_auc_threshold = 0.005,\n",
    "                 ctx_nes_threshold = 3.0,\n",
    "                 ctx_rank_threshold = 0.05,\n",
    "                 dem_log2fc_thr = 0.5,\n",
    "                 dem_motif_hit_thr = 3.0,\n",
    "                 dem_max_bg_regions = 500,\n",
    "                 path_to_motif_annotations = '/staging/leuven/stg_00002/lcb/cbravo/cluster_motif_collection_V10_no_desso_no_factorbook/snapshots/motifs-v10nr_clust-nr.mgi-m0.00001-o0.0.tbl',\n",
    "                 annotation_version = 'v10nr_clust',\n",
    "                 annotation = ['Direct_annot', 'Orthology_annot'],\n",
    "                 n_cpu = 8,\n",
    "                 _temp_dir = '/scratch/leuven/313/vsc31305/ray_spill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d55a20-39bf-4a66-85b3-0e13e82661c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --partition=batch\n",
    "#SBATCH --cluster wice\n",
    "#SBATCH --account lp_wice_pilot\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=carmen.bravogonzalezblas@kuleuven.be\n",
    "#SBATCH --ntasks=1\n",
    "\n",
    "#SBATCH --cpus-per-task=20\n",
    "#SBATCH --time=3:00:00\n",
    "#SBATCH --mem=180G\n",
    "\n",
    "#SBATCH --job-name=DPCL_cisTopicObject_20K_fragments_1K_cells\n",
    "#SBATCH --output=DPCL_cisTopicObject_20K_fragments_1K_cells.out\n",
    "#SBATCH --error=DPCL_cisTopicObject_20K_fragments_1K_cells.err\n",
    "\n",
    "singularity exec -B /lustre1,/staging,/data,/vsc-hard-mounts,/scratch,/local_scratch /data/leuven/software/biomed/singularity_images/scenicplus/scenicplus.sif python DPCL_cisTopicObject_20K_fragments_1K_cells.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11d7798-f1a6-42d1-8243-897ae56972c0",
   "metadata": {},
   "source": [
    "# DPCL_cisTopicObject_20K_fragments_10K_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97076868-aa03-4820-9521-a1e1251cbeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import pandas as pd\n",
    "import dill\n",
    "import pyranges as pr\n",
    "from pycistarget.motif_enrichment_cistarget import *\n",
    "from pycistarget.motif_enrichment_dem import *\n",
    "from pycistarget.utils import *\n",
    "import pybiomart as pbm\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "def run_pycistarget(region_sets: Dict[str, pr.PyRanges],\n",
    "                 species: str,\n",
    "                 save_path: str,\n",
    "                 custom_annot: pd.DataFrame = None,\n",
    "                 save_partial: bool = False,\n",
    "                 ctx_db_path: str = None,\n",
    "                 dem_db_path: str = None,\n",
    "                 run_without_promoters: bool = False,\n",
    "                 biomart_host: str = 'http://www.ensembl.org',\n",
    "                 promoter_space: int = 500,\n",
    "                 ctx_auc_threshold: float = 0.005,\n",
    "                 ctx_nes_threshold: float = 3.0,\n",
    "                 ctx_rank_threshold: float = 0.05,\n",
    "                 dem_log2fc_thr: float = 0.5,\n",
    "                 dem_motif_hit_thr: float = 3.0,\n",
    "                 dem_max_bg_regions: int = 500,\n",
    "                 annotation : List[str] = ['Direct_annot', 'Orthology_annot'],\n",
    "                 motif_similarity_fdr: float = 0.000001,\n",
    "                 path_to_motif_annotations: str = None,\n",
    "                 annotation_version: str = 'v9',\n",
    "                 n_cpu : int = 1,\n",
    "                 _temp_dir: str = None,\n",
    "                 exclude_motifs: str = None,\n",
    "                 exclude_collection: List[str] = None,\n",
    "                 **kwargs):\n",
    "    # Create logger\n",
    "    level = logging.INFO\n",
    "    log_format = '%(asctime)s %(name)-12s %(levelname)-8s %(message)s'\n",
    "    handlers = [logging.StreamHandler(stream=sys.stdout)]\n",
    "    logging.basicConfig(level=level, format=log_format, handlers=handlers)\n",
    "    log = logging.getLogger('pycisTarget_wrapper')\n",
    "    \n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    check_folder = os.path.isdir(save_path)\n",
    "    if not check_folder:\n",
    "        os.makedirs(save_path)\n",
    "        log.info(\"Created folder : \" + save_path)\n",
    "    else:\n",
    "        log.info(save_path + \" folder already exists.\")\n",
    "        \n",
    "    def get_species_annotation(species: str):\n",
    "        dataset = pbm.Dataset(name=species,  host=biomart_host)\n",
    "        annot = dataset.query(attributes=['chromosome_name', 'transcription_start_site', 'strand', 'external_gene_name', 'transcript_biotype'])\n",
    "        annot.columns = ['Chromosome', 'Start', 'Strand', 'Gene', 'Transcript_type']\n",
    "        annot['Chromosome'] = annot['Chromosome'].astype('str')\n",
    "        filterf = annot['Chromosome'].str.contains('CHR|GL|JH|MT|KI')\n",
    "        annot = annot[~filterf]\n",
    "        annot['Chromosome'] = annot['Chromosome'].replace(r'(\\b\\S)', r'chr\\1')\n",
    "        annot = annot[annot.Transcript_type == 'protein_coding']\n",
    "        annot = annot.dropna(subset = ['Chromosome', 'Start'])\n",
    "        # Check if chromosomes have chr\n",
    "        check = region_sets[list(region_sets.keys())[0]]\n",
    "        if not any(['chr' in c for c in check[list(check.keys())[0]].df['Chromosome']]):\n",
    "            annot.Chromosome = annot.Chromosome.str.replace('chr', '')\n",
    "        if not any(['chr' in x for x in annot.Chromosome]):\n",
    "            annot.Chromosome = [f'chr{x}' for x in annot.Chromosome]\n",
    "        annot_dem=annot.copy()\n",
    "        # Define promoter space\n",
    "        annot['End'] = annot['Start'].astype(int)+promoter_space\n",
    "        annot['Start'] = annot['Start'].astype(int)-promoter_space\n",
    "        annot = pr.PyRanges(annot[['Chromosome', 'Start', 'End']])\n",
    "        return annot, annot_dem\n",
    "        \n",
    "    # Prepare annotation\n",
    "    if species == 'homo_sapiens':\n",
    "        annot, annot_dem = get_species_annotation('hsapiens_gene_ensembl')\n",
    "    elif species == 'mus_musculus':\n",
    "        annot, annot_dem = get_species_annotation('mmusculus_gene_ensembl')\n",
    "    elif species == 'drosophila_melanogaster':\n",
    "        annot, annot_dem = get_species_annotation('dmelanogaster_gene_ensembl')\n",
    "    elif species == 'gallus_gallus':\n",
    "        annot, annot_dem = get_species_annotation('ggallus_gene_ensembl')\n",
    "    elif species == 'custom':\n",
    "        annot_dem = custom_annot\n",
    "        annot = annot_dem.copy()\n",
    "        # Define promoter space\n",
    "        annot['End'] = annot['Start'].astype(int)+promoter_space\n",
    "        annot['Start'] = annot['Start'].astype(int)-promoter_space\n",
    "        annot = pr.PyRanges(annot[['Chromosome', 'Start', 'End']])\n",
    "    else:\n",
    "        raise TypeError(\"Species not recognized\")\n",
    "\n",
    "    menr = {}\n",
    "    for key in region_sets.keys():\n",
    "        if ctx_db_path is not None:\n",
    "            log.info('Loading cisTarget database for ' + key)\n",
    "            ## CISTARGET\n",
    "            regions = region_sets[key]\n",
    "            ctx_db = cisTargetDatabase(ctx_db_path, regions)  \n",
    "            if exclude_motifs is not None:\n",
    "                out = pd.read_csv(exclude_motifs, header=None).iloc[:,0].tolist()\n",
    "                ctx_db.db_rankings = ctx_db.db_rankings.drop(out)\n",
    "            if exclude_collection is not None:\n",
    "                for col in exclude_collection:\n",
    "                    ctx_db.db_rankings = ctx_db.db_rankings[~ctx_db.db_rankings.index.str.contains(col)]\n",
    "            ## DEFAULT\n",
    "            import time\n",
    "            t1_start = time.time()\n",
    "            log.info('Running cisTarget for '+key)\n",
    "            menr['CTX_'+key+'_All'] = run_cistarget(ctx_db = ctx_db,\n",
    "                                   region_sets = regions,\n",
    "                                   specie = species,\n",
    "                                   auc_threshold = ctx_auc_threshold,\n",
    "                                   nes_threshold = ctx_nes_threshold,\n",
    "                                   rank_threshold = ctx_rank_threshold,\n",
    "                                   annotation = annotation,\n",
    "                                   motif_similarity_fdr = motif_similarity_fdr,\n",
    "                                   path_to_motif_annotations = path_to_motif_annotations,\n",
    "                                   n_cpu = n_cpu,\n",
    "                                   _temp_dir= _temp_dir,\n",
    "                                   annotation_version = annotation_version,\n",
    "                                   **kwargs)\n",
    "            m1=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "            t1_stop = time.time()\n",
    "            time_ctx_all = t1_stop-t1_start\n",
    "            out_folder = os.path.join(save_path,'CTX_'+key+'_All')\n",
    "            check_folder = os.path.isdir(out_folder)\n",
    "            if not check_folder:\n",
    "                os.makedirs(out_folder)\n",
    "                log.info(\"Created folder : \" + out_folder)\n",
    "            else:\n",
    "                log.info(out_folder + \" folder already exists.\")\n",
    "            for x in menr['CTX_'+key+'_All'].keys():\n",
    "                out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                menr['CTX_'+key+'_All'][str(x)].motif_enrichment.to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "            if(save_partial):\n",
    "                with open(os.path.join(save_path,'CTX_'+key+'_All' + '.pkl'), 'wb') as f:\n",
    "                    dill.dump(menr['CTX_'+key+'_All'], f, protocol=-1)\n",
    "\n",
    "            if run_without_promoters is True:\n",
    "                ## REMOVE PROMOTERS\n",
    "                log.info('Running cisTarget without promoters for '+key)\n",
    "                regions_overlaps = {key: regions[key].count_overlaps(annot) for key in regions.keys()}\n",
    "                regions_np = {key: regions_overlaps[key][regions_overlaps[key].NumberOverlaps == 0][['Chromosome', 'Start', 'End']] for key in regions.keys()}\n",
    "                db_regions = set(pd.concat([ctx_db.regions_to_db[x] for x in ctx_db.regions_to_db.keys()])['Query'])\n",
    "                ctx_db.regions_to_db = {x: target_to_query(regions_np[x], list(db_regions), fraction_overlap = 0.4) for x in regions_np.keys()}\n",
    "                t1_start = time.time()\n",
    "                menr['CTX_'+key+'_No_promoters'] = run_cistarget(ctx_db = ctx_db,\n",
    "                                   region_sets = regions_np,\n",
    "                                   specie = species,\n",
    "                                   auc_threshold = ctx_auc_threshold,\n",
    "                                   nes_threshold = ctx_nes_threshold,\n",
    "                                   rank_threshold = ctx_rank_threshold,\n",
    "                                   annotation = annotation,\n",
    "                                   motif_similarity_fdr = motif_similarity_fdr, \n",
    "                                   path_to_motif_annotations = path_to_motif_annotations,\n",
    "                                   n_cpu = n_cpu,\n",
    "                                   _temp_dir= _temp_dir,\n",
    "                                   annotation_version = annotation_version,\n",
    "                                   **kwargs)\n",
    "                m2=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "                t1_stop = time.time()\n",
    "                time_ctx_np = t1_stop-t1_start\n",
    "                out_folder = os.path.join(save_path,'CTX_'+key+'_No_promoters')\n",
    "                check_folder = os.path.isdir(out_folder)\n",
    "                if not check_folder:\n",
    "                    os.makedirs(out_folder)\n",
    "                    log.info(\"Created folder:\" + out_folder)\n",
    "                else:\n",
    "                    log.info(out_folder + \" folder already exists.\")\n",
    "                for x in menr['CTX_'+key+'_No_promoters'].keys():\n",
    "                    out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                    menr['CTX_'+key+'_No_promoters'][str(x)].motif_enrichment.to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "                \n",
    "                if(save_partial):\n",
    "                    with open(os.path.join(save_path,'CTX_'+key+'_No_promoters' + '.pkl'), 'wb') as f:\n",
    "                      dill.dump(menr['CTX_'+key+'_No_promoters'], f, protocol=-1)\n",
    "        ## DEM\n",
    "        if dem_db_path is not None:\n",
    "            log.info('Running DEM for '+key)\n",
    "            regions = region_sets[key]\n",
    "            dem_db = DEMDatabase(dem_db_path, regions)  \n",
    "            if exclude_motifs is not None:\n",
    "                out = pd.read_csv(exclude_motifs, header=None).iloc[:,0].tolist()\n",
    "                dem_db.db_scores = dem_db.db_scores.drop(out)\n",
    "            if exclude_collection is not None:\n",
    "                for col in exclude_collection:\n",
    "                    dem_db.db_scores = dem_db.db_scores[~dem_db.db_scores.index.str.contains(col)]\n",
    "            t1_start = time.time()\n",
    "            menr['DEM_'+key+'_All'] = DEM(dem_db = dem_db,\n",
    "                               region_sets = regions,\n",
    "                               log2fc_thr = dem_log2fc_thr,\n",
    "                               motif_hit_thr = dem_motif_hit_thr,\n",
    "                               max_bg_regions = dem_max_bg_regions,\n",
    "                               specie = species,\n",
    "                               genome_annotation = annot_dem,\n",
    "                               promoter_space = promoter_space,\n",
    "                               motif_annotation =   annotation,\n",
    "                               motif_similarity_fdr = motif_similarity_fdr, \n",
    "                               path_to_motif_annotations = path_to_motif_annotations,\n",
    "                               n_cpu = n_cpu,\n",
    "                               annotation_version = annotation_version,\n",
    "                               tmp_dir = save_path,\n",
    "                               _temp_dir= _temp_dir,\n",
    "                               **kwargs)\n",
    "            m3=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "            t1_stop = time.time()\n",
    "            time_dem_all = t1_stop-t1_start\n",
    "            out_folder = os.path.join(save_path,'DEM_'+key+'_All')\n",
    "            check_folder = os.path.isdir(out_folder)\n",
    "            if not check_folder:\n",
    "                os.makedirs(out_folder)\n",
    "                log.info(\"Created folder : \"+ out_folder)\n",
    "            else:\n",
    "                log.info(out_folder + \" folder already exists.\")\n",
    "            for x in menr['DEM_'+key+'_All'].motif_enrichment.keys():\n",
    "                out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                menr['DEM_'+key+'_All'].motif_enrichment[str(x)].to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "            if(save_partial):\n",
    "                with open(os.path.join(save_path, 'DEM_'+key+'_All'+'.pkl'), 'wb') as f:\n",
    "                  dill.dump(menr['DEM_'+key+'_All'], f, protocol=-1)\n",
    "                \n",
    "            if run_without_promoters is True:\n",
    "                log.info('Running DEM without promoters for '+key)\n",
    "                ## REMOVE PROMOTERS\n",
    "                regions_overlaps = {key: regions[key].count_overlaps(annot) for key in regions.keys()}\n",
    "                regions_np = {key: regions_overlaps[key][regions_overlaps[key].NumberOverlaps == 0][['Chromosome', 'Start', 'End']] for key in regions.keys()}\n",
    "                db_regions = set(pd.concat([dem_db.regions_to_db[x] for x in dem_db.regions_to_db.keys()])['Query'])\n",
    "                dem_db.regions_to_db = {x: target_to_query(regions_np[x], list(db_regions), fraction_overlap = 0.4) for x in regions_np.keys()}\n",
    "                t1_start = time.time()\n",
    "                menr['DEM_'+key+'_No_promoters'] = DEM(dem_db = dem_db,\n",
    "                               region_sets = regions_np,\n",
    "                               log2fc_thr = dem_log2fc_thr,\n",
    "                               motif_hit_thr = dem_motif_hit_thr,\n",
    "                               max_bg_regions = dem_max_bg_regions,\n",
    "                               specie = species,\n",
    "                               promoter_space = promoter_space,\n",
    "                               motif_annotation = annotation,\n",
    "                               motif_similarity_fdr = motif_similarity_fdr, \n",
    "                               path_to_motif_annotations = path_to_motif_annotations,\n",
    "                               n_cpu = n_cpu,\n",
    "                               annotation_version = annotation_version,\n",
    "                               tmp_dir = save_path,\n",
    "                               _temp_dir= _temp_dir,\n",
    "                               **kwargs)\n",
    "                m4=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "                t1_stop = time.time()\n",
    "                time_dem_np = t1_stop-t1_start\n",
    "                out_folder = os.path.join(save_path,'DEM_'+key+'_No_promoters')\n",
    "                check_folder = os.path.isdir(out_folder)\n",
    "                if not check_folder:\n",
    "                    os.makedirs(out_folder)\n",
    "                    log.info(\"Created folder : \"+ out_folder)\n",
    "                else:\n",
    "                    log.info(out_folder + \" folder already exists.\")\n",
    "                for x in menr['DEM_'+key+'_No_promoters'].motif_enrichment.keys():\n",
    "                    out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                    menr['DEM_'+key+'_No_promoters'].motif_enrichment[str(x)].to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "                if(save_partial):\n",
    "                    with open(os.path.join(save_path, 'DEM_'+key+'_No_promoters'+'.pkl'), 'wb') as f:\n",
    "                      dill.dump(menr['DEM_'+key+'_All'], f, protocol=-1)\n",
    "                    \n",
    "        times = [time_ctx_all, time_ctx_np, time_dem_all, time_dem_np]\n",
    "        df = pd.DataFrame(times, index=['CTX_all', 'CTX_np', 'DEM_all', 'DEM_np'], columns=['Time'])\n",
    "        df.to_csv(save_path+key+'running_times.tsv', sep='\\t') \n",
    "        memory=[m1,m2,m3,m4]\n",
    "        df = pd.DataFrame(memory, index=['CTX_all', 'CTX_np', 'DEM_all', 'DEM_np'], columns=['Memory'])\n",
    "        df.to_csv(save_path+key+'cummulative_memory.tsv', sep='\\t')  \n",
    "        memory=[m1,m2-m1,m3-m2,m4-m3]\n",
    "        df = pd.DataFrame(memory, index=['CTX_all', 'CTX_np', 'DEM_all', 'DEM_np'], columns=['Memory'])\n",
    "        df.to_csv(save_path+key+'memory_per_step.tsv', sep='\\t')  \n",
    "                    \n",
    "    log.info('Saving object')         \n",
    "    with open(os.path.join(save_path,'menr.pkl'), 'wb') as f:\n",
    "        dill.dump(menr, f, protocol=-1)\n",
    "    \n",
    "    import time\n",
    "    log.info('Finished! Took {} minutes'.format((time.time() - start_time)/60)) \n",
    "            \n",
    "# Load region binarized topics\n",
    "import pickle\n",
    "outDir = '/staging/leuven/stg_00002/lcb/cbravo/Multiomics_pipeline/analysis/DPCL/speed_benchmark/high_simulation/DPCL_cisTopicObject_20K_fragments_10K_cells/'\n",
    "infile = open(outDir+'binarized_topic_region.pkl', 'rb')\n",
    "binarized_topic_region = pickle.load(infile)\n",
    "infile.close()\n",
    "# Load DARs\n",
    "import pickle\n",
    "infile = open(outDir+'DARs.pkl', 'rb')\n",
    "DARs_dict = pickle.load(infile)\n",
    "infile.close()\n",
    "# Format region sets\n",
    "import re\n",
    "import pyranges as pr\n",
    "from pycistarget.utils import *\n",
    "region_sets = {}\n",
    "region_sets['Topics'] = {key: pr.PyRanges(region_names_to_coordinates(binarized_topic_region[key].index.tolist())) for key in binarized_topic_region.keys()}\n",
    "region_sets['DARs'] = {re.sub('[^A-Za-z0-9]+', '_', key): pr.PyRanges(region_names_to_coordinates(DARs_dict[key].index.tolist())) for key in DARs_dict.keys()}\n",
    "# Create save_path\n",
    "save_path = outDir + 'pycistarget/'\n",
    "# Create save_Dir\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "\n",
    "# Run pycistarget\n",
    "run_pycistarget(region_sets,\n",
    "                 ctx_db_path = '/staging/leuven/stg_00002/lcb/cbravo/Multiomics_pipeline/analysis/DPCL/ctx_db/cluster_V10_DPCL_feather_v2.regions_vs_motifs.rankings.feather',\n",
    "                 species = 'homo_sapiens',\n",
    "                 save_path = save_path,\n",
    "                 dem_db_path = '/staging/leuven/stg_00002/lcb/cbravo/Multiomics_pipeline/analysis/DPCL/ctx_db/cluster_V10_DPCL_feather_v2.regions_vs_motifs.scores.feather',\n",
    "                 run_without_promoters = True,\n",
    "                 biomart_host = 'http://www.ensembl.org',\n",
    "                 promoter_space = 500,\n",
    "                 ctx_auc_threshold = 0.005,\n",
    "                 ctx_nes_threshold = 3.0,\n",
    "                 ctx_rank_threshold = 0.05,\n",
    "                 dem_log2fc_thr = 0.5,\n",
    "                 dem_motif_hit_thr = 3.0,\n",
    "                 dem_max_bg_regions = 500,\n",
    "                 path_to_motif_annotations = '/staging/leuven/stg_00002/lcb/cbravo/cluster_motif_collection_V10_no_desso_no_factorbook/snapshots/motifs-v10nr_clust-nr.mgi-m0.00001-o0.0.tbl',\n",
    "                 annotation_version = 'v10nr_clust',\n",
    "                 annotation = ['Direct_annot', 'Orthology_annot'],\n",
    "                 n_cpu = 8,\n",
    "                 _temp_dir = '/scratch/leuven/313/vsc31305/ray_spill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a3c3b0-470e-40fa-a1b4-033b1f35face",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --partition=batch\n",
    "#SBATCH --cluster wice\n",
    "#SBATCH --account lp_wice_pilot\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=carmen.bravogonzalezblas@kuleuven.be\n",
    "#SBATCH --ntasks=1\n",
    "\n",
    "#SBATCH --cpus-per-task=20\n",
    "#SBATCH --time=3:00:00\n",
    "#SBATCH --mem=180G\n",
    "\n",
    "#SBATCH --job-name=DPCL_cisTopicObject_20K_fragments_10K_cells\n",
    "#SBATCH --output=DPCL_cisTopicObject_20K_fragments_10K_cells.out\n",
    "#SBATCH --error=DPCL_cisTopicObject_20K_fragments_10K_cells.err\n",
    "\n",
    "singularity exec -B /lustre1,/staging,/data,/vsc-hard-mounts,/scratch,/local_scratch /data/leuven/software/biomed/singularity_images/scenicplus/scenicplus.sif python DPCL_cisTopicObject_20K_fragments_10K_cells.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4525f3e-c2ac-4234-b754-9d980b2e00da",
   "metadata": {},
   "source": [
    "# DPCL_cisTopicObject_20K_fragments_25K_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31de3c44-9625-4e45-9a6d-3cb5537d6fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import pandas as pd\n",
    "import dill\n",
    "import pyranges as pr\n",
    "from pycistarget.motif_enrichment_cistarget import *\n",
    "from pycistarget.motif_enrichment_dem import *\n",
    "from pycistarget.utils import *\n",
    "import pybiomart as pbm\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "def run_pycistarget(region_sets: Dict[str, pr.PyRanges],\n",
    "                 species: str,\n",
    "                 save_path: str,\n",
    "                 custom_annot: pd.DataFrame = None,\n",
    "                 save_partial: bool = False,\n",
    "                 ctx_db_path: str = None,\n",
    "                 dem_db_path: str = None,\n",
    "                 run_without_promoters: bool = False,\n",
    "                 biomart_host: str = 'http://www.ensembl.org',\n",
    "                 promoter_space: int = 500,\n",
    "                 ctx_auc_threshold: float = 0.005,\n",
    "                 ctx_nes_threshold: float = 3.0,\n",
    "                 ctx_rank_threshold: float = 0.05,\n",
    "                 dem_log2fc_thr: float = 0.5,\n",
    "                 dem_motif_hit_thr: float = 3.0,\n",
    "                 dem_max_bg_regions: int = 500,\n",
    "                 annotation : List[str] = ['Direct_annot', 'Orthology_annot'],\n",
    "                 motif_similarity_fdr: float = 0.000001,\n",
    "                 path_to_motif_annotations: str = None,\n",
    "                 annotation_version: str = 'v9',\n",
    "                 n_cpu : int = 1,\n",
    "                 _temp_dir: str = None,\n",
    "                 exclude_motifs: str = None,\n",
    "                 exclude_collection: List[str] = None,\n",
    "                 **kwargs):\n",
    "    # Create logger\n",
    "    level = logging.INFO\n",
    "    log_format = '%(asctime)s %(name)-12s %(levelname)-8s %(message)s'\n",
    "    handlers = [logging.StreamHandler(stream=sys.stdout)]\n",
    "    logging.basicConfig(level=level, format=log_format, handlers=handlers)\n",
    "    log = logging.getLogger('pycisTarget_wrapper')\n",
    "    \n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    check_folder = os.path.isdir(save_path)\n",
    "    if not check_folder:\n",
    "        os.makedirs(save_path)\n",
    "        log.info(\"Created folder : \" + save_path)\n",
    "    else:\n",
    "        log.info(save_path + \" folder already exists.\")\n",
    "        \n",
    "    def get_species_annotation(species: str):\n",
    "        dataset = pbm.Dataset(name=species,  host=biomart_host)\n",
    "        annot = dataset.query(attributes=['chromosome_name', 'transcription_start_site', 'strand', 'external_gene_name', 'transcript_biotype'])\n",
    "        annot.columns = ['Chromosome', 'Start', 'Strand', 'Gene', 'Transcript_type']\n",
    "        annot['Chromosome'] = annot['Chromosome'].astype('str')\n",
    "        filterf = annot['Chromosome'].str.contains('CHR|GL|JH|MT|KI')\n",
    "        annot = annot[~filterf]\n",
    "        annot['Chromosome'] = annot['Chromosome'].replace(r'(\\b\\S)', r'chr\\1')\n",
    "        annot = annot[annot.Transcript_type == 'protein_coding']\n",
    "        annot = annot.dropna(subset = ['Chromosome', 'Start'])\n",
    "        # Check if chromosomes have chr\n",
    "        check = region_sets[list(region_sets.keys())[0]]\n",
    "        if not any(['chr' in c for c in check[list(check.keys())[0]].df['Chromosome']]):\n",
    "            annot.Chromosome = annot.Chromosome.str.replace('chr', '')\n",
    "        if not any(['chr' in x for x in annot.Chromosome]):\n",
    "            annot.Chromosome = [f'chr{x}' for x in annot.Chromosome]\n",
    "        annot_dem=annot.copy()\n",
    "        # Define promoter space\n",
    "        annot['End'] = annot['Start'].astype(int)+promoter_space\n",
    "        annot['Start'] = annot['Start'].astype(int)-promoter_space\n",
    "        annot = pr.PyRanges(annot[['Chromosome', 'Start', 'End']])\n",
    "        return annot, annot_dem\n",
    "        \n",
    "    # Prepare annotation\n",
    "    if species == 'homo_sapiens':\n",
    "        annot, annot_dem = get_species_annotation('hsapiens_gene_ensembl')\n",
    "    elif species == 'mus_musculus':\n",
    "        annot, annot_dem = get_species_annotation('mmusculus_gene_ensembl')\n",
    "    elif species == 'drosophila_melanogaster':\n",
    "        annot, annot_dem = get_species_annotation('dmelanogaster_gene_ensembl')\n",
    "    elif species == 'gallus_gallus':\n",
    "        annot, annot_dem = get_species_annotation('ggallus_gene_ensembl')\n",
    "    elif species == 'custom':\n",
    "        annot_dem = custom_annot\n",
    "        annot = annot_dem.copy()\n",
    "        # Define promoter space\n",
    "        annot['End'] = annot['Start'].astype(int)+promoter_space\n",
    "        annot['Start'] = annot['Start'].astype(int)-promoter_space\n",
    "        annot = pr.PyRanges(annot[['Chromosome', 'Start', 'End']])\n",
    "    else:\n",
    "        raise TypeError(\"Species not recognized\")\n",
    "\n",
    "    menr = {}\n",
    "    for key in region_sets.keys():\n",
    "        if ctx_db_path is not None:\n",
    "            log.info('Loading cisTarget database for ' + key)\n",
    "            ## CISTARGET\n",
    "            regions = region_sets[key]\n",
    "            ctx_db = cisTargetDatabase(ctx_db_path, regions)  \n",
    "            if exclude_motifs is not None:\n",
    "                out = pd.read_csv(exclude_motifs, header=None).iloc[:,0].tolist()\n",
    "                ctx_db.db_rankings = ctx_db.db_rankings.drop(out)\n",
    "            if exclude_collection is not None:\n",
    "                for col in exclude_collection:\n",
    "                    ctx_db.db_rankings = ctx_db.db_rankings[~ctx_db.db_rankings.index.str.contains(col)]\n",
    "            ## DEFAULT\n",
    "            import time\n",
    "            t1_start = time.time()\n",
    "            log.info('Running cisTarget for '+key)\n",
    "            menr['CTX_'+key+'_All'] = run_cistarget(ctx_db = ctx_db,\n",
    "                                   region_sets = regions,\n",
    "                                   specie = species,\n",
    "                                   auc_threshold = ctx_auc_threshold,\n",
    "                                   nes_threshold = ctx_nes_threshold,\n",
    "                                   rank_threshold = ctx_rank_threshold,\n",
    "                                   annotation = annotation,\n",
    "                                   motif_similarity_fdr = motif_similarity_fdr,\n",
    "                                   path_to_motif_annotations = path_to_motif_annotations,\n",
    "                                   n_cpu = n_cpu,\n",
    "                                   _temp_dir= _temp_dir,\n",
    "                                   annotation_version = annotation_version,\n",
    "                                   **kwargs)\n",
    "            m1=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "            t1_stop = time.time()\n",
    "            time_ctx_all = t1_stop-t1_start\n",
    "            out_folder = os.path.join(save_path,'CTX_'+key+'_All')\n",
    "            check_folder = os.path.isdir(out_folder)\n",
    "            if not check_folder:\n",
    "                os.makedirs(out_folder)\n",
    "                log.info(\"Created folder : \" + out_folder)\n",
    "            else:\n",
    "                log.info(out_folder + \" folder already exists.\")\n",
    "            for x in menr['CTX_'+key+'_All'].keys():\n",
    "                out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                menr['CTX_'+key+'_All'][str(x)].motif_enrichment.to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "            if(save_partial):\n",
    "                with open(os.path.join(save_path,'CTX_'+key+'_All' + '.pkl'), 'wb') as f:\n",
    "                    dill.dump(menr['CTX_'+key+'_All'], f, protocol=-1)\n",
    "\n",
    "            if run_without_promoters is True:\n",
    "                ## REMOVE PROMOTERS\n",
    "                log.info('Running cisTarget without promoters for '+key)\n",
    "                regions_overlaps = {key: regions[key].count_overlaps(annot) for key in regions.keys()}\n",
    "                regions_np = {key: regions_overlaps[key][regions_overlaps[key].NumberOverlaps == 0][['Chromosome', 'Start', 'End']] for key in regions.keys()}\n",
    "                db_regions = set(pd.concat([ctx_db.regions_to_db[x] for x in ctx_db.regions_to_db.keys()])['Query'])\n",
    "                ctx_db.regions_to_db = {x: target_to_query(regions_np[x], list(db_regions), fraction_overlap = 0.4) for x in regions_np.keys()}\n",
    "                t1_start = time.time()\n",
    "                menr['CTX_'+key+'_No_promoters'] = run_cistarget(ctx_db = ctx_db,\n",
    "                                   region_sets = regions_np,\n",
    "                                   specie = species,\n",
    "                                   auc_threshold = ctx_auc_threshold,\n",
    "                                   nes_threshold = ctx_nes_threshold,\n",
    "                                   rank_threshold = ctx_rank_threshold,\n",
    "                                   annotation = annotation,\n",
    "                                   motif_similarity_fdr = motif_similarity_fdr, \n",
    "                                   path_to_motif_annotations = path_to_motif_annotations,\n",
    "                                   n_cpu = n_cpu,\n",
    "                                   _temp_dir= _temp_dir,\n",
    "                                   annotation_version = annotation_version,\n",
    "                                   **kwargs)\n",
    "                m2=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "                t1_stop = time.time()\n",
    "                time_ctx_np = t1_stop-t1_start\n",
    "                out_folder = os.path.join(save_path,'CTX_'+key+'_No_promoters')\n",
    "                check_folder = os.path.isdir(out_folder)\n",
    "                if not check_folder:\n",
    "                    os.makedirs(out_folder)\n",
    "                    log.info(\"Created folder:\" + out_folder)\n",
    "                else:\n",
    "                    log.info(out_folder + \" folder already exists.\")\n",
    "                for x in menr['CTX_'+key+'_No_promoters'].keys():\n",
    "                    out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                    menr['CTX_'+key+'_No_promoters'][str(x)].motif_enrichment.to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "                \n",
    "                if(save_partial):\n",
    "                    with open(os.path.join(save_path,'CTX_'+key+'_No_promoters' + '.pkl'), 'wb') as f:\n",
    "                      dill.dump(menr['CTX_'+key+'_No_promoters'], f, protocol=-1)\n",
    "        ## DEM\n",
    "        if dem_db_path is not None:\n",
    "            log.info('Running DEM for '+key)\n",
    "            regions = region_sets[key]\n",
    "            dem_db = DEMDatabase(dem_db_path, regions)  \n",
    "            if exclude_motifs is not None:\n",
    "                out = pd.read_csv(exclude_motifs, header=None).iloc[:,0].tolist()\n",
    "                dem_db.db_scores = dem_db.db_scores.drop(out)\n",
    "            if exclude_collection is not None:\n",
    "                for col in exclude_collection:\n",
    "                    dem_db.db_scores = dem_db.db_scores[~dem_db.db_scores.index.str.contains(col)]\n",
    "            t1_start = time.time()\n",
    "            menr['DEM_'+key+'_All'] = DEM(dem_db = dem_db,\n",
    "                               region_sets = regions,\n",
    "                               log2fc_thr = dem_log2fc_thr,\n",
    "                               motif_hit_thr = dem_motif_hit_thr,\n",
    "                               max_bg_regions = dem_max_bg_regions,\n",
    "                               specie = species,\n",
    "                               genome_annotation = annot_dem,\n",
    "                               promoter_space = promoter_space,\n",
    "                               motif_annotation =   annotation,\n",
    "                               motif_similarity_fdr = motif_similarity_fdr, \n",
    "                               path_to_motif_annotations = path_to_motif_annotations,\n",
    "                               n_cpu = n_cpu,\n",
    "                               annotation_version = annotation_version,\n",
    "                               tmp_dir = save_path,\n",
    "                               _temp_dir= _temp_dir,\n",
    "                               **kwargs)\n",
    "            m3=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "            t1_stop = time.time()\n",
    "            time_dem_all = t1_stop-t1_start\n",
    "            out_folder = os.path.join(save_path,'DEM_'+key+'_All')\n",
    "            check_folder = os.path.isdir(out_folder)\n",
    "            if not check_folder:\n",
    "                os.makedirs(out_folder)\n",
    "                log.info(\"Created folder : \"+ out_folder)\n",
    "            else:\n",
    "                log.info(out_folder + \" folder already exists.\")\n",
    "            for x in menr['DEM_'+key+'_All'].motif_enrichment.keys():\n",
    "                out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                menr['DEM_'+key+'_All'].motif_enrichment[str(x)].to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "            if(save_partial):\n",
    "                with open(os.path.join(save_path, 'DEM_'+key+'_All'+'.pkl'), 'wb') as f:\n",
    "                  dill.dump(menr['DEM_'+key+'_All'], f, protocol=-1)\n",
    "                \n",
    "            if run_without_promoters is True:\n",
    "                log.info('Running DEM without promoters for '+key)\n",
    "                ## REMOVE PROMOTERS\n",
    "                regions_overlaps = {key: regions[key].count_overlaps(annot) for key in regions.keys()}\n",
    "                regions_np = {key: regions_overlaps[key][regions_overlaps[key].NumberOverlaps == 0][['Chromosome', 'Start', 'End']] for key in regions.keys()}\n",
    "                db_regions = set(pd.concat([dem_db.regions_to_db[x] for x in dem_db.regions_to_db.keys()])['Query'])\n",
    "                dem_db.regions_to_db = {x: target_to_query(regions_np[x], list(db_regions), fraction_overlap = 0.4) for x in regions_np.keys()}\n",
    "                t1_start = time.time()\n",
    "                menr['DEM_'+key+'_No_promoters'] = DEM(dem_db = dem_db,\n",
    "                               region_sets = regions_np,\n",
    "                               log2fc_thr = dem_log2fc_thr,\n",
    "                               motif_hit_thr = dem_motif_hit_thr,\n",
    "                               max_bg_regions = dem_max_bg_regions,\n",
    "                               specie = species,\n",
    "                               promoter_space = promoter_space,\n",
    "                               motif_annotation = annotation,\n",
    "                               motif_similarity_fdr = motif_similarity_fdr, \n",
    "                               path_to_motif_annotations = path_to_motif_annotations,\n",
    "                               n_cpu = n_cpu,\n",
    "                               annotation_version = annotation_version,\n",
    "                               tmp_dir = save_path,\n",
    "                               _temp_dir= _temp_dir,\n",
    "                               **kwargs)\n",
    "                m4=psutil.Process().memory_info().rss / (1024 * 1024) / 1000\n",
    "                t1_stop = time.time()\n",
    "                time_dem_np = t1_stop-t1_start\n",
    "                out_folder = os.path.join(save_path,'DEM_'+key+'_No_promoters')\n",
    "                check_folder = os.path.isdir(out_folder)\n",
    "                if not check_folder:\n",
    "                    os.makedirs(out_folder)\n",
    "                    log.info(\"Created folder : \"+ out_folder)\n",
    "                else:\n",
    "                    log.info(out_folder + \" folder already exists.\")\n",
    "                for x in menr['DEM_'+key+'_No_promoters'].motif_enrichment.keys():\n",
    "                    out_file = os.path.join(out_folder, str(x) +'.html')\n",
    "                    menr['DEM_'+key+'_No_promoters'].motif_enrichment[str(x)].to_html(open(out_file, 'w'), escape=False, col_space=80)\n",
    "                if(save_partial):\n",
    "                    with open(os.path.join(save_path, 'DEM_'+key+'_No_promoters'+'.pkl'), 'wb') as f:\n",
    "                      dill.dump(menr['DEM_'+key+'_All'], f, protocol=-1)\n",
    "                    \n",
    "        times = [time_ctx_all, time_ctx_np, time_dem_all, time_dem_np]\n",
    "        df = pd.DataFrame(times, index=['CTX_all', 'CTX_np', 'DEM_all', 'DEM_np'], columns=['Time'])\n",
    "        df.to_csv(save_path+key+'running_times.tsv', sep='\\t') \n",
    "        memory=[m1,m2,m3,m4]\n",
    "        df = pd.DataFrame(memory, index=['CTX_all', 'CTX_np', 'DEM_all', 'DEM_np'], columns=['Memory'])\n",
    "        df.to_csv(save_path+key+'cummulative_memory.tsv', sep='\\t')  \n",
    "        memory=[m1,m2-m1,m3-m2,m4-m3]\n",
    "        df = pd.DataFrame(memory, index=['CTX_all', 'CTX_np', 'DEM_all', 'DEM_np'], columns=['Memory'])\n",
    "        df.to_csv(save_path+key+'memory_per_step.tsv', sep='\\t')  \n",
    "                    \n",
    "    log.info('Saving object')         \n",
    "    with open(os.path.join(save_path,'menr.pkl'), 'wb') as f:\n",
    "        dill.dump(menr, f, protocol=-1)\n",
    "    \n",
    "    import time\n",
    "    log.info('Finished! Took {} minutes'.format((time.time() - start_time)/60)) \n",
    "            \n",
    "# Load region binarized topics\n",
    "import pickle\n",
    "outDir = '/staging/leuven/stg_00002/lcb/cbravo/Multiomics_pipeline/analysis/DPCL/speed_benchmark/high_simulation/DPCL_cisTopicObject_20K_fragments_25K_cells/'\n",
    "infile = open(outDir+'binarized_topic_region.pkl', 'rb')\n",
    "binarized_topic_region = pickle.load(infile)\n",
    "infile.close()\n",
    "# Load DARs\n",
    "import pickle\n",
    "infile = open(outDir+'DARs.pkl', 'rb')\n",
    "DARs_dict = pickle.load(infile)\n",
    "infile.close()\n",
    "# Format region sets\n",
    "import re\n",
    "import pyranges as pr\n",
    "from pycistarget.utils import *\n",
    "region_sets = {}\n",
    "region_sets['Topics'] = {key: pr.PyRanges(region_names_to_coordinates(binarized_topic_region[key].index.tolist())) for key in binarized_topic_region.keys()}\n",
    "region_sets['DARs'] = {re.sub('[^A-Za-z0-9]+', '_', key): pr.PyRanges(region_names_to_coordinates(DARs_dict[key].index.tolist())) for key in DARs_dict.keys()}\n",
    "# Create save_path\n",
    "save_path = outDir + 'pycistarget/'\n",
    "# Create save_Dir\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "\n",
    "# Run pycistarget\n",
    "run_pycistarget(region_sets,\n",
    "                 ctx_db_path = '/staging/leuven/stg_00002/lcb/cbravo/Multiomics_pipeline/analysis/DPCL/ctx_db/cluster_V10_DPCL_feather_v2.regions_vs_motifs.rankings.feather',\n",
    "                 species = 'homo_sapiens',\n",
    "                 save_path = save_path,\n",
    "                 dem_db_path = '/staging/leuven/stg_00002/lcb/cbravo/Multiomics_pipeline/analysis/DPCL/ctx_db/cluster_V10_DPCL_feather_v2.regions_vs_motifs.scores.feather',\n",
    "                 run_without_promoters = True,\n",
    "                 biomart_host = 'http://www.ensembl.org',\n",
    "                 promoter_space = 500,\n",
    "                 ctx_auc_threshold = 0.005,\n",
    "                 ctx_nes_threshold = 3.0,\n",
    "                 ctx_rank_threshold = 0.05,\n",
    "                 dem_log2fc_thr = 0.5,\n",
    "                 dem_motif_hit_thr = 3.0,\n",
    "                 dem_max_bg_regions = 500,\n",
    "                 path_to_motif_annotations = '/staging/leuven/stg_00002/lcb/cbravo/cluster_motif_collection_V10_no_desso_no_factorbook/snapshots/motifs-v10nr_clust-nr.mgi-m0.00001-o0.0.tbl',\n",
    "                 annotation_version = 'v10nr_clust',\n",
    "                 annotation = ['Direct_annot', 'Orthology_annot'],\n",
    "                 n_cpu = 8,\n",
    "                 _temp_dir = '/scratch/leuven/313/vsc31305/ray_spill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba1dcfd-6311-470c-b952-26a3b6c58002",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --partition=batch\n",
    "#SBATCH --cluster wice\n",
    "#SBATCH --account lp_wice_pilot\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=carmen.bravogonzalezblas@kuleuven.be\n",
    "#SBATCH --ntasks=1\n",
    "\n",
    "#SBATCH --cpus-per-task=20\n",
    "#SBATCH --time=3:00:00\n",
    "#SBATCH --mem=180G\n",
    "\n",
    "#SBATCH --job-name=DPCL_cisTopicObject_20K_fragments_25K_cells\n",
    "#SBATCH --output=DPCL_cisTopicObject_20K_fragments_25K_cells.out\n",
    "#SBATCH --error=DPCL_cisTopicObject_20K_fragments_25K_cells.err\n",
    "\n",
    "singularity exec -B /lustre1,/staging,/data,/vsc-hard-mounts,/scratch,/local_scratch /data/leuven/software/biomed/singularity_images/scenicplus/scenicplus.sif python DPCL_cisTopicObject_20K_fragments_25K_cells.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee806aa0-fb47-4caf-bc17-7b826496365a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DEV IMAGE - SCENIC+ latest (use at own risk)",
   "language": "python",
   "name": "pyscenic_plus_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
